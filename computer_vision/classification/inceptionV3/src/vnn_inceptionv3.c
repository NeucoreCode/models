/****************************************************************************
*   Generated by ACUITY 3.11.0
*   Match ovxlib 1.0.8
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_inceptionv3.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        _node->uid = (uint32_t)_uid; \
        if( NULL == _node ) {\
            goto error;\
        }\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(uint32_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (127)
#define NET_NORM_TENSOR_NUM     (2)
#define NET_CONST_TENSOR_NUM    (208)
#define NET_VIRTUAL_TENSOR_NUM  (127)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM + 32)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static void load_hw_config
    (
    vsi_nn_context_t ctx
    )
{
    ctx->config.evis.ver = VSI_NN_HW_EVIS_2;
    strncpy(ctx->config.target_name, "VIP8000", VSI_NN_MAX_TARGET_NAME);
}

static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    int32_t ret;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = fseek(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    ret = fread(data, 1, sz, fp);
    VSILOGI("Read %d data.", ret);
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateInceptionv3
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx
    )
{
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;

    uint32_t   perm_1[] = { 2, 0, 1, 3 };
    uint32_t   shape_1[] = { 1, 1, 1001, 1 };
    uint32_t   shape_2[] = { 1001, -1 };


    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
        load_hw_config(ctx);
    }
    else
    {
        ctx = in_ctx;
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphInputs( graph, NULL, 1 );
    vsi_nn_SetGraphOutputs( graph, NULL, 1 );

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D_314_InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu_312
      var       - node[0]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[299, 299, 3, 1]]
      out_shape - [[149, 149, 32, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_CONV_RELU, 3, 1, 312);
    node[0]->nn_param.conv2d.ksize[0] = 3;
    node[0]->nn_param.conv2d.ksize[1] = 3;
    node[0]->nn_param.conv2d.weights = 32;
    node[0]->nn_param.conv2d.stride[0] = 2;
    node[0]->nn_param.conv2d.stride[1] = 2;
    node[0]->nn_param.conv2d.pad[0] = 0;
    node[0]->nn_param.conv2d.pad[1] = 0;
    node[0]->nn_param.conv2d.pad[2] = 0;
    node[0]->nn_param.conv2d.pad[3] = 0;
    node[0]->nn_param.conv2d.group = 1;
    node[0]->nn_param.conv2d.dilation[0] = 1;
    node[0]->nn_param.conv2d.dilation[1] = 1;
    node[0]->vx_param.has_relu = TRUE;
    node[0]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[0]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[0]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Conv2d_2a_3x3/Conv2D_311_InceptionV3/InceptionV3/Conv2d_2a_3x3/Relu_309
      var       - node[1]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[149, 149, 32, 1]]
      out_shape - [[147, 147, 32, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_CONV_RELU, 3, 1, 309);
    node[1]->nn_param.conv2d.ksize[0] = 3;
    node[1]->nn_param.conv2d.ksize[1] = 3;
    node[1]->nn_param.conv2d.weights = 32;
    node[1]->nn_param.conv2d.stride[0] = 1;
    node[1]->nn_param.conv2d.stride[1] = 1;
    node[1]->nn_param.conv2d.pad[0] = 0;
    node[1]->nn_param.conv2d.pad[1] = 0;
    node[1]->nn_param.conv2d.pad[2] = 0;
    node[1]->nn_param.conv2d.pad[3] = 0;
    node[1]->nn_param.conv2d.group = 1;
    node[1]->nn_param.conv2d.dilation[0] = 1;
    node[1]->nn_param.conv2d.dilation[1] = 1;
    node[1]->vx_param.has_relu = TRUE;
    node[1]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[1]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[1]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Conv2d_2b_3x3/Conv2D_308_InceptionV3/InceptionV3/Conv2d_2b_3x3/Relu_306
      var       - node[2]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[147, 147, 32, 1]]
      out_shape - [[147, 147, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_CONV_RELU, 3, 1, 306);
    node[2]->nn_param.conv2d.ksize[0] = 3;
    node[2]->nn_param.conv2d.ksize[1] = 3;
    node[2]->nn_param.conv2d.weights = 64;
    node[2]->nn_param.conv2d.stride[0] = 1;
    node[2]->nn_param.conv2d.stride[1] = 1;
    node[2]->nn_param.conv2d.pad[0] = 1;
    node[2]->nn_param.conv2d.pad[1] = 1;
    node[2]->nn_param.conv2d.pad[2] = 1;
    node[2]->nn_param.conv2d.pad[3] = 1;
    node[2]->nn_param.conv2d.group = 1;
    node[2]->nn_param.conv2d.dilation[0] = 1;
    node[2]->nn_param.conv2d.dilation[1] = 1;
    node[2]->vx_param.has_relu = TRUE;
    node[2]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[2]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[2]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/MaxPool_3a_3x3/MaxPool_305
      var       - node[3]
      name      - InceptionV3/InceptionV3/MaxPool_3a_3x3/MaxPool
      operation - pooling
      in_shape  - [[147, 147, 64, 1]]
      out_shape - [[73, 73, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_POOL, 1, 1, 305);
    node[3]->nn_param.pool.ksize[0] = 3;
    node[3]->nn_param.pool.ksize[1] = 3;
    node[3]->nn_param.pool.stride[0] = 2;
    node[3]->nn_param.pool.stride[1] = 2;
    node[3]->nn_param.pool.pad[0] = 0;
    node[3]->nn_param.pool.pad[1] = 0;
    node[3]->nn_param.pool.pad[2] = 0;
    node[3]->nn_param.pool.pad[3] = 0;
    node[3]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[3]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[3]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Conv2d_3b_1x1/Conv2D_304_InceptionV3/InceptionV3/Conv2d_3b_1x1/Relu_302
      var       - node[4]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[73, 73, 64, 1]]
      out_shape - [[73, 73, 80, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_CONV_RELU, 3, 1, 302);
    node[4]->nn_param.conv2d.ksize[0] = 1;
    node[4]->nn_param.conv2d.ksize[1] = 1;
    node[4]->nn_param.conv2d.weights = 80;
    node[4]->nn_param.conv2d.stride[0] = 1;
    node[4]->nn_param.conv2d.stride[1] = 1;
    node[4]->nn_param.conv2d.pad[0] = 0;
    node[4]->nn_param.conv2d.pad[1] = 0;
    node[4]->nn_param.conv2d.pad[2] = 0;
    node[4]->nn_param.conv2d.pad[3] = 0;
    node[4]->nn_param.conv2d.group = 1;
    node[4]->nn_param.conv2d.dilation[0] = 1;
    node[4]->nn_param.conv2d.dilation[1] = 1;
    node[4]->vx_param.has_relu = TRUE;
    node[4]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[4]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[4]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Conv2d_4a_3x3/Conv2D_301_InceptionV3/InceptionV3/Conv2d_4a_3x3/Relu_299
      var       - node[5]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[73, 73, 80, 1]]
      out_shape - [[71, 71, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_CONV_RELU, 3, 1, 299);
    node[5]->nn_param.conv2d.ksize[0] = 3;
    node[5]->nn_param.conv2d.ksize[1] = 3;
    node[5]->nn_param.conv2d.weights = 192;
    node[5]->nn_param.conv2d.stride[0] = 1;
    node[5]->nn_param.conv2d.stride[1] = 1;
    node[5]->nn_param.conv2d.pad[0] = 0;
    node[5]->nn_param.conv2d.pad[1] = 0;
    node[5]->nn_param.conv2d.pad[2] = 0;
    node[5]->nn_param.conv2d.pad[3] = 0;
    node[5]->nn_param.conv2d.group = 1;
    node[5]->nn_param.conv2d.dilation[0] = 1;
    node[5]->nn_param.conv2d.dilation[1] = 1;
    node[5]->vx_param.has_relu = TRUE;
    node[5]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[5]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[5]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/MaxPool_5a_3x3/MaxPool_298
      var       - node[6]
      name      - InceptionV3/InceptionV3/MaxPool_5a_3x3/MaxPool
      operation - pooling
      in_shape  - [[71, 71, 192, 1]]
      out_shape - [[35, 35, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_POOL, 1, 1, 298);
    node[6]->nn_param.pool.ksize[0] = 3;
    node[6]->nn_param.pool.ksize[1] = 3;
    node[6]->nn_param.pool.stride[0] = 2;
    node[6]->nn_param.pool.stride[1] = 2;
    node[6]->nn_param.pool.pad[0] = 0;
    node[6]->nn_param.pool.pad[1] = 0;
    node[6]->nn_param.pool.pad[2] = 0;
    node[6]->nn_param.pool.pad[3] = 0;
    node[6]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[6]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[6]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_284_InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_276
      var       - node[7]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 192, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_CONV_RELU, 3, 1, 276);
    node[7]->nn_param.conv2d.ksize[0] = 1;
    node[7]->nn_param.conv2d.ksize[1] = 1;
    node[7]->nn_param.conv2d.weights = 64;
    node[7]->nn_param.conv2d.stride[0] = 1;
    node[7]->nn_param.conv2d.stride[1] = 1;
    node[7]->nn_param.conv2d.pad[0] = 0;
    node[7]->nn_param.conv2d.pad[1] = 0;
    node[7]->nn_param.conv2d.pad[2] = 0;
    node[7]->nn_param.conv2d.pad[3] = 0;
    node[7]->nn_param.conv2d.group = 1;
    node[7]->nn_param.conv2d.dilation[0] = 1;
    node[7]->nn_param.conv2d.dilation[1] = 1;
    node[7]->vx_param.has_relu = TRUE;
    node[7]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[7]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[7]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_293_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_288
      var       - node[8]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 192, 1]]
      out_shape - [[35, 35, 48, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_CONV_RELU, 3, 1, 288);
    node[8]->nn_param.conv2d.ksize[0] = 1;
    node[8]->nn_param.conv2d.ksize[1] = 1;
    node[8]->nn_param.conv2d.weights = 48;
    node[8]->nn_param.conv2d.stride[0] = 1;
    node[8]->nn_param.conv2d.stride[1] = 1;
    node[8]->nn_param.conv2d.pad[0] = 0;
    node[8]->nn_param.conv2d.pad[1] = 0;
    node[8]->nn_param.conv2d.pad[2] = 0;
    node[8]->nn_param.conv2d.pad[3] = 0;
    node[8]->nn_param.conv2d.group = 1;
    node[8]->nn_param.conv2d.dilation[0] = 1;
    node[8]->nn_param.conv2d.dilation[1] = 1;
    node[8]->vx_param.has_relu = TRUE;
    node[8]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[8]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[8]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_297_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_295
      var       - node[9]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 192, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_CONV_RELU, 3, 1, 295);
    node[9]->nn_param.conv2d.ksize[0] = 1;
    node[9]->nn_param.conv2d.ksize[1] = 1;
    node[9]->nn_param.conv2d.weights = 64;
    node[9]->nn_param.conv2d.stride[0] = 1;
    node[9]->nn_param.conv2d.stride[1] = 1;
    node[9]->nn_param.conv2d.pad[0] = 0;
    node[9]->nn_param.conv2d.pad[1] = 0;
    node[9]->nn_param.conv2d.pad[2] = 0;
    node[9]->nn_param.conv2d.pad[3] = 0;
    node[9]->nn_param.conv2d.group = 1;
    node[9]->nn_param.conv2d.dilation[0] = 1;
    node[9]->nn_param.conv2d.dilation[1] = 1;
    node[9]->vx_param.has_relu = TRUE;
    node[9]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[9]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[9]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_290_conv_323
      var       - node[10]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 192, 1]]
      out_shape - [[35, 35, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_CONV_RELU, 3, 1, 323);
    node[10]->nn_param.conv2d.ksize[0] = 3;
    node[10]->nn_param.conv2d.ksize[1] = 3;
    node[10]->nn_param.conv2d.weights = 192;
    node[10]->nn_param.conv2d.stride[0] = 1;
    node[10]->nn_param.conv2d.stride[1] = 1;
    node[10]->nn_param.conv2d.pad[0] = 1;
    node[10]->nn_param.conv2d.pad[1] = 1;
    node[10]->nn_param.conv2d.pad[2] = 1;
    node[10]->nn_param.conv2d.pad[3] = 1;
    node[10]->nn_param.conv2d.group = 1;
    node[10]->nn_param.conv2d.dilation[0] = 1;
    node[10]->nn_param.conv2d.dilation[1] = 1;
    node[10]->vx_param.has_relu = FALSE;
    node[10]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[10]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[10]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Conv2D_285_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Relu_277
      var       - node[11]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 48, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_CONV_RELU, 3, 1, 277);
    node[11]->nn_param.conv2d.ksize[0] = 5;
    node[11]->nn_param.conv2d.ksize[1] = 5;
    node[11]->nn_param.conv2d.weights = 64;
    node[11]->nn_param.conv2d.stride[0] = 1;
    node[11]->nn_param.conv2d.stride[1] = 1;
    node[11]->nn_param.conv2d.pad[0] = 2;
    node[11]->nn_param.conv2d.pad[1] = 2;
    node[11]->nn_param.conv2d.pad[2] = 2;
    node[11]->nn_param.conv2d.pad[3] = 2;
    node[11]->nn_param.conv2d.group = 1;
    node[11]->nn_param.conv2d.dilation[0] = 1;
    node[11]->nn_param.conv2d.dilation[1] = 1;
    node[11]->vx_param.has_relu = TRUE;
    node[11]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[11]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[11]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_294_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_289
      var       - node[12]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_CONV_RELU, 3, 1, 289);
    node[12]->nn_param.conv2d.ksize[0] = 3;
    node[12]->nn_param.conv2d.ksize[1] = 3;
    node[12]->nn_param.conv2d.weights = 96;
    node[12]->nn_param.conv2d.stride[0] = 1;
    node[12]->nn_param.conv2d.stride[1] = 1;
    node[12]->nn_param.conv2d.pad[0] = 1;
    node[12]->nn_param.conv2d.pad[1] = 1;
    node[12]->nn_param.conv2d.pad[2] = 1;
    node[12]->nn_param.conv2d.pad[3] = 1;
    node[12]->nn_param.conv2d.group = 1;
    node[12]->nn_param.conv2d.dilation[0] = 1;
    node[12]->nn_param.conv2d.dilation[1] = 1;
    node[12]->vx_param.has_relu = TRUE;
    node[12]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[12]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[12]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_287_InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_279
      var       - node[13]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 192, 1]]
      out_shape - [[35, 35, 32, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_CONV_RELU, 3, 1, 279);
    node[13]->nn_param.conv2d.ksize[0] = 1;
    node[13]->nn_param.conv2d.ksize[1] = 1;
    node[13]->nn_param.conv2d.weights = 32;
    node[13]->nn_param.conv2d.stride[0] = 1;
    node[13]->nn_param.conv2d.stride[1] = 1;
    node[13]->nn_param.conv2d.pad[0] = 0;
    node[13]->nn_param.conv2d.pad[1] = 0;
    node[13]->nn_param.conv2d.pad[2] = 0;
    node[13]->nn_param.conv2d.pad[3] = 0;
    node[13]->nn_param.conv2d.group = 1;
    node[13]->nn_param.conv2d.dilation[0] = 1;
    node[13]->nn_param.conv2d.dilation[1] = 1;
    node[13]->vx_param.has_relu = TRUE;
    node[13]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[13]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[13]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_286_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_278
      var       - node[14]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 96, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_CONV_RELU, 3, 1, 278);
    node[14]->nn_param.conv2d.ksize[0] = 3;
    node[14]->nn_param.conv2d.ksize[1] = 3;
    node[14]->nn_param.conv2d.weights = 96;
    node[14]->nn_param.conv2d.stride[0] = 1;
    node[14]->nn_param.conv2d.stride[1] = 1;
    node[14]->nn_param.conv2d.pad[0] = 1;
    node[14]->nn_param.conv2d.pad[1] = 1;
    node[14]->nn_param.conv2d.pad[2] = 1;
    node[14]->nn_param.conv2d.pad[3] = 1;
    node[14]->nn_param.conv2d.group = 1;
    node[14]->nn_param.conv2d.dilation[0] = 1;
    node[14]->nn_param.conv2d.dilation[1] = 1;
    node[14]->vx_param.has_relu = TRUE;
    node[14]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[14]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[14]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5b/concat_275
      var       - node[15]
      name      - InceptionV3/InceptionV3/Mixed_5b/concat
      operation - concat
      in_shape  - [[35, 35, 64, 1]]
                  [[35, 35, 64, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 32, 1]]
      out_shape - [[35, 35, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_CONCAT, 4, 1, 275);
    node[15]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_261_InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_253
      var       - node[16]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 256, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_CONV_RELU, 3, 1, 253);
    node[16]->nn_param.conv2d.ksize[0] = 1;
    node[16]->nn_param.conv2d.ksize[1] = 1;
    node[16]->nn_param.conv2d.weights = 64;
    node[16]->nn_param.conv2d.stride[0] = 1;
    node[16]->nn_param.conv2d.stride[1] = 1;
    node[16]->nn_param.conv2d.pad[0] = 0;
    node[16]->nn_param.conv2d.pad[1] = 0;
    node[16]->nn_param.conv2d.pad[2] = 0;
    node[16]->nn_param.conv2d.pad[3] = 0;
    node[16]->nn_param.conv2d.group = 1;
    node[16]->nn_param.conv2d.dilation[0] = 1;
    node[16]->nn_param.conv2d.dilation[1] = 1;
    node[16]->vx_param.has_relu = TRUE;
    node[16]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[16]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[16]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Conv2D_270_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Relu_265
      var       - node[17]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 256, 1]]
      out_shape - [[35, 35, 48, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_CONV_RELU, 3, 1, 265);
    node[17]->nn_param.conv2d.ksize[0] = 1;
    node[17]->nn_param.conv2d.ksize[1] = 1;
    node[17]->nn_param.conv2d.weights = 48;
    node[17]->nn_param.conv2d.stride[0] = 1;
    node[17]->nn_param.conv2d.stride[1] = 1;
    node[17]->nn_param.conv2d.pad[0] = 0;
    node[17]->nn_param.conv2d.pad[1] = 0;
    node[17]->nn_param.conv2d.pad[2] = 0;
    node[17]->nn_param.conv2d.pad[3] = 0;
    node[17]->nn_param.conv2d.group = 1;
    node[17]->nn_param.conv2d.dilation[0] = 1;
    node[17]->nn_param.conv2d.dilation[1] = 1;
    node[17]->vx_param.has_relu = TRUE;
    node[17]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[17]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[17]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_274_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_272
      var       - node[18]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 256, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_CONV_RELU, 3, 1, 272);
    node[18]->nn_param.conv2d.ksize[0] = 1;
    node[18]->nn_param.conv2d.ksize[1] = 1;
    node[18]->nn_param.conv2d.weights = 64;
    node[18]->nn_param.conv2d.stride[0] = 1;
    node[18]->nn_param.conv2d.stride[1] = 1;
    node[18]->nn_param.conv2d.pad[0] = 0;
    node[18]->nn_param.conv2d.pad[1] = 0;
    node[18]->nn_param.conv2d.pad[2] = 0;
    node[18]->nn_param.conv2d.pad[3] = 0;
    node[18]->nn_param.conv2d.group = 1;
    node[18]->nn_param.conv2d.dilation[0] = 1;
    node[18]->nn_param.conv2d.dilation[1] = 1;
    node[18]->vx_param.has_relu = TRUE;
    node[18]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[18]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[18]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_267_conv_322
      var       - node[19]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 256, 1]]
      out_shape - [[35, 35, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_CONV_RELU, 3, 1, 322);
    node[19]->nn_param.conv2d.ksize[0] = 3;
    node[19]->nn_param.conv2d.ksize[1] = 3;
    node[19]->nn_param.conv2d.weights = 256;
    node[19]->nn_param.conv2d.stride[0] = 1;
    node[19]->nn_param.conv2d.stride[1] = 1;
    node[19]->nn_param.conv2d.pad[0] = 1;
    node[19]->nn_param.conv2d.pad[1] = 1;
    node[19]->nn_param.conv2d.pad[2] = 1;
    node[19]->nn_param.conv2d.pad[3] = 1;
    node[19]->nn_param.conv2d.group = 1;
    node[19]->nn_param.conv2d.dilation[0] = 1;
    node[19]->nn_param.conv2d.dilation[1] = 1;
    node[19]->vx_param.has_relu = FALSE;
    node[19]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[19]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[19]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Conv2D_262_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Relu_254
      var       - node[20]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 48, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_CONV_RELU, 3, 1, 254);
    node[20]->nn_param.conv2d.ksize[0] = 5;
    node[20]->nn_param.conv2d.ksize[1] = 5;
    node[20]->nn_param.conv2d.weights = 64;
    node[20]->nn_param.conv2d.stride[0] = 1;
    node[20]->nn_param.conv2d.stride[1] = 1;
    node[20]->nn_param.conv2d.pad[0] = 2;
    node[20]->nn_param.conv2d.pad[1] = 2;
    node[20]->nn_param.conv2d.pad[2] = 2;
    node[20]->nn_param.conv2d.pad[3] = 2;
    node[20]->nn_param.conv2d.group = 1;
    node[20]->nn_param.conv2d.dilation[0] = 1;
    node[20]->nn_param.conv2d.dilation[1] = 1;
    node[20]->vx_param.has_relu = TRUE;
    node[20]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[20]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[20]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_271_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_266
      var       - node[21]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_CONV_RELU, 3, 1, 266);
    node[21]->nn_param.conv2d.ksize[0] = 3;
    node[21]->nn_param.conv2d.ksize[1] = 3;
    node[21]->nn_param.conv2d.weights = 96;
    node[21]->nn_param.conv2d.stride[0] = 1;
    node[21]->nn_param.conv2d.stride[1] = 1;
    node[21]->nn_param.conv2d.pad[0] = 1;
    node[21]->nn_param.conv2d.pad[1] = 1;
    node[21]->nn_param.conv2d.pad[2] = 1;
    node[21]->nn_param.conv2d.pad[3] = 1;
    node[21]->nn_param.conv2d.group = 1;
    node[21]->nn_param.conv2d.dilation[0] = 1;
    node[21]->nn_param.conv2d.dilation[1] = 1;
    node[21]->vx_param.has_relu = TRUE;
    node[21]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[21]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[21]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_264_InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_256
      var       - node[22]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 256, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_CONV_RELU, 3, 1, 256);
    node[22]->nn_param.conv2d.ksize[0] = 1;
    node[22]->nn_param.conv2d.ksize[1] = 1;
    node[22]->nn_param.conv2d.weights = 64;
    node[22]->nn_param.conv2d.stride[0] = 1;
    node[22]->nn_param.conv2d.stride[1] = 1;
    node[22]->nn_param.conv2d.pad[0] = 0;
    node[22]->nn_param.conv2d.pad[1] = 0;
    node[22]->nn_param.conv2d.pad[2] = 0;
    node[22]->nn_param.conv2d.pad[3] = 0;
    node[22]->nn_param.conv2d.group = 1;
    node[22]->nn_param.conv2d.dilation[0] = 1;
    node[22]->nn_param.conv2d.dilation[1] = 1;
    node[22]->vx_param.has_relu = TRUE;
    node[22]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[22]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[22]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_263_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_255
      var       - node[23]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 96, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_CONV_RELU, 3, 1, 255);
    node[23]->nn_param.conv2d.ksize[0] = 3;
    node[23]->nn_param.conv2d.ksize[1] = 3;
    node[23]->nn_param.conv2d.weights = 96;
    node[23]->nn_param.conv2d.stride[0] = 1;
    node[23]->nn_param.conv2d.stride[1] = 1;
    node[23]->nn_param.conv2d.pad[0] = 1;
    node[23]->nn_param.conv2d.pad[1] = 1;
    node[23]->nn_param.conv2d.pad[2] = 1;
    node[23]->nn_param.conv2d.pad[3] = 1;
    node[23]->nn_param.conv2d.group = 1;
    node[23]->nn_param.conv2d.dilation[0] = 1;
    node[23]->nn_param.conv2d.dilation[1] = 1;
    node[23]->vx_param.has_relu = TRUE;
    node[23]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[23]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[23]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5c/concat_252
      var       - node[24]
      name      - InceptionV3/InceptionV3/Mixed_5c/concat
      operation - concat
      in_shape  - [[35, 35, 64, 1]]
                  [[35, 35, 64, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 64, 1]]
      out_shape - [[35, 35, 288, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_CONCAT, 4, 1, 252);
    node[24]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_238_InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_230
      var       - node[25]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 288, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_CONV_RELU, 3, 1, 230);
    node[25]->nn_param.conv2d.ksize[0] = 1;
    node[25]->nn_param.conv2d.ksize[1] = 1;
    node[25]->nn_param.conv2d.weights = 64;
    node[25]->nn_param.conv2d.stride[0] = 1;
    node[25]->nn_param.conv2d.stride[1] = 1;
    node[25]->nn_param.conv2d.pad[0] = 0;
    node[25]->nn_param.conv2d.pad[1] = 0;
    node[25]->nn_param.conv2d.pad[2] = 0;
    node[25]->nn_param.conv2d.pad[3] = 0;
    node[25]->nn_param.conv2d.group = 1;
    node[25]->nn_param.conv2d.dilation[0] = 1;
    node[25]->nn_param.conv2d.dilation[1] = 1;
    node[25]->vx_param.has_relu = TRUE;
    node[25]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[25]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[25]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_247_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_242
      var       - node[26]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 288, 1]]
      out_shape - [[35, 35, 48, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_CONV_RELU, 3, 1, 242);
    node[26]->nn_param.conv2d.ksize[0] = 1;
    node[26]->nn_param.conv2d.ksize[1] = 1;
    node[26]->nn_param.conv2d.weights = 48;
    node[26]->nn_param.conv2d.stride[0] = 1;
    node[26]->nn_param.conv2d.stride[1] = 1;
    node[26]->nn_param.conv2d.pad[0] = 0;
    node[26]->nn_param.conv2d.pad[1] = 0;
    node[26]->nn_param.conv2d.pad[2] = 0;
    node[26]->nn_param.conv2d.pad[3] = 0;
    node[26]->nn_param.conv2d.group = 1;
    node[26]->nn_param.conv2d.dilation[0] = 1;
    node[26]->nn_param.conv2d.dilation[1] = 1;
    node[26]->vx_param.has_relu = TRUE;
    node[26]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[26]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[26]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_251_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_249
      var       - node[27]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 288, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_CONV_RELU, 3, 1, 249);
    node[27]->nn_param.conv2d.ksize[0] = 1;
    node[27]->nn_param.conv2d.ksize[1] = 1;
    node[27]->nn_param.conv2d.weights = 64;
    node[27]->nn_param.conv2d.stride[0] = 1;
    node[27]->nn_param.conv2d.stride[1] = 1;
    node[27]->nn_param.conv2d.pad[0] = 0;
    node[27]->nn_param.conv2d.pad[1] = 0;
    node[27]->nn_param.conv2d.pad[2] = 0;
    node[27]->nn_param.conv2d.pad[3] = 0;
    node[27]->nn_param.conv2d.group = 1;
    node[27]->nn_param.conv2d.dilation[0] = 1;
    node[27]->nn_param.conv2d.dilation[1] = 1;
    node[27]->vx_param.has_relu = TRUE;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_244_conv_321
      var       - node[28]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 288, 1]]
      out_shape - [[35, 35, 288, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_CONV_RELU, 3, 1, 321);
    node[28]->nn_param.conv2d.ksize[0] = 3;
    node[28]->nn_param.conv2d.ksize[1] = 3;
    node[28]->nn_param.conv2d.weights = 288;
    node[28]->nn_param.conv2d.stride[0] = 1;
    node[28]->nn_param.conv2d.stride[1] = 1;
    node[28]->nn_param.conv2d.pad[0] = 1;
    node[28]->nn_param.conv2d.pad[1] = 1;
    node[28]->nn_param.conv2d.pad[2] = 1;
    node[28]->nn_param.conv2d.pad[3] = 1;
    node[28]->nn_param.conv2d.group = 1;
    node[28]->nn_param.conv2d.dilation[0] = 1;
    node[28]->nn_param.conv2d.dilation[1] = 1;
    node[28]->vx_param.has_relu = FALSE;
    node[28]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[28]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[28]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Conv2D_239_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Relu_231
      var       - node[29]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 48, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_CONV_RELU, 3, 1, 231);
    node[29]->nn_param.conv2d.ksize[0] = 5;
    node[29]->nn_param.conv2d.ksize[1] = 5;
    node[29]->nn_param.conv2d.weights = 64;
    node[29]->nn_param.conv2d.stride[0] = 1;
    node[29]->nn_param.conv2d.stride[1] = 1;
    node[29]->nn_param.conv2d.pad[0] = 2;
    node[29]->nn_param.conv2d.pad[1] = 2;
    node[29]->nn_param.conv2d.pad[2] = 2;
    node[29]->nn_param.conv2d.pad[3] = 2;
    node[29]->nn_param.conv2d.group = 1;
    node[29]->nn_param.conv2d.dilation[0] = 1;
    node[29]->nn_param.conv2d.dilation[1] = 1;
    node[29]->vx_param.has_relu = TRUE;
    node[29]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[29]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[29]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_248_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_243
      var       - node[30]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_CONV_RELU, 3, 1, 243);
    node[30]->nn_param.conv2d.ksize[0] = 3;
    node[30]->nn_param.conv2d.ksize[1] = 3;
    node[30]->nn_param.conv2d.weights = 96;
    node[30]->nn_param.conv2d.stride[0] = 1;
    node[30]->nn_param.conv2d.stride[1] = 1;
    node[30]->nn_param.conv2d.pad[0] = 1;
    node[30]->nn_param.conv2d.pad[1] = 1;
    node[30]->nn_param.conv2d.pad[2] = 1;
    node[30]->nn_param.conv2d.pad[3] = 1;
    node[30]->nn_param.conv2d.group = 1;
    node[30]->nn_param.conv2d.dilation[0] = 1;
    node[30]->nn_param.conv2d.dilation[1] = 1;
    node[30]->vx_param.has_relu = TRUE;
    node[30]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[30]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[30]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_241_InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_233
      var       - node[31]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 288, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_CONV_RELU, 3, 1, 233);
    node[31]->nn_param.conv2d.ksize[0] = 1;
    node[31]->nn_param.conv2d.ksize[1] = 1;
    node[31]->nn_param.conv2d.weights = 64;
    node[31]->nn_param.conv2d.stride[0] = 1;
    node[31]->nn_param.conv2d.stride[1] = 1;
    node[31]->nn_param.conv2d.pad[0] = 0;
    node[31]->nn_param.conv2d.pad[1] = 0;
    node[31]->nn_param.conv2d.pad[2] = 0;
    node[31]->nn_param.conv2d.pad[3] = 0;
    node[31]->nn_param.conv2d.group = 1;
    node[31]->nn_param.conv2d.dilation[0] = 1;
    node[31]->nn_param.conv2d.dilation[1] = 1;
    node[31]->vx_param.has_relu = TRUE;
    node[31]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[31]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[31]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_240_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_232
      var       - node[32]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 96, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_CONV_RELU, 3, 1, 232);
    node[32]->nn_param.conv2d.ksize[0] = 3;
    node[32]->nn_param.conv2d.ksize[1] = 3;
    node[32]->nn_param.conv2d.weights = 96;
    node[32]->nn_param.conv2d.stride[0] = 1;
    node[32]->nn_param.conv2d.stride[1] = 1;
    node[32]->nn_param.conv2d.pad[0] = 1;
    node[32]->nn_param.conv2d.pad[1] = 1;
    node[32]->nn_param.conv2d.pad[2] = 1;
    node[32]->nn_param.conv2d.pad[3] = 1;
    node[32]->nn_param.conv2d.group = 1;
    node[32]->nn_param.conv2d.dilation[0] = 1;
    node[32]->nn_param.conv2d.dilation[1] = 1;
    node[32]->vx_param.has_relu = TRUE;
    node[32]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[32]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[32]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_5d/concat_229
      var       - node[33]
      name      - InceptionV3/InceptionV3/Mixed_5d/concat
      operation - concat
      in_shape  - [[35, 35, 64, 1]]
                  [[35, 35, 64, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 64, 1]]
      out_shape - [[35, 35, 288, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[33], VSI_NN_OP_CONCAT, 4, 1, 229);
    node[33]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6a/Branch_2/MaxPool_1a_3x3/MaxPool_218
      var       - node[34]
      name      - InceptionV3/InceptionV3/Mixed_6a/Branch_2/MaxPool_1a_3x3/MaxPool
      operation - pooling
      in_shape  - [[35, 35, 288, 1]]
      out_shape - [[17, 17, 288, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[34], VSI_NN_OP_POOL, 1, 1, 218);
    node[34]->nn_param.pool.ksize[0] = 3;
    node[34]->nn_param.pool.ksize[1] = 3;
    node[34]->nn_param.pool.stride[0] = 2;
    node[34]->nn_param.pool.stride[1] = 2;
    node[34]->nn_param.pool.pad[0] = 0;
    node[34]->nn_param.pool.pad[1] = 0;
    node[34]->nn_param.pool.pad[2] = 0;
    node[34]->nn_param.pool.pad[3] = 0;
    node[34]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[34]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[34]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Conv2D_221_InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Relu_216
      var       - node[35]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 288, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[35], VSI_NN_OP_CONV_RELU, 3, 1, 216);
    node[35]->nn_param.conv2d.ksize[0] = 3;
    node[35]->nn_param.conv2d.ksize[1] = 3;
    node[35]->nn_param.conv2d.weights = 384;
    node[35]->nn_param.conv2d.stride[0] = 2;
    node[35]->nn_param.conv2d.stride[1] = 2;
    node[35]->nn_param.conv2d.pad[0] = 0;
    node[35]->nn_param.conv2d.pad[1] = 0;
    node[35]->nn_param.conv2d.pad[2] = 0;
    node[35]->nn_param.conv2d.pad[3] = 0;
    node[35]->nn_param.conv2d.group = 1;
    node[35]->nn_param.conv2d.dilation[0] = 1;
    node[35]->nn_param.conv2d.dilation[1] = 1;
    node[35]->vx_param.has_relu = TRUE;
    node[35]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[35]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[35]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_228_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_226
      var       - node[36]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 288, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[36], VSI_NN_OP_CONV_RELU, 3, 1, 226);
    node[36]->nn_param.conv2d.ksize[0] = 1;
    node[36]->nn_param.conv2d.ksize[1] = 1;
    node[36]->nn_param.conv2d.weights = 64;
    node[36]->nn_param.conv2d.stride[0] = 1;
    node[36]->nn_param.conv2d.stride[1] = 1;
    node[36]->nn_param.conv2d.pad[0] = 0;
    node[36]->nn_param.conv2d.pad[1] = 0;
    node[36]->nn_param.conv2d.pad[2] = 0;
    node[36]->nn_param.conv2d.pad[3] = 0;
    node[36]->nn_param.conv2d.group = 1;
    node[36]->nn_param.conv2d.dilation[0] = 1;
    node[36]->nn_param.conv2d.dilation[1] = 1;
    node[36]->vx_param.has_relu = TRUE;
    node[36]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[36]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[36]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_225_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_223
      var       - node[37]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[37], VSI_NN_OP_CONV_RELU, 3, 1, 223);
    node[37]->nn_param.conv2d.ksize[0] = 3;
    node[37]->nn_param.conv2d.ksize[1] = 3;
    node[37]->nn_param.conv2d.weights = 96;
    node[37]->nn_param.conv2d.stride[0] = 1;
    node[37]->nn_param.conv2d.stride[1] = 1;
    node[37]->nn_param.conv2d.pad[0] = 1;
    node[37]->nn_param.conv2d.pad[1] = 1;
    node[37]->nn_param.conv2d.pad[2] = 1;
    node[37]->nn_param.conv2d.pad[3] = 1;
    node[37]->nn_param.conv2d.group = 1;
    node[37]->nn_param.conv2d.dilation[0] = 1;
    node[37]->nn_param.conv2d.dilation[1] = 1;
    node[37]->vx_param.has_relu = TRUE;
    node[37]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[37]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[37]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Conv2D_222_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Relu_217
      var       - node[38]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 96, 1]]
      out_shape - [[17, 17, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[38], VSI_NN_OP_CONV_RELU, 3, 1, 217);
    node[38]->nn_param.conv2d.ksize[0] = 3;
    node[38]->nn_param.conv2d.ksize[1] = 3;
    node[38]->nn_param.conv2d.weights = 96;
    node[38]->nn_param.conv2d.stride[0] = 2;
    node[38]->nn_param.conv2d.stride[1] = 2;
    node[38]->nn_param.conv2d.pad[0] = 0;
    node[38]->nn_param.conv2d.pad[1] = 0;
    node[38]->nn_param.conv2d.pad[2] = 0;
    node[38]->nn_param.conv2d.pad[3] = 0;
    node[38]->nn_param.conv2d.group = 1;
    node[38]->nn_param.conv2d.dilation[0] = 1;
    node[38]->nn_param.conv2d.dilation[1] = 1;
    node[38]->vx_param.has_relu = TRUE;
    node[38]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[38]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[38]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6a/concat_215
      var       - node[39]
      name      - InceptionV3/InceptionV3/Mixed_6a/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 96, 1]]
                  [[17, 17, 288, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[39], VSI_NN_OP_CONCAT, 3, 1, 215);
    node[39]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_192_InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_184
      var       - node[40]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[40], VSI_NN_OP_CONV_RELU, 3, 1, 184);
    node[40]->nn_param.conv2d.ksize[0] = 1;
    node[40]->nn_param.conv2d.ksize[1] = 1;
    node[40]->nn_param.conv2d.weights = 192;
    node[40]->nn_param.conv2d.stride[0] = 1;
    node[40]->nn_param.conv2d.stride[1] = 1;
    node[40]->nn_param.conv2d.pad[0] = 0;
    node[40]->nn_param.conv2d.pad[1] = 0;
    node[40]->nn_param.conv2d.pad[2] = 0;
    node[40]->nn_param.conv2d.pad[3] = 0;
    node[40]->nn_param.conv2d.group = 1;
    node[40]->nn_param.conv2d.dilation[0] = 1;
    node[40]->nn_param.conv2d.dilation[1] = 1;
    node[40]->vx_param.has_relu = TRUE;
    node[40]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[40]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[40]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_207_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_203
      var       - node[41]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[41], VSI_NN_OP_CONV_RELU, 3, 1, 203);
    node[41]->nn_param.conv2d.ksize[0] = 1;
    node[41]->nn_param.conv2d.ksize[1] = 1;
    node[41]->nn_param.conv2d.weights = 128;
    node[41]->nn_param.conv2d.stride[0] = 1;
    node[41]->nn_param.conv2d.stride[1] = 1;
    node[41]->nn_param.conv2d.pad[0] = 0;
    node[41]->nn_param.conv2d.pad[1] = 0;
    node[41]->nn_param.conv2d.pad[2] = 0;
    node[41]->nn_param.conv2d.pad[3] = 0;
    node[41]->nn_param.conv2d.group = 1;
    node[41]->nn_param.conv2d.dilation[0] = 1;
    node[41]->nn_param.conv2d.dilation[1] = 1;
    node[41]->vx_param.has_relu = TRUE;
    node[41]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[41]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[41]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_214_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_212
      var       - node[42]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[42], VSI_NN_OP_CONV_RELU, 3, 1, 212);
    node[42]->nn_param.conv2d.ksize[0] = 1;
    node[42]->nn_param.conv2d.ksize[1] = 1;
    node[42]->nn_param.conv2d.weights = 128;
    node[42]->nn_param.conv2d.stride[0] = 1;
    node[42]->nn_param.conv2d.stride[1] = 1;
    node[42]->nn_param.conv2d.pad[0] = 0;
    node[42]->nn_param.conv2d.pad[1] = 0;
    node[42]->nn_param.conv2d.pad[2] = 0;
    node[42]->nn_param.conv2d.pad[3] = 0;
    node[42]->nn_param.conv2d.group = 1;
    node[42]->nn_param.conv2d.dilation[0] = 1;
    node[42]->nn_param.conv2d.dilation[1] = 1;
    node[42]->vx_param.has_relu = TRUE;
    node[42]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[42]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[42]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_198_conv_320
      var       - node[43]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[43], VSI_NN_OP_CONV_RELU, 3, 1, 320);
    node[43]->nn_param.conv2d.ksize[0] = 3;
    node[43]->nn_param.conv2d.ksize[1] = 3;
    node[43]->nn_param.conv2d.weights = 768;
    node[43]->nn_param.conv2d.stride[0] = 1;
    node[43]->nn_param.conv2d.stride[1] = 1;
    node[43]->nn_param.conv2d.pad[0] = 1;
    node[43]->nn_param.conv2d.pad[1] = 1;
    node[43]->nn_param.conv2d.pad[2] = 1;
    node[43]->nn_param.conv2d.pad[3] = 1;
    node[43]->nn_param.conv2d.group = 1;
    node[43]->nn_param.conv2d.dilation[0] = 1;
    node[43]->nn_param.conv2d.dilation[1] = 1;
    node[43]->vx_param.has_relu = FALSE;
    node[43]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[43]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[43]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_201_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_196
      var       - node[44]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 128, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[44], VSI_NN_OP_CONV_RELU, 3, 1, 196);
    node[44]->nn_param.conv2d.ksize[0] = 7;
    node[44]->nn_param.conv2d.ksize[1] = 7;
    node[44]->nn_param.conv2d.weights = 128;
    node[44]->nn_param.conv2d.stride[0] = 1;
    node[44]->nn_param.conv2d.stride[1] = 1;
    node[44]->nn_param.conv2d.pad[0] = 3;
    node[44]->nn_param.conv2d.pad[1] = 3;
    node[44]->nn_param.conv2d.pad[2] = 3;
    node[44]->nn_param.conv2d.pad[3] = 3;
    node[44]->nn_param.conv2d.group = 1;
    node[44]->nn_param.conv2d.dilation[0] = 1;
    node[44]->nn_param.conv2d.dilation[1] = 1;
    node[44]->vx_param.has_relu = TRUE;
    node[44]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[44]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[44]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_211_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_209
      var       - node[45]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 128, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[45], VSI_NN_OP_CONV_RELU, 3, 1, 209);
    node[45]->nn_param.conv2d.ksize[0] = 1;
    node[45]->nn_param.conv2d.ksize[1] = 7;
    node[45]->nn_param.conv2d.weights = 128;
    node[45]->nn_param.conv2d.stride[0] = 1;
    node[45]->nn_param.conv2d.stride[1] = 1;
    node[45]->nn_param.conv2d.pad[0] = 0;
    node[45]->nn_param.conv2d.pad[1] = 0;
    node[45]->nn_param.conv2d.pad[2] = 3;
    node[45]->nn_param.conv2d.pad[3] = 3;
    node[45]->nn_param.conv2d.group = 1;
    node[45]->nn_param.conv2d.dilation[0] = 1;
    node[45]->nn_param.conv2d.dilation[1] = 1;
    node[45]->vx_param.has_relu = TRUE;
    node[45]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[45]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[45]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_195_InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_187
      var       - node[46]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[46], VSI_NN_OP_CONV_RELU, 3, 1, 187);
    node[46]->nn_param.conv2d.ksize[0] = 1;
    node[46]->nn_param.conv2d.ksize[1] = 1;
    node[46]->nn_param.conv2d.weights = 192;
    node[46]->nn_param.conv2d.stride[0] = 1;
    node[46]->nn_param.conv2d.stride[1] = 1;
    node[46]->nn_param.conv2d.pad[0] = 0;
    node[46]->nn_param.conv2d.pad[1] = 0;
    node[46]->nn_param.conv2d.pad[2] = 0;
    node[46]->nn_param.conv2d.pad[3] = 0;
    node[46]->nn_param.conv2d.group = 1;
    node[46]->nn_param.conv2d.dilation[0] = 1;
    node[46]->nn_param.conv2d.dilation[1] = 1;
    node[46]->vx_param.has_relu = TRUE;
    node[46]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[46]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[46]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_193_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_185
      var       - node[47]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 128, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[47], VSI_NN_OP_CONV_RELU, 3, 1, 185);
    node[47]->nn_param.conv2d.ksize[0] = 1;
    node[47]->nn_param.conv2d.ksize[1] = 7;
    node[47]->nn_param.conv2d.weights = 192;
    node[47]->nn_param.conv2d.stride[0] = 1;
    node[47]->nn_param.conv2d.stride[1] = 1;
    node[47]->nn_param.conv2d.pad[0] = 0;
    node[47]->nn_param.conv2d.pad[1] = 0;
    node[47]->nn_param.conv2d.pad[2] = 3;
    node[47]->nn_param.conv2d.pad[3] = 3;
    node[47]->nn_param.conv2d.group = 1;
    node[47]->nn_param.conv2d.dilation[0] = 1;
    node[47]->nn_param.conv2d.dilation[1] = 1;
    node[47]->vx_param.has_relu = TRUE;
    node[47]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[47]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[47]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_208_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_204
      var       - node[48]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 128, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[48], VSI_NN_OP_CONV_RELU, 3, 1, 204);
    node[48]->nn_param.conv2d.ksize[0] = 7;
    node[48]->nn_param.conv2d.ksize[1] = 7;
    node[48]->nn_param.conv2d.weights = 128;
    node[48]->nn_param.conv2d.stride[0] = 1;
    node[48]->nn_param.conv2d.stride[1] = 1;
    node[48]->nn_param.conv2d.pad[0] = 3;
    node[48]->nn_param.conv2d.pad[1] = 3;
    node[48]->nn_param.conv2d.pad[2] = 3;
    node[48]->nn_param.conv2d.pad[3] = 3;
    node[48]->nn_param.conv2d.group = 1;
    node[48]->nn_param.conv2d.dilation[0] = 1;
    node[48]->nn_param.conv2d.dilation[1] = 1;
    node[48]->vx_param.has_relu = TRUE;
    node[48]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[48]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[48]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_202_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_197
      var       - node[49]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 128, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[49], VSI_NN_OP_CONV_RELU, 3, 1, 197);
    node[49]->nn_param.conv2d.ksize[0] = 1;
    node[49]->nn_param.conv2d.ksize[1] = 7;
    node[49]->nn_param.conv2d.weights = 128;
    node[49]->nn_param.conv2d.stride[0] = 1;
    node[49]->nn_param.conv2d.stride[1] = 1;
    node[49]->nn_param.conv2d.pad[0] = 0;
    node[49]->nn_param.conv2d.pad[1] = 0;
    node[49]->nn_param.conv2d.pad[2] = 3;
    node[49]->nn_param.conv2d.pad[3] = 3;
    node[49]->nn_param.conv2d.group = 1;
    node[49]->nn_param.conv2d.dilation[0] = 1;
    node[49]->nn_param.conv2d.dilation[1] = 1;
    node[49]->vx_param.has_relu = TRUE;
    node[49]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[49]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[49]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_194_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_186
      var       - node[50]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 128, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[50], VSI_NN_OP_CONV_RELU, 3, 1, 186);
    node[50]->nn_param.conv2d.ksize[0] = 7;
    node[50]->nn_param.conv2d.ksize[1] = 7;
    node[50]->nn_param.conv2d.weights = 192;
    node[50]->nn_param.conv2d.stride[0] = 1;
    node[50]->nn_param.conv2d.stride[1] = 1;
    node[50]->nn_param.conv2d.pad[0] = 3;
    node[50]->nn_param.conv2d.pad[1] = 3;
    node[50]->nn_param.conv2d.pad[2] = 3;
    node[50]->nn_param.conv2d.pad[3] = 3;
    node[50]->nn_param.conv2d.group = 1;
    node[50]->nn_param.conv2d.dilation[0] = 1;
    node[50]->nn_param.conv2d.dilation[1] = 1;
    node[50]->vx_param.has_relu = TRUE;
    node[50]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[50]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[50]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6b/concat_183
      var       - node[51]
      name      - InceptionV3/InceptionV3/Mixed_6b/concat
      operation - concat
      in_shape  - [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[51], VSI_NN_OP_CONCAT, 4, 1, 183);
    node[51]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_160_InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_152
      var       - node[52]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[52], VSI_NN_OP_CONV_RELU, 3, 1, 152);
    node[52]->nn_param.conv2d.ksize[0] = 1;
    node[52]->nn_param.conv2d.ksize[1] = 1;
    node[52]->nn_param.conv2d.weights = 192;
    node[52]->nn_param.conv2d.stride[0] = 1;
    node[52]->nn_param.conv2d.stride[1] = 1;
    node[52]->nn_param.conv2d.pad[0] = 0;
    node[52]->nn_param.conv2d.pad[1] = 0;
    node[52]->nn_param.conv2d.pad[2] = 0;
    node[52]->nn_param.conv2d.pad[3] = 0;
    node[52]->nn_param.conv2d.group = 1;
    node[52]->nn_param.conv2d.dilation[0] = 1;
    node[52]->nn_param.conv2d.dilation[1] = 1;
    node[52]->vx_param.has_relu = TRUE;
    node[52]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[52]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[52]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_175_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_171
      var       - node[53]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[53], VSI_NN_OP_CONV_RELU, 3, 1, 171);
    node[53]->nn_param.conv2d.ksize[0] = 1;
    node[53]->nn_param.conv2d.ksize[1] = 1;
    node[53]->nn_param.conv2d.weights = 160;
    node[53]->nn_param.conv2d.stride[0] = 1;
    node[53]->nn_param.conv2d.stride[1] = 1;
    node[53]->nn_param.conv2d.pad[0] = 0;
    node[53]->nn_param.conv2d.pad[1] = 0;
    node[53]->nn_param.conv2d.pad[2] = 0;
    node[53]->nn_param.conv2d.pad[3] = 0;
    node[53]->nn_param.conv2d.group = 1;
    node[53]->nn_param.conv2d.dilation[0] = 1;
    node[53]->nn_param.conv2d.dilation[1] = 1;
    node[53]->vx_param.has_relu = TRUE;
    node[53]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[53]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[53]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_182_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_180
      var       - node[54]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[54], VSI_NN_OP_CONV_RELU, 3, 1, 180);
    node[54]->nn_param.conv2d.ksize[0] = 1;
    node[54]->nn_param.conv2d.ksize[1] = 1;
    node[54]->nn_param.conv2d.weights = 160;
    node[54]->nn_param.conv2d.stride[0] = 1;
    node[54]->nn_param.conv2d.stride[1] = 1;
    node[54]->nn_param.conv2d.pad[0] = 0;
    node[54]->nn_param.conv2d.pad[1] = 0;
    node[54]->nn_param.conv2d.pad[2] = 0;
    node[54]->nn_param.conv2d.pad[3] = 0;
    node[54]->nn_param.conv2d.group = 1;
    node[54]->nn_param.conv2d.dilation[0] = 1;
    node[54]->nn_param.conv2d.dilation[1] = 1;
    node[54]->vx_param.has_relu = TRUE;
    node[54]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[54]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[54]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_166_conv_319
      var       - node[55]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[55], VSI_NN_OP_CONV_RELU, 3, 1, 319);
    node[55]->nn_param.conv2d.ksize[0] = 3;
    node[55]->nn_param.conv2d.ksize[1] = 3;
    node[55]->nn_param.conv2d.weights = 768;
    node[55]->nn_param.conv2d.stride[0] = 1;
    node[55]->nn_param.conv2d.stride[1] = 1;
    node[55]->nn_param.conv2d.pad[0] = 1;
    node[55]->nn_param.conv2d.pad[1] = 1;
    node[55]->nn_param.conv2d.pad[2] = 1;
    node[55]->nn_param.conv2d.pad[3] = 1;
    node[55]->nn_param.conv2d.group = 1;
    node[55]->nn_param.conv2d.dilation[0] = 1;
    node[55]->nn_param.conv2d.dilation[1] = 1;
    node[55]->vx_param.has_relu = FALSE;
    node[55]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[55]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[55]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_169_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_164
      var       - node[56]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[56], VSI_NN_OP_CONV_RELU, 3, 1, 164);
    node[56]->nn_param.conv2d.ksize[0] = 7;
    node[56]->nn_param.conv2d.ksize[1] = 7;
    node[56]->nn_param.conv2d.weights = 160;
    node[56]->nn_param.conv2d.stride[0] = 1;
    node[56]->nn_param.conv2d.stride[1] = 1;
    node[56]->nn_param.conv2d.pad[0] = 3;
    node[56]->nn_param.conv2d.pad[1] = 3;
    node[56]->nn_param.conv2d.pad[2] = 3;
    node[56]->nn_param.conv2d.pad[3] = 3;
    node[56]->nn_param.conv2d.group = 1;
    node[56]->nn_param.conv2d.dilation[0] = 1;
    node[56]->nn_param.conv2d.dilation[1] = 1;
    node[56]->vx_param.has_relu = TRUE;
    node[56]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[56]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[56]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_179_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_177
      var       - node[57]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[57], VSI_NN_OP_CONV_RELU, 3, 1, 177);
    node[57]->nn_param.conv2d.ksize[0] = 1;
    node[57]->nn_param.conv2d.ksize[1] = 7;
    node[57]->nn_param.conv2d.weights = 160;
    node[57]->nn_param.conv2d.stride[0] = 1;
    node[57]->nn_param.conv2d.stride[1] = 1;
    node[57]->nn_param.conv2d.pad[0] = 0;
    node[57]->nn_param.conv2d.pad[1] = 0;
    node[57]->nn_param.conv2d.pad[2] = 3;
    node[57]->nn_param.conv2d.pad[3] = 3;
    node[57]->nn_param.conv2d.group = 1;
    node[57]->nn_param.conv2d.dilation[0] = 1;
    node[57]->nn_param.conv2d.dilation[1] = 1;
    node[57]->vx_param.has_relu = TRUE;
    node[57]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[57]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[57]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_163_InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_155
      var       - node[58]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[58], VSI_NN_OP_CONV_RELU, 3, 1, 155);
    node[58]->nn_param.conv2d.ksize[0] = 1;
    node[58]->nn_param.conv2d.ksize[1] = 1;
    node[58]->nn_param.conv2d.weights = 192;
    node[58]->nn_param.conv2d.stride[0] = 1;
    node[58]->nn_param.conv2d.stride[1] = 1;
    node[58]->nn_param.conv2d.pad[0] = 0;
    node[58]->nn_param.conv2d.pad[1] = 0;
    node[58]->nn_param.conv2d.pad[2] = 0;
    node[58]->nn_param.conv2d.pad[3] = 0;
    node[58]->nn_param.conv2d.group = 1;
    node[58]->nn_param.conv2d.dilation[0] = 1;
    node[58]->nn_param.conv2d.dilation[1] = 1;
    node[58]->vx_param.has_relu = TRUE;
    node[58]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[58]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[58]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_161_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_153
      var       - node[59]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[59], VSI_NN_OP_CONV_RELU, 3, 1, 153);
    node[59]->nn_param.conv2d.ksize[0] = 1;
    node[59]->nn_param.conv2d.ksize[1] = 7;
    node[59]->nn_param.conv2d.weights = 192;
    node[59]->nn_param.conv2d.stride[0] = 1;
    node[59]->nn_param.conv2d.stride[1] = 1;
    node[59]->nn_param.conv2d.pad[0] = 0;
    node[59]->nn_param.conv2d.pad[1] = 0;
    node[59]->nn_param.conv2d.pad[2] = 3;
    node[59]->nn_param.conv2d.pad[3] = 3;
    node[59]->nn_param.conv2d.group = 1;
    node[59]->nn_param.conv2d.dilation[0] = 1;
    node[59]->nn_param.conv2d.dilation[1] = 1;
    node[59]->vx_param.has_relu = TRUE;
    node[59]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[59]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[59]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_176_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_172
      var       - node[60]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[60], VSI_NN_OP_CONV_RELU, 3, 1, 172);
    node[60]->nn_param.conv2d.ksize[0] = 7;
    node[60]->nn_param.conv2d.ksize[1] = 7;
    node[60]->nn_param.conv2d.weights = 160;
    node[60]->nn_param.conv2d.stride[0] = 1;
    node[60]->nn_param.conv2d.stride[1] = 1;
    node[60]->nn_param.conv2d.pad[0] = 3;
    node[60]->nn_param.conv2d.pad[1] = 3;
    node[60]->nn_param.conv2d.pad[2] = 3;
    node[60]->nn_param.conv2d.pad[3] = 3;
    node[60]->nn_param.conv2d.group = 1;
    node[60]->nn_param.conv2d.dilation[0] = 1;
    node[60]->nn_param.conv2d.dilation[1] = 1;
    node[60]->vx_param.has_relu = TRUE;
    node[60]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[60]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[60]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_170_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_165
      var       - node[61]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[61], VSI_NN_OP_CONV_RELU, 3, 1, 165);
    node[61]->nn_param.conv2d.ksize[0] = 1;
    node[61]->nn_param.conv2d.ksize[1] = 7;
    node[61]->nn_param.conv2d.weights = 160;
    node[61]->nn_param.conv2d.stride[0] = 1;
    node[61]->nn_param.conv2d.stride[1] = 1;
    node[61]->nn_param.conv2d.pad[0] = 0;
    node[61]->nn_param.conv2d.pad[1] = 0;
    node[61]->nn_param.conv2d.pad[2] = 3;
    node[61]->nn_param.conv2d.pad[3] = 3;
    node[61]->nn_param.conv2d.group = 1;
    node[61]->nn_param.conv2d.dilation[0] = 1;
    node[61]->nn_param.conv2d.dilation[1] = 1;
    node[61]->vx_param.has_relu = TRUE;
    node[61]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[61]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[61]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_162_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_154
      var       - node[62]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[62], VSI_NN_OP_CONV_RELU, 3, 1, 154);
    node[62]->nn_param.conv2d.ksize[0] = 7;
    node[62]->nn_param.conv2d.ksize[1] = 7;
    node[62]->nn_param.conv2d.weights = 192;
    node[62]->nn_param.conv2d.stride[0] = 1;
    node[62]->nn_param.conv2d.stride[1] = 1;
    node[62]->nn_param.conv2d.pad[0] = 3;
    node[62]->nn_param.conv2d.pad[1] = 3;
    node[62]->nn_param.conv2d.pad[2] = 3;
    node[62]->nn_param.conv2d.pad[3] = 3;
    node[62]->nn_param.conv2d.group = 1;
    node[62]->nn_param.conv2d.dilation[0] = 1;
    node[62]->nn_param.conv2d.dilation[1] = 1;
    node[62]->vx_param.has_relu = TRUE;
    node[62]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[62]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[62]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6c/concat_151
      var       - node[63]
      name      - InceptionV3/InceptionV3/Mixed_6c/concat
      operation - concat
      in_shape  - [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[63], VSI_NN_OP_CONCAT, 4, 1, 151);
    node[63]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_128_InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_120
      var       - node[64]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[64], VSI_NN_OP_CONV_RELU, 3, 1, 120);
    node[64]->nn_param.conv2d.ksize[0] = 1;
    node[64]->nn_param.conv2d.ksize[1] = 1;
    node[64]->nn_param.conv2d.weights = 192;
    node[64]->nn_param.conv2d.stride[0] = 1;
    node[64]->nn_param.conv2d.stride[1] = 1;
    node[64]->nn_param.conv2d.pad[0] = 0;
    node[64]->nn_param.conv2d.pad[1] = 0;
    node[64]->nn_param.conv2d.pad[2] = 0;
    node[64]->nn_param.conv2d.pad[3] = 0;
    node[64]->nn_param.conv2d.group = 1;
    node[64]->nn_param.conv2d.dilation[0] = 1;
    node[64]->nn_param.conv2d.dilation[1] = 1;
    node[64]->vx_param.has_relu = TRUE;
    node[64]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[64]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[64]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_143_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_139
      var       - node[65]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[65], VSI_NN_OP_CONV_RELU, 3, 1, 139);
    node[65]->nn_param.conv2d.ksize[0] = 1;
    node[65]->nn_param.conv2d.ksize[1] = 1;
    node[65]->nn_param.conv2d.weights = 160;
    node[65]->nn_param.conv2d.stride[0] = 1;
    node[65]->nn_param.conv2d.stride[1] = 1;
    node[65]->nn_param.conv2d.pad[0] = 0;
    node[65]->nn_param.conv2d.pad[1] = 0;
    node[65]->nn_param.conv2d.pad[2] = 0;
    node[65]->nn_param.conv2d.pad[3] = 0;
    node[65]->nn_param.conv2d.group = 1;
    node[65]->nn_param.conv2d.dilation[0] = 1;
    node[65]->nn_param.conv2d.dilation[1] = 1;
    node[65]->vx_param.has_relu = TRUE;
    node[65]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[65]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[65]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_150_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_148
      var       - node[66]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[66], VSI_NN_OP_CONV_RELU, 3, 1, 148);
    node[66]->nn_param.conv2d.ksize[0] = 1;
    node[66]->nn_param.conv2d.ksize[1] = 1;
    node[66]->nn_param.conv2d.weights = 160;
    node[66]->nn_param.conv2d.stride[0] = 1;
    node[66]->nn_param.conv2d.stride[1] = 1;
    node[66]->nn_param.conv2d.pad[0] = 0;
    node[66]->nn_param.conv2d.pad[1] = 0;
    node[66]->nn_param.conv2d.pad[2] = 0;
    node[66]->nn_param.conv2d.pad[3] = 0;
    node[66]->nn_param.conv2d.group = 1;
    node[66]->nn_param.conv2d.dilation[0] = 1;
    node[66]->nn_param.conv2d.dilation[1] = 1;
    node[66]->vx_param.has_relu = TRUE;
    node[66]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[66]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[66]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_134_conv_318
      var       - node[67]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[67], VSI_NN_OP_CONV_RELU, 3, 1, 318);
    node[67]->nn_param.conv2d.ksize[0] = 3;
    node[67]->nn_param.conv2d.ksize[1] = 3;
    node[67]->nn_param.conv2d.weights = 768;
    node[67]->nn_param.conv2d.stride[0] = 1;
    node[67]->nn_param.conv2d.stride[1] = 1;
    node[67]->nn_param.conv2d.pad[0] = 1;
    node[67]->nn_param.conv2d.pad[1] = 1;
    node[67]->nn_param.conv2d.pad[2] = 1;
    node[67]->nn_param.conv2d.pad[3] = 1;
    node[67]->nn_param.conv2d.group = 1;
    node[67]->nn_param.conv2d.dilation[0] = 1;
    node[67]->nn_param.conv2d.dilation[1] = 1;
    node[67]->vx_param.has_relu = FALSE;
    node[67]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[67]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[67]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_137_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_132
      var       - node[68]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[68], VSI_NN_OP_CONV_RELU, 3, 1, 132);
    node[68]->nn_param.conv2d.ksize[0] = 7;
    node[68]->nn_param.conv2d.ksize[1] = 7;
    node[68]->nn_param.conv2d.weights = 160;
    node[68]->nn_param.conv2d.stride[0] = 1;
    node[68]->nn_param.conv2d.stride[1] = 1;
    node[68]->nn_param.conv2d.pad[0] = 3;
    node[68]->nn_param.conv2d.pad[1] = 3;
    node[68]->nn_param.conv2d.pad[2] = 3;
    node[68]->nn_param.conv2d.pad[3] = 3;
    node[68]->nn_param.conv2d.group = 1;
    node[68]->nn_param.conv2d.dilation[0] = 1;
    node[68]->nn_param.conv2d.dilation[1] = 1;
    node[68]->vx_param.has_relu = TRUE;
    node[68]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[68]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[68]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_147_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_145
      var       - node[69]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[69], VSI_NN_OP_CONV_RELU, 3, 1, 145);
    node[69]->nn_param.conv2d.ksize[0] = 1;
    node[69]->nn_param.conv2d.ksize[1] = 7;
    node[69]->nn_param.conv2d.weights = 160;
    node[69]->nn_param.conv2d.stride[0] = 1;
    node[69]->nn_param.conv2d.stride[1] = 1;
    node[69]->nn_param.conv2d.pad[0] = 0;
    node[69]->nn_param.conv2d.pad[1] = 0;
    node[69]->nn_param.conv2d.pad[2] = 3;
    node[69]->nn_param.conv2d.pad[3] = 3;
    node[69]->nn_param.conv2d.group = 1;
    node[69]->nn_param.conv2d.dilation[0] = 1;
    node[69]->nn_param.conv2d.dilation[1] = 1;
    node[69]->vx_param.has_relu = TRUE;
    node[69]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[69]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[69]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_131_InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_123
      var       - node[70]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[70], VSI_NN_OP_CONV_RELU, 3, 1, 123);
    node[70]->nn_param.conv2d.ksize[0] = 1;
    node[70]->nn_param.conv2d.ksize[1] = 1;
    node[70]->nn_param.conv2d.weights = 192;
    node[70]->nn_param.conv2d.stride[0] = 1;
    node[70]->nn_param.conv2d.stride[1] = 1;
    node[70]->nn_param.conv2d.pad[0] = 0;
    node[70]->nn_param.conv2d.pad[1] = 0;
    node[70]->nn_param.conv2d.pad[2] = 0;
    node[70]->nn_param.conv2d.pad[3] = 0;
    node[70]->nn_param.conv2d.group = 1;
    node[70]->nn_param.conv2d.dilation[0] = 1;
    node[70]->nn_param.conv2d.dilation[1] = 1;
    node[70]->vx_param.has_relu = TRUE;
    node[70]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[70]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[70]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_129_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_121
      var       - node[71]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[71], VSI_NN_OP_CONV_RELU, 3, 1, 121);
    node[71]->nn_param.conv2d.ksize[0] = 1;
    node[71]->nn_param.conv2d.ksize[1] = 7;
    node[71]->nn_param.conv2d.weights = 192;
    node[71]->nn_param.conv2d.stride[0] = 1;
    node[71]->nn_param.conv2d.stride[1] = 1;
    node[71]->nn_param.conv2d.pad[0] = 0;
    node[71]->nn_param.conv2d.pad[1] = 0;
    node[71]->nn_param.conv2d.pad[2] = 3;
    node[71]->nn_param.conv2d.pad[3] = 3;
    node[71]->nn_param.conv2d.group = 1;
    node[71]->nn_param.conv2d.dilation[0] = 1;
    node[71]->nn_param.conv2d.dilation[1] = 1;
    node[71]->vx_param.has_relu = TRUE;
    node[71]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[71]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[71]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_144_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_140
      var       - node[72]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[72], VSI_NN_OP_CONV_RELU, 3, 1, 140);
    node[72]->nn_param.conv2d.ksize[0] = 7;
    node[72]->nn_param.conv2d.ksize[1] = 7;
    node[72]->nn_param.conv2d.weights = 160;
    node[72]->nn_param.conv2d.stride[0] = 1;
    node[72]->nn_param.conv2d.stride[1] = 1;
    node[72]->nn_param.conv2d.pad[0] = 3;
    node[72]->nn_param.conv2d.pad[1] = 3;
    node[72]->nn_param.conv2d.pad[2] = 3;
    node[72]->nn_param.conv2d.pad[3] = 3;
    node[72]->nn_param.conv2d.group = 1;
    node[72]->nn_param.conv2d.dilation[0] = 1;
    node[72]->nn_param.conv2d.dilation[1] = 1;
    node[72]->vx_param.has_relu = TRUE;
    node[72]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[72]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[72]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_138_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_133
      var       - node[73]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[73], VSI_NN_OP_CONV_RELU, 3, 1, 133);
    node[73]->nn_param.conv2d.ksize[0] = 1;
    node[73]->nn_param.conv2d.ksize[1] = 7;
    node[73]->nn_param.conv2d.weights = 160;
    node[73]->nn_param.conv2d.stride[0] = 1;
    node[73]->nn_param.conv2d.stride[1] = 1;
    node[73]->nn_param.conv2d.pad[0] = 0;
    node[73]->nn_param.conv2d.pad[1] = 0;
    node[73]->nn_param.conv2d.pad[2] = 3;
    node[73]->nn_param.conv2d.pad[3] = 3;
    node[73]->nn_param.conv2d.group = 1;
    node[73]->nn_param.conv2d.dilation[0] = 1;
    node[73]->nn_param.conv2d.dilation[1] = 1;
    node[73]->vx_param.has_relu = TRUE;
    node[73]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[73]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[73]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_130_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_122
      var       - node[74]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 160, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[74], VSI_NN_OP_CONV_RELU, 3, 1, 122);
    node[74]->nn_param.conv2d.ksize[0] = 7;
    node[74]->nn_param.conv2d.ksize[1] = 7;
    node[74]->nn_param.conv2d.weights = 192;
    node[74]->nn_param.conv2d.stride[0] = 1;
    node[74]->nn_param.conv2d.stride[1] = 1;
    node[74]->nn_param.conv2d.pad[0] = 3;
    node[74]->nn_param.conv2d.pad[1] = 3;
    node[74]->nn_param.conv2d.pad[2] = 3;
    node[74]->nn_param.conv2d.pad[3] = 3;
    node[74]->nn_param.conv2d.group = 1;
    node[74]->nn_param.conv2d.dilation[0] = 1;
    node[74]->nn_param.conv2d.dilation[1] = 1;
    node[74]->vx_param.has_relu = TRUE;
    node[74]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[74]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[74]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6d/concat_119
      var       - node[75]
      name      - InceptionV3/InceptionV3/Mixed_6d/concat
      operation - concat
      in_shape  - [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[75], VSI_NN_OP_CONCAT, 4, 1, 119);
    node[75]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_96_InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_88
      var       - node[76]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[76], VSI_NN_OP_CONV_RELU, 3, 1, 88);
    node[76]->nn_param.conv2d.ksize[0] = 1;
    node[76]->nn_param.conv2d.ksize[1] = 1;
    node[76]->nn_param.conv2d.weights = 192;
    node[76]->nn_param.conv2d.stride[0] = 1;
    node[76]->nn_param.conv2d.stride[1] = 1;
    node[76]->nn_param.conv2d.pad[0] = 0;
    node[76]->nn_param.conv2d.pad[1] = 0;
    node[76]->nn_param.conv2d.pad[2] = 0;
    node[76]->nn_param.conv2d.pad[3] = 0;
    node[76]->nn_param.conv2d.group = 1;
    node[76]->nn_param.conv2d.dilation[0] = 1;
    node[76]->nn_param.conv2d.dilation[1] = 1;
    node[76]->vx_param.has_relu = TRUE;
    node[76]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[76]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[76]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_111_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_107
      var       - node[77]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[77], VSI_NN_OP_CONV_RELU, 3, 1, 107);
    node[77]->nn_param.conv2d.ksize[0] = 1;
    node[77]->nn_param.conv2d.ksize[1] = 1;
    node[77]->nn_param.conv2d.weights = 192;
    node[77]->nn_param.conv2d.stride[0] = 1;
    node[77]->nn_param.conv2d.stride[1] = 1;
    node[77]->nn_param.conv2d.pad[0] = 0;
    node[77]->nn_param.conv2d.pad[1] = 0;
    node[77]->nn_param.conv2d.pad[2] = 0;
    node[77]->nn_param.conv2d.pad[3] = 0;
    node[77]->nn_param.conv2d.group = 1;
    node[77]->nn_param.conv2d.dilation[0] = 1;
    node[77]->nn_param.conv2d.dilation[1] = 1;
    node[77]->vx_param.has_relu = TRUE;
    node[77]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[77]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[77]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_118_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_116
      var       - node[78]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[78], VSI_NN_OP_CONV_RELU, 3, 1, 116);
    node[78]->nn_param.conv2d.ksize[0] = 1;
    node[78]->nn_param.conv2d.ksize[1] = 1;
    node[78]->nn_param.conv2d.weights = 192;
    node[78]->nn_param.conv2d.stride[0] = 1;
    node[78]->nn_param.conv2d.stride[1] = 1;
    node[78]->nn_param.conv2d.pad[0] = 0;
    node[78]->nn_param.conv2d.pad[1] = 0;
    node[78]->nn_param.conv2d.pad[2] = 0;
    node[78]->nn_param.conv2d.pad[3] = 0;
    node[78]->nn_param.conv2d.group = 1;
    node[78]->nn_param.conv2d.dilation[0] = 1;
    node[78]->nn_param.conv2d.dilation[1] = 1;
    node[78]->vx_param.has_relu = TRUE;
    node[78]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[78]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[78]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_102_conv_317
      var       - node[79]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[79], VSI_NN_OP_CONV_RELU, 3, 1, 317);
    node[79]->nn_param.conv2d.ksize[0] = 3;
    node[79]->nn_param.conv2d.ksize[1] = 3;
    node[79]->nn_param.conv2d.weights = 768;
    node[79]->nn_param.conv2d.stride[0] = 1;
    node[79]->nn_param.conv2d.stride[1] = 1;
    node[79]->nn_param.conv2d.pad[0] = 1;
    node[79]->nn_param.conv2d.pad[1] = 1;
    node[79]->nn_param.conv2d.pad[2] = 1;
    node[79]->nn_param.conv2d.pad[3] = 1;
    node[79]->nn_param.conv2d.group = 1;
    node[79]->nn_param.conv2d.dilation[0] = 1;
    node[79]->nn_param.conv2d.dilation[1] = 1;
    node[79]->vx_param.has_relu = FALSE;
    node[79]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[79]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[79]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_105_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_100
      var       - node[80]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[80], VSI_NN_OP_CONV_RELU, 3, 1, 100);
    node[80]->nn_param.conv2d.ksize[0] = 7;
    node[80]->nn_param.conv2d.ksize[1] = 7;
    node[80]->nn_param.conv2d.weights = 192;
    node[80]->nn_param.conv2d.stride[0] = 1;
    node[80]->nn_param.conv2d.stride[1] = 1;
    node[80]->nn_param.conv2d.pad[0] = 3;
    node[80]->nn_param.conv2d.pad[1] = 3;
    node[80]->nn_param.conv2d.pad[2] = 3;
    node[80]->nn_param.conv2d.pad[3] = 3;
    node[80]->nn_param.conv2d.group = 1;
    node[80]->nn_param.conv2d.dilation[0] = 1;
    node[80]->nn_param.conv2d.dilation[1] = 1;
    node[80]->vx_param.has_relu = TRUE;
    node[80]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[80]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[80]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_115_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_113
      var       - node[81]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[81], VSI_NN_OP_CONV_RELU, 3, 1, 113);
    node[81]->nn_param.conv2d.ksize[0] = 1;
    node[81]->nn_param.conv2d.ksize[1] = 7;
    node[81]->nn_param.conv2d.weights = 192;
    node[81]->nn_param.conv2d.stride[0] = 1;
    node[81]->nn_param.conv2d.stride[1] = 1;
    node[81]->nn_param.conv2d.pad[0] = 0;
    node[81]->nn_param.conv2d.pad[1] = 0;
    node[81]->nn_param.conv2d.pad[2] = 3;
    node[81]->nn_param.conv2d.pad[3] = 3;
    node[81]->nn_param.conv2d.group = 1;
    node[81]->nn_param.conv2d.dilation[0] = 1;
    node[81]->nn_param.conv2d.dilation[1] = 1;
    node[81]->vx_param.has_relu = TRUE;
    node[81]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[81]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[81]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_99_InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_91
      var       - node[82]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[82], VSI_NN_OP_CONV_RELU, 3, 1, 91);
    node[82]->nn_param.conv2d.ksize[0] = 1;
    node[82]->nn_param.conv2d.ksize[1] = 1;
    node[82]->nn_param.conv2d.weights = 192;
    node[82]->nn_param.conv2d.stride[0] = 1;
    node[82]->nn_param.conv2d.stride[1] = 1;
    node[82]->nn_param.conv2d.pad[0] = 0;
    node[82]->nn_param.conv2d.pad[1] = 0;
    node[82]->nn_param.conv2d.pad[2] = 0;
    node[82]->nn_param.conv2d.pad[3] = 0;
    node[82]->nn_param.conv2d.group = 1;
    node[82]->nn_param.conv2d.dilation[0] = 1;
    node[82]->nn_param.conv2d.dilation[1] = 1;
    node[82]->vx_param.has_relu = TRUE;
    node[82]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[82]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[82]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_97_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_89
      var       - node[83]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[83], VSI_NN_OP_CONV_RELU, 3, 1, 89);
    node[83]->nn_param.conv2d.ksize[0] = 1;
    node[83]->nn_param.conv2d.ksize[1] = 7;
    node[83]->nn_param.conv2d.weights = 192;
    node[83]->nn_param.conv2d.stride[0] = 1;
    node[83]->nn_param.conv2d.stride[1] = 1;
    node[83]->nn_param.conv2d.pad[0] = 0;
    node[83]->nn_param.conv2d.pad[1] = 0;
    node[83]->nn_param.conv2d.pad[2] = 3;
    node[83]->nn_param.conv2d.pad[3] = 3;
    node[83]->nn_param.conv2d.group = 1;
    node[83]->nn_param.conv2d.dilation[0] = 1;
    node[83]->nn_param.conv2d.dilation[1] = 1;
    node[83]->vx_param.has_relu = TRUE;
    node[83]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[83]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[83]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_112_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_108
      var       - node[84]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[84], VSI_NN_OP_CONV_RELU, 3, 1, 108);
    node[84]->nn_param.conv2d.ksize[0] = 7;
    node[84]->nn_param.conv2d.ksize[1] = 7;
    node[84]->nn_param.conv2d.weights = 192;
    node[84]->nn_param.conv2d.stride[0] = 1;
    node[84]->nn_param.conv2d.stride[1] = 1;
    node[84]->nn_param.conv2d.pad[0] = 3;
    node[84]->nn_param.conv2d.pad[1] = 3;
    node[84]->nn_param.conv2d.pad[2] = 3;
    node[84]->nn_param.conv2d.pad[3] = 3;
    node[84]->nn_param.conv2d.group = 1;
    node[84]->nn_param.conv2d.dilation[0] = 1;
    node[84]->nn_param.conv2d.dilation[1] = 1;
    node[84]->vx_param.has_relu = TRUE;
    node[84]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[84]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[84]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_106_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_101
      var       - node[85]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[85], VSI_NN_OP_CONV_RELU, 3, 1, 101);
    node[85]->nn_param.conv2d.ksize[0] = 1;
    node[85]->nn_param.conv2d.ksize[1] = 7;
    node[85]->nn_param.conv2d.weights = 192;
    node[85]->nn_param.conv2d.stride[0] = 1;
    node[85]->nn_param.conv2d.stride[1] = 1;
    node[85]->nn_param.conv2d.pad[0] = 0;
    node[85]->nn_param.conv2d.pad[1] = 0;
    node[85]->nn_param.conv2d.pad[2] = 3;
    node[85]->nn_param.conv2d.pad[3] = 3;
    node[85]->nn_param.conv2d.group = 1;
    node[85]->nn_param.conv2d.dilation[0] = 1;
    node[85]->nn_param.conv2d.dilation[1] = 1;
    node[85]->vx_param.has_relu = TRUE;
    node[85]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[85]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[85]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_98_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_90
      var       - node[86]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[86], VSI_NN_OP_CONV_RELU, 3, 1, 90);
    node[86]->nn_param.conv2d.ksize[0] = 7;
    node[86]->nn_param.conv2d.ksize[1] = 7;
    node[86]->nn_param.conv2d.weights = 192;
    node[86]->nn_param.conv2d.stride[0] = 1;
    node[86]->nn_param.conv2d.stride[1] = 1;
    node[86]->nn_param.conv2d.pad[0] = 3;
    node[86]->nn_param.conv2d.pad[1] = 3;
    node[86]->nn_param.conv2d.pad[2] = 3;
    node[86]->nn_param.conv2d.pad[3] = 3;
    node[86]->nn_param.conv2d.group = 1;
    node[86]->nn_param.conv2d.dilation[0] = 1;
    node[86]->nn_param.conv2d.dilation[1] = 1;
    node[86]->vx_param.has_relu = TRUE;
    node[86]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[86]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[86]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_6e/concat_87
      var       - node[87]
      name      - InceptionV3/InceptionV3/Mixed_6e/concat
      operation - concat
      in_shape  - [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
                  [[17, 17, 192, 1]]
      out_shape - [[17, 17, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[87], VSI_NN_OP_CONCAT, 4, 1, 87);
    node[87]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7a/Branch_2/MaxPool_1a_3x3/MaxPool_70
      var       - node[88]
      name      - InceptionV3/InceptionV3/Mixed_7a/Branch_2/MaxPool_1a_3x3/MaxPool
      operation - pooling
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[8, 8, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[88], VSI_NN_OP_POOL, 1, 1, 70);
    node[88]->nn_param.pool.ksize[0] = 3;
    node[88]->nn_param.pool.ksize[1] = 3;
    node[88]->nn_param.pool.stride[0] = 2;
    node[88]->nn_param.pool.stride[1] = 2;
    node[88]->nn_param.pool.pad[0] = 0;
    node[88]->nn_param.pool.pad[1] = 0;
    node[88]->nn_param.pool.pad[2] = 0;
    node[88]->nn_param.pool.pad[3] = 0;
    node[88]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[88]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[88]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_79_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_75
      var       - node[89]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[89], VSI_NN_OP_CONV_RELU, 3, 1, 75);
    node[89]->nn_param.conv2d.ksize[0] = 1;
    node[89]->nn_param.conv2d.ksize[1] = 1;
    node[89]->nn_param.conv2d.weights = 192;
    node[89]->nn_param.conv2d.stride[0] = 1;
    node[89]->nn_param.conv2d.stride[1] = 1;
    node[89]->nn_param.conv2d.pad[0] = 0;
    node[89]->nn_param.conv2d.pad[1] = 0;
    node[89]->nn_param.conv2d.pad[2] = 0;
    node[89]->nn_param.conv2d.pad[3] = 0;
    node[89]->nn_param.conv2d.group = 1;
    node[89]->nn_param.conv2d.dilation[0] = 1;
    node[89]->nn_param.conv2d.dilation[1] = 1;
    node[89]->vx_param.has_relu = TRUE;
    node[89]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[89]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[89]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_86_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_84
      var       - node[90]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 768, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[90], VSI_NN_OP_CONV_RELU, 3, 1, 84);
    node[90]->nn_param.conv2d.ksize[0] = 1;
    node[90]->nn_param.conv2d.ksize[1] = 1;
    node[90]->nn_param.conv2d.weights = 192;
    node[90]->nn_param.conv2d.stride[0] = 1;
    node[90]->nn_param.conv2d.stride[1] = 1;
    node[90]->nn_param.conv2d.pad[0] = 0;
    node[90]->nn_param.conv2d.pad[1] = 0;
    node[90]->nn_param.conv2d.pad[2] = 0;
    node[90]->nn_param.conv2d.pad[3] = 0;
    node[90]->nn_param.conv2d.group = 1;
    node[90]->nn_param.conv2d.dilation[0] = 1;
    node[90]->nn_param.conv2d.dilation[1] = 1;
    node[90]->vx_param.has_relu = TRUE;
    node[90]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[90]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[90]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_73_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_68
      var       - node[91]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[8, 8, 320, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[91], VSI_NN_OP_CONV_RELU, 3, 1, 68);
    node[91]->nn_param.conv2d.ksize[0] = 3;
    node[91]->nn_param.conv2d.ksize[1] = 3;
    node[91]->nn_param.conv2d.weights = 320;
    node[91]->nn_param.conv2d.stride[0] = 2;
    node[91]->nn_param.conv2d.stride[1] = 2;
    node[91]->nn_param.conv2d.pad[0] = 0;
    node[91]->nn_param.conv2d.pad[1] = 0;
    node[91]->nn_param.conv2d.pad[2] = 0;
    node[91]->nn_param.conv2d.pad[3] = 0;
    node[91]->nn_param.conv2d.group = 1;
    node[91]->nn_param.conv2d.dilation[0] = 1;
    node[91]->nn_param.conv2d.dilation[1] = 1;
    node[91]->vx_param.has_relu = TRUE;
    node[91]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[91]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[91]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_83_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_81
      var       - node[92]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[92], VSI_NN_OP_CONV_RELU, 3, 1, 81);
    node[92]->nn_param.conv2d.ksize[0] = 7;
    node[92]->nn_param.conv2d.ksize[1] = 7;
    node[92]->nn_param.conv2d.weights = 192;
    node[92]->nn_param.conv2d.stride[0] = 1;
    node[92]->nn_param.conv2d.stride[1] = 1;
    node[92]->nn_param.conv2d.pad[0] = 3;
    node[92]->nn_param.conv2d.pad[1] = 3;
    node[92]->nn_param.conv2d.pad[2] = 3;
    node[92]->nn_param.conv2d.pad[3] = 3;
    node[92]->nn_param.conv2d.group = 1;
    node[92]->nn_param.conv2d.dilation[0] = 1;
    node[92]->nn_param.conv2d.dilation[1] = 1;
    node[92]->vx_param.has_relu = TRUE;
    node[92]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[92]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[92]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_80_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_76
      var       - node[93]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[93], VSI_NN_OP_CONV_RELU, 3, 1, 76);
    node[93]->nn_param.conv2d.ksize[0] = 1;
    node[93]->nn_param.conv2d.ksize[1] = 7;
    node[93]->nn_param.conv2d.weights = 192;
    node[93]->nn_param.conv2d.stride[0] = 1;
    node[93]->nn_param.conv2d.stride[1] = 1;
    node[93]->nn_param.conv2d.pad[0] = 0;
    node[93]->nn_param.conv2d.pad[1] = 0;
    node[93]->nn_param.conv2d.pad[2] = 3;
    node[93]->nn_param.conv2d.pad[3] = 3;
    node[93]->nn_param.conv2d.group = 1;
    node[93]->nn_param.conv2d.dilation[0] = 1;
    node[93]->nn_param.conv2d.dilation[1] = 1;
    node[93]->vx_param.has_relu = TRUE;
    node[93]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[93]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[93]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_74_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_69
      var       - node[94]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[8, 8, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[94], VSI_NN_OP_CONV_RELU, 3, 1, 69);
    node[94]->nn_param.conv2d.ksize[0] = 3;
    node[94]->nn_param.conv2d.ksize[1] = 3;
    node[94]->nn_param.conv2d.weights = 192;
    node[94]->nn_param.conv2d.stride[0] = 2;
    node[94]->nn_param.conv2d.stride[1] = 2;
    node[94]->nn_param.conv2d.pad[0] = 0;
    node[94]->nn_param.conv2d.pad[1] = 0;
    node[94]->nn_param.conv2d.pad[2] = 0;
    node[94]->nn_param.conv2d.pad[3] = 0;
    node[94]->nn_param.conv2d.group = 1;
    node[94]->nn_param.conv2d.dilation[0] = 1;
    node[94]->nn_param.conv2d.dilation[1] = 1;
    node[94]->vx_param.has_relu = TRUE;
    node[94]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[94]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[94]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7a/concat_67
      var       - node[95]
      name      - InceptionV3/InceptionV3/Mixed_7a/concat
      operation - concat
      in_shape  - [[8, 8, 320, 1]]
                  [[8, 8, 192, 1]]
                  [[8, 8, 768, 1]]
      out_shape - [[8, 8, 1280, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[95], VSI_NN_OP_CONCAT, 3, 1, 67);
    node[95]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_47_InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_37
      var       - node[96]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1280, 1]]
      out_shape - [[8, 8, 320, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[96], VSI_NN_OP_CONV_RELU, 3, 1, 37);
    node[96]->nn_param.conv2d.ksize[0] = 1;
    node[96]->nn_param.conv2d.ksize[1] = 1;
    node[96]->nn_param.conv2d.weights = 320;
    node[96]->nn_param.conv2d.stride[0] = 1;
    node[96]->nn_param.conv2d.stride[1] = 1;
    node[96]->nn_param.conv2d.pad[0] = 0;
    node[96]->nn_param.conv2d.pad[1] = 0;
    node[96]->nn_param.conv2d.pad[2] = 0;
    node[96]->nn_param.conv2d.pad[3] = 0;
    node[96]->nn_param.conv2d.group = 1;
    node[96]->nn_param.conv2d.dilation[0] = 1;
    node[96]->nn_param.conv2d.dilation[1] = 1;
    node[96]->vx_param.has_relu = TRUE;
    node[96]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[96]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[96]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_62_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_58
      var       - node[97]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1280, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[97], VSI_NN_OP_CONV_RELU, 3, 1, 58);
    node[97]->nn_param.conv2d.ksize[0] = 1;
    node[97]->nn_param.conv2d.ksize[1] = 1;
    node[97]->nn_param.conv2d.weights = 384;
    node[97]->nn_param.conv2d.stride[0] = 1;
    node[97]->nn_param.conv2d.stride[1] = 1;
    node[97]->nn_param.conv2d.pad[0] = 0;
    node[97]->nn_param.conv2d.pad[1] = 0;
    node[97]->nn_param.conv2d.pad[2] = 0;
    node[97]->nn_param.conv2d.pad[3] = 0;
    node[97]->nn_param.conv2d.group = 1;
    node[97]->nn_param.conv2d.dilation[0] = 1;
    node[97]->nn_param.conv2d.dilation[1] = 1;
    node[97]->vx_param.has_relu = TRUE;
    node[97]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[97]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[97]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_66_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_64
      var       - node[98]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1280, 1]]
      out_shape - [[8, 8, 448, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[98], VSI_NN_OP_CONV_RELU, 3, 1, 64);
    node[98]->nn_param.conv2d.ksize[0] = 1;
    node[98]->nn_param.conv2d.ksize[1] = 1;
    node[98]->nn_param.conv2d.weights = 448;
    node[98]->nn_param.conv2d.stride[0] = 1;
    node[98]->nn_param.conv2d.stride[1] = 1;
    node[98]->nn_param.conv2d.pad[0] = 0;
    node[98]->nn_param.conv2d.pad[1] = 0;
    node[98]->nn_param.conv2d.pad[2] = 0;
    node[98]->nn_param.conv2d.pad[3] = 0;
    node[98]->nn_param.conv2d.group = 1;
    node[98]->nn_param.conv2d.dilation[0] = 1;
    node[98]->nn_param.conv2d.dilation[1] = 1;
    node[98]->vx_param.has_relu = TRUE;
    node[98]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[98]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[98]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_57_conv_316
      var       - node[99]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1280, 1]]
      out_shape - [[8, 8, 1280, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[99], VSI_NN_OP_CONV_RELU, 3, 1, 316);
    node[99]->nn_param.conv2d.ksize[0] = 3;
    node[99]->nn_param.conv2d.ksize[1] = 3;
    node[99]->nn_param.conv2d.weights = 1280;
    node[99]->nn_param.conv2d.stride[0] = 1;
    node[99]->nn_param.conv2d.stride[1] = 1;
    node[99]->nn_param.conv2d.pad[0] = 1;
    node[99]->nn_param.conv2d.pad[1] = 1;
    node[99]->nn_param.conv2d.pad[2] = 1;
    node[99]->nn_param.conv2d.pad[3] = 1;
    node[99]->nn_param.conv2d.group = 1;
    node[99]->nn_param.conv2d.dilation[0] = 1;
    node[99]->nn_param.conv2d.dilation[1] = 1;
    node[99]->vx_param.has_relu = FALSE;
    node[99]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[99]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[99]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_53_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_42
      var       - node[100]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[100], VSI_NN_OP_CONV_RELU, 3, 1, 42);
    node[100]->nn_param.conv2d.ksize[0] = 3;
    node[100]->nn_param.conv2d.ksize[1] = 3;
    node[100]->nn_param.conv2d.weights = 384;
    node[100]->nn_param.conv2d.stride[0] = 1;
    node[100]->nn_param.conv2d.stride[1] = 1;
    node[100]->nn_param.conv2d.pad[0] = 1;
    node[100]->nn_param.conv2d.pad[1] = 1;
    node[100]->nn_param.conv2d.pad[2] = 1;
    node[100]->nn_param.conv2d.pad[3] = 1;
    node[100]->nn_param.conv2d.group = 1;
    node[100]->nn_param.conv2d.dilation[0] = 1;
    node[100]->nn_param.conv2d.dilation[1] = 1;
    node[100]->vx_param.has_relu = TRUE;
    node[100]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[100]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[100]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Conv2D_54_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Relu_43
      var       - node[101]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[101], VSI_NN_OP_CONV_RELU, 3, 1, 43);
    node[101]->nn_param.conv2d.ksize[0] = 1;
    node[101]->nn_param.conv2d.ksize[1] = 3;
    node[101]->nn_param.conv2d.weights = 384;
    node[101]->nn_param.conv2d.stride[0] = 1;
    node[101]->nn_param.conv2d.stride[1] = 1;
    node[101]->nn_param.conv2d.pad[0] = 0;
    node[101]->nn_param.conv2d.pad[1] = 0;
    node[101]->nn_param.conv2d.pad[2] = 1;
    node[101]->nn_param.conv2d.pad[3] = 1;
    node[101]->nn_param.conv2d.group = 1;
    node[101]->nn_param.conv2d.dilation[0] = 1;
    node[101]->nn_param.conv2d.dilation[1] = 1;
    node[101]->vx_param.has_relu = TRUE;
    node[101]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[101]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[101]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Conv2D_63_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Relu_59
      var       - node[102]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 448, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[102], VSI_NN_OP_CONV_RELU, 3, 1, 59);
    node[102]->nn_param.conv2d.ksize[0] = 3;
    node[102]->nn_param.conv2d.ksize[1] = 3;
    node[102]->nn_param.conv2d.weights = 384;
    node[102]->nn_param.conv2d.stride[0] = 1;
    node[102]->nn_param.conv2d.stride[1] = 1;
    node[102]->nn_param.conv2d.pad[0] = 1;
    node[102]->nn_param.conv2d.pad[1] = 1;
    node[102]->nn_param.conv2d.pad[2] = 1;
    node[102]->nn_param.conv2d.pad[3] = 1;
    node[102]->nn_param.conv2d.group = 1;
    node[102]->nn_param.conv2d.dilation[0] = 1;
    node[102]->nn_param.conv2d.dilation[1] = 1;
    node[102]->vx_param.has_relu = TRUE;
    node[102]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[102]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[102]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_52_InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_40
      var       - node[103]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1280, 1]]
      out_shape - [[8, 8, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[103], VSI_NN_OP_CONV_RELU, 3, 1, 40);
    node[103]->nn_param.conv2d.ksize[0] = 1;
    node[103]->nn_param.conv2d.ksize[1] = 1;
    node[103]->nn_param.conv2d.weights = 192;
    node[103]->nn_param.conv2d.stride[0] = 1;
    node[103]->nn_param.conv2d.stride[1] = 1;
    node[103]->nn_param.conv2d.pad[0] = 0;
    node[103]->nn_param.conv2d.pad[1] = 0;
    node[103]->nn_param.conv2d.pad[2] = 0;
    node[103]->nn_param.conv2d.pad[3] = 0;
    node[103]->nn_param.conv2d.group = 1;
    node[103]->nn_param.conv2d.dilation[0] = 1;
    node[103]->nn_param.conv2d.dilation[1] = 1;
    node[103]->vx_param.has_relu = TRUE;
    node[103]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[103]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[103]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_1/concat_38
      var       - node[104]
      name      - InceptionV3/InceptionV3/Mixed_7b/Branch_1/concat
      operation - concat
      in_shape  - [[8, 8, 384, 1]]
                  [[8, 8, 384, 1]]
      out_shape - [[8, 8, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[104], VSI_NN_OP_CONCAT, 2, 1, 38);
    node[104]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_55_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_44
      var       - node[105]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[105], VSI_NN_OP_CONV_RELU, 3, 1, 44);
    node[105]->nn_param.conv2d.ksize[0] = 3;
    node[105]->nn_param.conv2d.ksize[1] = 3;
    node[105]->nn_param.conv2d.weights = 384;
    node[105]->nn_param.conv2d.stride[0] = 1;
    node[105]->nn_param.conv2d.stride[1] = 1;
    node[105]->nn_param.conv2d.pad[0] = 1;
    node[105]->nn_param.conv2d.pad[1] = 1;
    node[105]->nn_param.conv2d.pad[2] = 1;
    node[105]->nn_param.conv2d.pad[3] = 1;
    node[105]->nn_param.conv2d.group = 1;
    node[105]->nn_param.conv2d.dilation[0] = 1;
    node[105]->nn_param.conv2d.dilation[1] = 1;
    node[105]->vx_param.has_relu = TRUE;
    node[105]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[105]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[105]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Conv2D_56_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Relu_45
      var       - node[106]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[106], VSI_NN_OP_CONV_RELU, 3, 1, 45);
    node[106]->nn_param.conv2d.ksize[0] = 1;
    node[106]->nn_param.conv2d.ksize[1] = 3;
    node[106]->nn_param.conv2d.weights = 384;
    node[106]->nn_param.conv2d.stride[0] = 1;
    node[106]->nn_param.conv2d.stride[1] = 1;
    node[106]->nn_param.conv2d.pad[0] = 0;
    node[106]->nn_param.conv2d.pad[1] = 0;
    node[106]->nn_param.conv2d.pad[2] = 1;
    node[106]->nn_param.conv2d.pad[3] = 1;
    node[106]->nn_param.conv2d.group = 1;
    node[106]->nn_param.conv2d.dilation[0] = 1;
    node[106]->nn_param.conv2d.dilation[1] = 1;
    node[106]->vx_param.has_relu = TRUE;
    node[106]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[106]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[106]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/Branch_2/concat_39
      var       - node[107]
      name      - InceptionV3/InceptionV3/Mixed_7b/Branch_2/concat
      operation - concat
      in_shape  - [[8, 8, 384, 1]]
                  [[8, 8, 384, 1]]
      out_shape - [[8, 8, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[107], VSI_NN_OP_CONCAT, 2, 1, 39);
    node[107]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7b/concat_36
      var       - node[108]
      name      - InceptionV3/InceptionV3/Mixed_7b/concat
      operation - concat
      in_shape  - [[8, 8, 320, 1]]
                  [[8, 8, 768, 1]]
                  [[8, 8, 768, 1]]
                  [[8, 8, 192, 1]]
      out_shape - [[8, 8, 2048, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[108], VSI_NN_OP_CONCAT, 4, 1, 36);
    node[108]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_16_InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_6
      var       - node[109]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 2048, 1]]
      out_shape - [[8, 8, 320, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[109], VSI_NN_OP_CONV_RELU, 3, 1, 6);
    node[109]->nn_param.conv2d.ksize[0] = 1;
    node[109]->nn_param.conv2d.ksize[1] = 1;
    node[109]->nn_param.conv2d.weights = 320;
    node[109]->nn_param.conv2d.stride[0] = 1;
    node[109]->nn_param.conv2d.stride[1] = 1;
    node[109]->nn_param.conv2d.pad[0] = 0;
    node[109]->nn_param.conv2d.pad[1] = 0;
    node[109]->nn_param.conv2d.pad[2] = 0;
    node[109]->nn_param.conv2d.pad[3] = 0;
    node[109]->nn_param.conv2d.group = 1;
    node[109]->nn_param.conv2d.dilation[0] = 1;
    node[109]->nn_param.conv2d.dilation[1] = 1;
    node[109]->vx_param.has_relu = TRUE;
    node[109]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[109]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[109]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_31_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_27
      var       - node[110]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 2048, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[110], VSI_NN_OP_CONV_RELU, 3, 1, 27);
    node[110]->nn_param.conv2d.ksize[0] = 1;
    node[110]->nn_param.conv2d.ksize[1] = 1;
    node[110]->nn_param.conv2d.weights = 384;
    node[110]->nn_param.conv2d.stride[0] = 1;
    node[110]->nn_param.conv2d.stride[1] = 1;
    node[110]->nn_param.conv2d.pad[0] = 0;
    node[110]->nn_param.conv2d.pad[1] = 0;
    node[110]->nn_param.conv2d.pad[2] = 0;
    node[110]->nn_param.conv2d.pad[3] = 0;
    node[110]->nn_param.conv2d.group = 1;
    node[110]->nn_param.conv2d.dilation[0] = 1;
    node[110]->nn_param.conv2d.dilation[1] = 1;
    node[110]->vx_param.has_relu = TRUE;
    node[110]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[110]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[110]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_35_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_33
      var       - node[111]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 2048, 1]]
      out_shape - [[8, 8, 448, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[111], VSI_NN_OP_CONV_RELU, 3, 1, 33);
    node[111]->nn_param.conv2d.ksize[0] = 1;
    node[111]->nn_param.conv2d.ksize[1] = 1;
    node[111]->nn_param.conv2d.weights = 448;
    node[111]->nn_param.conv2d.stride[0] = 1;
    node[111]->nn_param.conv2d.stride[1] = 1;
    node[111]->nn_param.conv2d.pad[0] = 0;
    node[111]->nn_param.conv2d.pad[1] = 0;
    node[111]->nn_param.conv2d.pad[2] = 0;
    node[111]->nn_param.conv2d.pad[3] = 0;
    node[111]->nn_param.conv2d.group = 1;
    node[111]->nn_param.conv2d.dilation[0] = 1;
    node[111]->nn_param.conv2d.dilation[1] = 1;
    node[111]->vx_param.has_relu = TRUE;
    node[111]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[111]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[111]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/InceptionV3/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_26_conv_315
      var       - node[112]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 2048, 1]]
      out_shape - [[8, 8, 2048, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[112], VSI_NN_OP_CONV_RELU, 3, 1, 315);
    node[112]->nn_param.conv2d.ksize[0] = 3;
    node[112]->nn_param.conv2d.ksize[1] = 3;
    node[112]->nn_param.conv2d.weights = 2048;
    node[112]->nn_param.conv2d.stride[0] = 1;
    node[112]->nn_param.conv2d.stride[1] = 1;
    node[112]->nn_param.conv2d.pad[0] = 1;
    node[112]->nn_param.conv2d.pad[1] = 1;
    node[112]->nn_param.conv2d.pad[2] = 1;
    node[112]->nn_param.conv2d.pad[3] = 1;
    node[112]->nn_param.conv2d.group = 1;
    node[112]->nn_param.conv2d.dilation[0] = 1;
    node[112]->nn_param.conv2d.dilation[1] = 1;
    node[112]->vx_param.has_relu = FALSE;
    node[112]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[112]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[112]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_22_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_11
      var       - node[113]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[113], VSI_NN_OP_CONV_RELU, 3, 1, 11);
    node[113]->nn_param.conv2d.ksize[0] = 3;
    node[113]->nn_param.conv2d.ksize[1] = 3;
    node[113]->nn_param.conv2d.weights = 384;
    node[113]->nn_param.conv2d.stride[0] = 1;
    node[113]->nn_param.conv2d.stride[1] = 1;
    node[113]->nn_param.conv2d.pad[0] = 1;
    node[113]->nn_param.conv2d.pad[1] = 1;
    node[113]->nn_param.conv2d.pad[2] = 1;
    node[113]->nn_param.conv2d.pad[3] = 1;
    node[113]->nn_param.conv2d.group = 1;
    node[113]->nn_param.conv2d.dilation[0] = 1;
    node[113]->nn_param.conv2d.dilation[1] = 1;
    node[113]->vx_param.has_relu = TRUE;
    node[113]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[113]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[113]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_23_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_12
      var       - node[114]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[114], VSI_NN_OP_CONV_RELU, 3, 1, 12);
    node[114]->nn_param.conv2d.ksize[0] = 1;
    node[114]->nn_param.conv2d.ksize[1] = 3;
    node[114]->nn_param.conv2d.weights = 384;
    node[114]->nn_param.conv2d.stride[0] = 1;
    node[114]->nn_param.conv2d.stride[1] = 1;
    node[114]->nn_param.conv2d.pad[0] = 0;
    node[114]->nn_param.conv2d.pad[1] = 0;
    node[114]->nn_param.conv2d.pad[2] = 1;
    node[114]->nn_param.conv2d.pad[3] = 1;
    node[114]->nn_param.conv2d.group = 1;
    node[114]->nn_param.conv2d.dilation[0] = 1;
    node[114]->nn_param.conv2d.dilation[1] = 1;
    node[114]->vx_param.has_relu = TRUE;
    node[114]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[114]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[114]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Conv2D_32_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Relu_28
      var       - node[115]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 448, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[115], VSI_NN_OP_CONV_RELU, 3, 1, 28);
    node[115]->nn_param.conv2d.ksize[0] = 3;
    node[115]->nn_param.conv2d.ksize[1] = 3;
    node[115]->nn_param.conv2d.weights = 384;
    node[115]->nn_param.conv2d.stride[0] = 1;
    node[115]->nn_param.conv2d.stride[1] = 1;
    node[115]->nn_param.conv2d.pad[0] = 1;
    node[115]->nn_param.conv2d.pad[1] = 1;
    node[115]->nn_param.conv2d.pad[2] = 1;
    node[115]->nn_param.conv2d.pad[3] = 1;
    node[115]->nn_param.conv2d.group = 1;
    node[115]->nn_param.conv2d.dilation[0] = 1;
    node[115]->nn_param.conv2d.dilation[1] = 1;
    node[115]->vx_param.has_relu = TRUE;
    node[115]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[115]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[115]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_21_InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_9
      var       - node[116]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 2048, 1]]
      out_shape - [[8, 8, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[116], VSI_NN_OP_CONV_RELU, 3, 1, 9);
    node[116]->nn_param.conv2d.ksize[0] = 1;
    node[116]->nn_param.conv2d.ksize[1] = 1;
    node[116]->nn_param.conv2d.weights = 192;
    node[116]->nn_param.conv2d.stride[0] = 1;
    node[116]->nn_param.conv2d.stride[1] = 1;
    node[116]->nn_param.conv2d.pad[0] = 0;
    node[116]->nn_param.conv2d.pad[1] = 0;
    node[116]->nn_param.conv2d.pad[2] = 0;
    node[116]->nn_param.conv2d.pad[3] = 0;
    node[116]->nn_param.conv2d.group = 1;
    node[116]->nn_param.conv2d.dilation[0] = 1;
    node[116]->nn_param.conv2d.dilation[1] = 1;
    node[116]->vx_param.has_relu = TRUE;
    node[116]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[116]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[116]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_1/concat_7
      var       - node[117]
      name      - InceptionV3/InceptionV3/Mixed_7c/Branch_1/concat
      operation - concat
      in_shape  - [[8, 8, 384, 1]]
                  [[8, 8, 384, 1]]
      out_shape - [[8, 8, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[117], VSI_NN_OP_CONCAT, 2, 1, 7);
    node[117]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_24_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_13
      var       - node[118]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[118], VSI_NN_OP_CONV_RELU, 3, 1, 13);
    node[118]->nn_param.conv2d.ksize[0] = 3;
    node[118]->nn_param.conv2d.ksize[1] = 3;
    node[118]->nn_param.conv2d.weights = 384;
    node[118]->nn_param.conv2d.stride[0] = 1;
    node[118]->nn_param.conv2d.stride[1] = 1;
    node[118]->nn_param.conv2d.pad[0] = 1;
    node[118]->nn_param.conv2d.pad[1] = 1;
    node[118]->nn_param.conv2d.pad[2] = 1;
    node[118]->nn_param.conv2d.pad[3] = 1;
    node[118]->nn_param.conv2d.group = 1;
    node[118]->nn_param.conv2d.dilation[0] = 1;
    node[118]->nn_param.conv2d.dilation[1] = 1;
    node[118]->vx_param.has_relu = TRUE;
    node[118]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[118]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[118]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Conv2D_25_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Relu_14
      var       - node[119]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[119], VSI_NN_OP_CONV_RELU, 3, 1, 14);
    node[119]->nn_param.conv2d.ksize[0] = 1;
    node[119]->nn_param.conv2d.ksize[1] = 3;
    node[119]->nn_param.conv2d.weights = 384;
    node[119]->nn_param.conv2d.stride[0] = 1;
    node[119]->nn_param.conv2d.stride[1] = 1;
    node[119]->nn_param.conv2d.pad[0] = 0;
    node[119]->nn_param.conv2d.pad[1] = 0;
    node[119]->nn_param.conv2d.pad[2] = 1;
    node[119]->nn_param.conv2d.pad[3] = 1;
    node[119]->nn_param.conv2d.group = 1;
    node[119]->nn_param.conv2d.dilation[0] = 1;
    node[119]->nn_param.conv2d.dilation[1] = 1;
    node[119]->vx_param.has_relu = TRUE;
    node[119]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[119]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[119]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/Branch_2/concat_8
      var       - node[120]
      name      - InceptionV3/InceptionV3/Mixed_7c/Branch_2/concat
      operation - concat
      in_shape  - [[8, 8, 384, 1]]
                  [[8, 8, 384, 1]]
      out_shape - [[8, 8, 768, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[120], VSI_NN_OP_CONCAT, 2, 1, 8);
    node[120]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/InceptionV3/Mixed_7c/concat_5
      var       - node[121]
      name      - InceptionV3/InceptionV3/Mixed_7c/concat
      operation - concat
      in_shape  - [[8, 8, 320, 1]]
                  [[8, 8, 768, 1]]
                  [[8, 8, 768, 1]]
                  [[8, 8, 192, 1]]
      out_shape - [[8, 8, 2048, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[121], VSI_NN_OP_CONCAT, 4, 1, 5);
    node[121]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV3/Logits/AvgPool_1a_8x8/AvgPool_4
      var       - node[122]
      name      - InceptionV3/Logits/AvgPool_1a_8x8/AvgPool
      operation - pooling
      in_shape  - [[8, 8, 2048, 1]]
      out_shape - [[1, 1, 2048, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[122], VSI_NN_OP_POOL, 1, 1, 4);
    node[122]->nn_param.pool.ksize[0] = 8;
    node[122]->nn_param.pool.ksize[1] = 8;
    node[122]->nn_param.pool.stride[0] = 2;
    node[122]->nn_param.pool.stride[1] = 2;
    node[122]->nn_param.pool.pad[0] = 0;
    node[122]->nn_param.pool.pad[1] = 0;
    node[122]->nn_param.pool.pad[2] = 0;
    node[122]->nn_param.pool.pad[3] = 0;
    node[122]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[122]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[122]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3
      var       - node[123]
      name      - fullconnectrelu
      operation - fullconnectrelu
      in_shape  - [[1, 1, 2048, 1]]
      out_shape - [[1001, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[123], VSI_NN_OP_FCL_RELU, 3, 1, 3);
    node[123]->nn_param.fcl.weights = 1001;
    node[123]->vx_param.has_relu = FALSE;
    node[123]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[123]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[123]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3_reshape_10
      var       - node[124]
      name      - InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3_reshape
      operation - reshape
      in_shape  - [[1001, 1]]
      out_shape - [[1, 1, 1001, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[124], VSI_NN_OP_RESHAPE, 1, 1, 10);
    node[124]->nn_param.reshape.size = shape_1;
    node[124]->nn_param.reshape.dim_num = 4;

    /*-----------------------------------------
      lid       - permute_15
      var       - node[125]
      name      - permute
      operation - permute
      in_shape  - [[1, 1, 1001, 1]]
      out_shape - [[1001, 1, 1, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[125], VSI_NN_OP_PERMUTE, 1, 1, 15);
    node[125]->nn_param.permute.perm = perm_1;
    node[125]->nn_param.permute.dim_num = 4;

    /*-----------------------------------------
      lid       - InceptionV3/Logits/SpatialSqueeze_2
      var       - node[126]
      name      - InceptionV3/Logits/SpatialSqueeze
      operation - reshape
      in_shape  - [[1001, 1, 1, 1]]
      out_shape - [[1001, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[126], VSI_NN_OP_RESHAPE, 1, 1, 2);
    node[126]->nn_param.reshape.size = shape_2;
    node[126]->nn_param.reshape.dim_num = 2;


/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @input_1:out0 */
    attr.size[0] = 299;
    attr.size[1] = 299;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_INT8);

    /* @output_0:out0 */
    attr.size[0] = 1001;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_INT8);



    /* @InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D_314_InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu_312:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 3;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_INT8, 128, 864);

    /* @InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D_314_InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu_312:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_INT32, 0, 128);

    /* @InceptionV3/InceptionV3/Conv2d_2a_3x3/Conv2D_311_InceptionV3/InceptionV3/Conv2d_2a_3x3/Relu_309:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_INT8, 1120, 9216);

    /* @InceptionV3/InceptionV3/Conv2d_2a_3x3/Conv2D_311_InceptionV3/InceptionV3/Conv2d_2a_3x3/Relu_309:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_INT32, 992, 128);

    /* @InceptionV3/InceptionV3/Conv2d_2b_3x3/Conv2D_308_InceptionV3/InceptionV3/Conv2d_2b_3x3/Relu_306:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_INT8, 10592, 18432);

    /* @InceptionV3/InceptionV3/Conv2d_2b_3x3/Conv2D_308_InceptionV3/InceptionV3/Conv2d_2b_3x3/Relu_306:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_INT32, 10336, 256);

    /* @InceptionV3/InceptionV3/Conv2d_3b_1x1/Conv2D_304_InceptionV3/InceptionV3/Conv2d_3b_1x1/Relu_302:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 80;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_INT8, 29344, 5120);

    /* @InceptionV3/InceptionV3/Conv2d_3b_1x1/Conv2D_304_InceptionV3/InceptionV3/Conv2d_3b_1x1/Relu_302:bias */
    attr.size[0] = 80;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_INT32, 29024, 320);

    /* @InceptionV3/InceptionV3/Conv2d_4a_3x3/Conv2D_301_InceptionV3/InceptionV3/Conv2d_4a_3x3/Relu_299:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 80;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_INT8, 35232, 138240);

    /* @InceptionV3/InceptionV3/Conv2d_4a_3x3/Conv2D_301_InceptionV3/InceptionV3/Conv2d_4a_3x3/Relu_299:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_INT32, 34464, 768);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_284_InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_276:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 192;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_INT8, 173728, 12288);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_284_InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_276:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_INT32, 173472, 256);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_293_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_288:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 192;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_INT8, 186208, 9216);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_293_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_288:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_INT32, 186016, 192);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_297_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_295:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 192;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_INT8, 272736, 12288);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_297_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_295:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_INT32, 272480, 256);

    /* @trans_InceptionV3/InceptionV3/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_290_conv_323:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_INT8, 40842592, 331776);

    /* @trans_InceptionV3/InceptionV3/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_290_conv_323:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_INT32, 40841824, 768);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Conv2D_285_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Relu_277:weight */
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 48;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_INT8, 195680, 76800);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Conv2D_285_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Relu_277:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_INT32, 195424, 256);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_294_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_289:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_INT8, 285408, 55296);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_294_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_289:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_INT32, 285024, 384);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_287_InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_279:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 192;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_INT8, 424160, 6144);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_287_InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_279:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_INT32, 424032, 128);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_286_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_278:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_INT8, 341088, 82944);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_286_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_278:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_INT32, 340704, 384);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_261_InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_253:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_INT8, 430560, 16384);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_261_InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_253:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_INT32, 430304, 256);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Conv2D_270_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Relu_265:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_INT8, 447136, 12288);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Conv2D_270_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Relu_265:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_INT32, 446944, 192);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_274_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_272:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_INT8, 536736, 16384);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_274_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_272:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_INT32, 536480, 256);

    /* @trans_InceptionV3/InceptionV3/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_267_conv_322:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_INT8, 41175392, 589824);

    /* @trans_InceptionV3/InceptionV3/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_267_conv_322:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_INT32, 41174368, 1024);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Conv2D_262_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Relu_254:weight */
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 48;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_INT8, 459680, 76800);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Conv2D_262_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Relu_254:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_INT32, 459424, 256);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_271_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_266:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_INT8, 553504, 55296);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_271_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_266:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_INT32, 553120, 384);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_264_InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_256:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_INT8, 692384, 16384);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_264_InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_256:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_INT32, 692128, 256);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_263_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_255:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_INT8, 609184, 82944);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_263_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_255:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_INT32, 608800, 384);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_238_InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_230:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 288;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_INT8, 709024, 18432);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_238_InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_230:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_INT32, 708768, 256);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_247_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_242:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 288;
    attr.size[3] = 48;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_INT8, 727648, 13824);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_247_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_242:bias */
    attr.size[0] = 48;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_INT32, 727456, 192);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_251_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_249:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 288;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_INT8, 818784, 18432);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_251_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_249:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_INT32, 818528, 256);

    /* @trans_InceptionV3/InceptionV3/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_244_conv_321:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 288;
    attr.size[3] = 288;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_INT8, 41766368, 746496);

    /* @trans_InceptionV3/InceptionV3/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_244_conv_321:bias */
    attr.size[0] = 288;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_INT32, 41765216, 1152);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Conv2D_239_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Relu_231:weight */
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 48;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_INT8, 741728, 76800);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Conv2D_239_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Relu_231:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_INT32, 741472, 256);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_248_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_243:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[52], attr, VSI_NN_TYPE_INT8, 837600, 55296);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_248_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_243:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[53], attr, VSI_NN_TYPE_INT32, 837216, 384);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_241_InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_233:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 288;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[54], attr, VSI_NN_TYPE_INT8, 976480, 18432);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_241_InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_233:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[55], attr, VSI_NN_TYPE_INT32, 976224, 256);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_240_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_232:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[56], attr, VSI_NN_TYPE_INT8, 893280, 82944);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_240_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_232:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[57], attr, VSI_NN_TYPE_INT32, 892896, 384);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Conv2D_221_InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Relu_216:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 288;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[58], attr, VSI_NN_TYPE_INT8, 996448, 995328);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Conv2D_221_InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Relu_216:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[59], attr, VSI_NN_TYPE_INT32, 994912, 1536);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_228_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_226:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 288;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[60], attr, VSI_NN_TYPE_INT8, 1992032, 18432);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_228_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_226:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[61], attr, VSI_NN_TYPE_INT32, 1991776, 256);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_225_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_223:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[62], attr, VSI_NN_TYPE_INT8, 2010848, 55296);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_225_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_223:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[63], attr, VSI_NN_TYPE_INT32, 2010464, 384);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Conv2D_222_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Relu_217:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[64], attr, VSI_NN_TYPE_INT8, 2066528, 82944);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Conv2D_222_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Relu_217:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[65], attr, VSI_NN_TYPE_INT32, 2066144, 384);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_192_InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_184:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[66], attr, VSI_NN_TYPE_INT8, 2150240, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_192_InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_184:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[67], attr, VSI_NN_TYPE_INT32, 2149472, 768);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_207_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_203:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[68], attr, VSI_NN_TYPE_INT8, 2298208, 98304);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_207_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_203:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[69], attr, VSI_NN_TYPE_INT32, 2297696, 512);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_214_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_212:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[70], attr, VSI_NN_TYPE_INT8, 3373152, 98304);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_214_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_212:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[71], attr, VSI_NN_TYPE_INT32, 3372640, 512);

    /* @trans_InceptionV3/InceptionV3/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_198_conv_320:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 768;
    attr.size[3] = 768;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[72], attr, VSI_NN_TYPE_INT8, 42515936, 5308416);

    /* @trans_InceptionV3/InceptionV3/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_198_conv_320:bias */
    attr.size[0] = 768;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[73], attr, VSI_NN_TYPE_INT32, 42512864, 3072);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_201_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_196:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[74], attr, VSI_NN_TYPE_INT8, 2397024, 802816);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_201_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_196:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[75], attr, VSI_NN_TYPE_INT32, 2396512, 512);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_211_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_209:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[76], attr, VSI_NN_TYPE_INT8, 3471968, 114688);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_211_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_209:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[77], attr, VSI_NN_TYPE_INT32, 3471456, 512);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_195_InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_187:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[78], attr, VSI_NN_TYPE_INT8, 5710944, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_195_InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_187:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[79], attr, VSI_NN_TYPE_INT32, 5710176, 768);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_193_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_185:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 128;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[80], attr, VSI_NN_TYPE_INT8, 3200608, 172032);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_193_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_185:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[81], attr, VSI_NN_TYPE_INT32, 3199840, 768);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_208_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_204:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[82], attr, VSI_NN_TYPE_INT8, 3587168, 802816);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_208_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_204:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[83], attr, VSI_NN_TYPE_INT32, 3586656, 512);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_202_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_197:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[84], attr, VSI_NN_TYPE_INT8, 4390496, 114688);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_202_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_197:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[85], attr, VSI_NN_TYPE_INT32, 4389984, 512);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_194_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_186:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 128;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[86], attr, VSI_NN_TYPE_INT8, 4505952, 1204224);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_194_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_186:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[87], attr, VSI_NN_TYPE_INT32, 4505184, 768);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_160_InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_152:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[88], attr, VSI_NN_TYPE_INT8, 5859168, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_160_InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_152:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[89], attr, VSI_NN_TYPE_INT32, 5858400, 768);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_175_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_171:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[90], attr, VSI_NN_TYPE_INT8, 6007264, 122880);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_175_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_171:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[91], attr, VSI_NN_TYPE_INT32, 6006624, 640);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_182_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_180:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[92], attr, VSI_NN_TYPE_INT8, 7601632, 122880);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_182_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_180:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[93], attr, VSI_NN_TYPE_INT32, 7600992, 640);

    /* @trans_InceptionV3/InceptionV3/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_166_conv_319:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 768;
    attr.size[3] = 768;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[94], attr, VSI_NN_TYPE_INT8, 47827424, 5308416);

    /* @trans_InceptionV3/InceptionV3/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_166_conv_319:bias */
    attr.size[0] = 768;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[95], attr, VSI_NN_TYPE_INT32, 47824352, 3072);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_169_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_164:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[96], attr, VSI_NN_TYPE_INT8, 6130784, 1254400);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_169_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_164:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[97], attr, VSI_NN_TYPE_INT32, 6130144, 640);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_179_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_177:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[98], attr, VSI_NN_TYPE_INT8, 7725152, 179200);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_179_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_177:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[99], attr, VSI_NN_TYPE_INT32, 7724512, 640);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_163_InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_155:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[100], attr, VSI_NN_TYPE_INT8, 10846048, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_163_InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_155:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[101], attr, VSI_NN_TYPE_INT32, 10845280, 768);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_161_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_153:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[102], attr, VSI_NN_TYPE_INT8, 7385952, 215040);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_161_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_153:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[103], attr, VSI_NN_TYPE_INT32, 7385184, 768);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_176_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_172:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[104], attr, VSI_NN_TYPE_INT8, 7904992, 1254400);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_176_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_172:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[105], attr, VSI_NN_TYPE_INT32, 7904352, 640);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_170_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_165:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[106], attr, VSI_NN_TYPE_INT8, 9160032, 179200);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_170_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_165:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[107], attr, VSI_NN_TYPE_INT32, 9159392, 640);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_162_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_154:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[108], attr, VSI_NN_TYPE_INT8, 9340000, 1505280);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_162_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_154:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[109], attr, VSI_NN_TYPE_INT32, 9339232, 768);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_128_InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_120:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[110], attr, VSI_NN_TYPE_INT8, 10994272, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_128_InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_120:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[111], attr, VSI_NN_TYPE_INT32, 10993504, 768);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_143_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_139:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[112], attr, VSI_NN_TYPE_INT8, 11142368, 122880);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_143_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_139:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[113], attr, VSI_NN_TYPE_INT32, 11141728, 640);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_150_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_148:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[114], attr, VSI_NN_TYPE_INT8, 12736736, 122880);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_150_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_148:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[115], attr, VSI_NN_TYPE_INT32, 12736096, 640);

    /* @trans_InceptionV3/InceptionV3/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_134_conv_318:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 768;
    attr.size[3] = 768;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[116], attr, VSI_NN_TYPE_INT8, 53138912, 5308416);

    /* @trans_InceptionV3/InceptionV3/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_134_conv_318:bias */
    attr.size[0] = 768;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[117], attr, VSI_NN_TYPE_INT32, 53135840, 3072);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_137_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_132:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[118], attr, VSI_NN_TYPE_INT8, 11265888, 1254400);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_137_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_132:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[119], attr, VSI_NN_TYPE_INT32, 11265248, 640);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_147_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_145:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[120], attr, VSI_NN_TYPE_INT8, 12860256, 179200);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_147_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_145:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[121], attr, VSI_NN_TYPE_INT32, 12859616, 640);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_131_InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_123:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[122], attr, VSI_NN_TYPE_INT8, 15981152, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_131_InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_123:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[123], attr, VSI_NN_TYPE_INT32, 15980384, 768);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_129_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_121:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[124], attr, VSI_NN_TYPE_INT8, 12521056, 215040);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_129_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_121:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[125], attr, VSI_NN_TYPE_INT32, 12520288, 768);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_144_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_140:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[126], attr, VSI_NN_TYPE_INT8, 13040096, 1254400);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_144_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_140:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[127], attr, VSI_NN_TYPE_INT32, 13039456, 640);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_138_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_133:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 160;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[128], attr, VSI_NN_TYPE_INT8, 14295136, 179200);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_138_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_133:bias */
    attr.size[0] = 160;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[129], attr, VSI_NN_TYPE_INT32, 14294496, 640);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_130_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_122:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 160;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[130], attr, VSI_NN_TYPE_INT8, 14475104, 1505280);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_130_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_122:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[131], attr, VSI_NN_TYPE_INT32, 14474336, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_96_InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_88:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[132], attr, VSI_NN_TYPE_INT8, 16129376, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_96_InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_88:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[133], attr, VSI_NN_TYPE_INT32, 16128608, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_111_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_107:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[134], attr, VSI_NN_TYPE_INT8, 16277600, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_111_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_107:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[135], attr, VSI_NN_TYPE_INT32, 16276832, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_118_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_116:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[136], attr, VSI_NN_TYPE_INT8, 18491744, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_118_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_116:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[137], attr, VSI_NN_TYPE_INT32, 18490976, 768);

    /* @trans_InceptionV3/InceptionV3/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_102_conv_317:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 768;
    attr.size[3] = 768;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[138], attr, VSI_NN_TYPE_INT8, 58450400, 5308416);

    /* @trans_InceptionV3/InceptionV3/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_102_conv_317:bias */
    attr.size[0] = 768;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[139], attr, VSI_NN_TYPE_INT32, 58447328, 3072);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_105_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_100:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[140], attr, VSI_NN_TYPE_INT8, 16425824, 1806336);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_105_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_100:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[141], attr, VSI_NN_TYPE_INT32, 16425056, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_115_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_113:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[142], attr, VSI_NN_TYPE_INT8, 18639968, 258048);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_115_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_113:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[143], attr, VSI_NN_TYPE_INT32, 18639200, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_99_InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_91:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[144], attr, VSI_NN_TYPE_INT8, 22771808, 147456);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_99_InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_91:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[145], attr, VSI_NN_TYPE_INT32, 22771040, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_97_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_89:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[146], attr, VSI_NN_TYPE_INT8, 18232928, 258048);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_97_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_89:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[147], attr, VSI_NN_TYPE_INT32, 18232160, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_112_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_108:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[148], attr, VSI_NN_TYPE_INT8, 18898784, 1806336);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_112_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_108:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[149], attr, VSI_NN_TYPE_INT32, 18898016, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_106_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_101:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[150], attr, VSI_NN_TYPE_INT8, 20705888, 258048);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_106_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_101:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[151], attr, VSI_NN_TYPE_INT32, 20705120, 768);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_98_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_90:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[152], attr, VSI_NN_TYPE_INT8, 20964704, 1806336);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_98_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_90:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[153], attr, VSI_NN_TYPE_INT32, 20963936, 768);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_79_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_75:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[154], attr, VSI_NN_TYPE_INT8, 22920032, 147456);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_79_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_75:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[155], attr, VSI_NN_TYPE_INT32, 22919264, 768);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_86_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_84:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 768;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[156], attr, VSI_NN_TYPE_INT8, 23622496, 147456);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_86_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_84:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[157], attr, VSI_NN_TYPE_INT32, 23621728, 768);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_73_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_68:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 192;
    attr.size[3] = 320;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[158], attr, VSI_NN_TYPE_INT8, 23068768, 552960);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_73_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_68:bias */
    attr.size[0] = 320;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[159], attr, VSI_NN_TYPE_INT32, 23067488, 1280);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_83_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_81:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[160], attr, VSI_NN_TYPE_INT8, 23770720, 1806336);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_83_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_81:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[161], attr, VSI_NN_TYPE_INT32, 23769952, 768);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_80_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_76:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[162], attr, VSI_NN_TYPE_INT8, 25577824, 258048);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_80_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_76:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[163], attr, VSI_NN_TYPE_INT32, 25577056, 768);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_74_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_69:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[164], attr, VSI_NN_TYPE_INT8, 25836640, 331776);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_74_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_69:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[165], attr, VSI_NN_TYPE_INT32, 25835872, 768);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_47_InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_37:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1280;
    attr.size[3] = 320;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[166], attr, VSI_NN_TYPE_INT8, 26169696, 409600);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_47_InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_37:bias */
    attr.size[0] = 320;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[167], attr, VSI_NN_TYPE_INT32, 26168416, 1280);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_62_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_58:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1280;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[168], attr, VSI_NN_TYPE_INT8, 26580832, 491520);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_62_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_58:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[169], attr, VSI_NN_TYPE_INT32, 26579296, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_66_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_64:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1280;
    attr.size[3] = 448;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[170], attr, VSI_NN_TYPE_INT8, 28846688, 573440);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_66_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_64:bias */
    attr.size[0] = 448;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[171], attr, VSI_NN_TYPE_INT32, 28844896, 1792);

    /* @trans_InceptionV3/InceptionV3/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_57_conv_316:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1280;
    attr.size[3] = 1280;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[172], attr, VSI_NN_TYPE_INT8, 63763936, 14745600);

    /* @trans_InceptionV3/InceptionV3/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_57_conv_316:bias */
    attr.size[0] = 1280;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[173], attr, VSI_NN_TYPE_INT32, 63758816, 5120);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_53_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_42:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[174], attr, VSI_NN_TYPE_INT8, 27073888, 1327104);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_53_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_42:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[175], attr, VSI_NN_TYPE_INT32, 27072352, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Conv2D_54_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Relu_43:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[176], attr, VSI_NN_TYPE_INT8, 28402528, 442368);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Conv2D_54_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Relu_43:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[177], attr, VSI_NN_TYPE_INT32, 28400992, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Conv2D_63_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Relu_59:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 448;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[178], attr, VSI_NN_TYPE_INT8, 29421664, 1548288);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Conv2D_63_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Relu_59:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[179], attr, VSI_NN_TYPE_INT32, 29420128, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_52_InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_40:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1280;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[180], attr, VSI_NN_TYPE_INT8, 32743264, 245760);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_52_InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_40:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[181], attr, VSI_NN_TYPE_INT32, 32742496, 768);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_55_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_44:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[182], attr, VSI_NN_TYPE_INT8, 30971488, 1327104);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_55_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_44:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[183], attr, VSI_NN_TYPE_INT32, 30969952, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Conv2D_56_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Relu_45:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[184], attr, VSI_NN_TYPE_INT8, 32300128, 442368);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Conv2D_56_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Relu_45:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[185], attr, VSI_NN_TYPE_INT32, 32298592, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_16_InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_6:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 2048;
    attr.size[3] = 320;
    attr.dim_num = 4;
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[186], attr, VSI_NN_TYPE_INT8, 32990304, 655360);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_16_InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_6:bias */
    attr.size[0] = 320;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[187], attr, VSI_NN_TYPE_INT32, 32989024, 1280);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_31_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_27:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 2048;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[188], attr, VSI_NN_TYPE_INT8, 33647200, 786432);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_31_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_27:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[189], attr, VSI_NN_TYPE_INT32, 33645664, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_35_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_33:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 2048;
    attr.size[3] = 448;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[190], attr, VSI_NN_TYPE_INT8, 36207968, 917504);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_35_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_33:bias */
    attr.size[0] = 448;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[191], attr, VSI_NN_TYPE_INT32, 36206176, 1792);

    /* @trans_InceptionV3/InceptionV3/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_26_conv_315:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 2048;
    attr.size[3] = 2048;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[192], attr, VSI_NN_TYPE_INT8, 78517728, 37748736);

    /* @trans_InceptionV3/InceptionV3/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_26_conv_315:bias */
    attr.size[0] = 2048;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[193], attr, VSI_NN_TYPE_INT32, 78509536, 8192);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_22_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_11:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[194], attr, VSI_NN_TYPE_INT8, 34435168, 1327104);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_22_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_11:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[195], attr, VSI_NN_TYPE_INT32, 34433632, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_23_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_12:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[196], attr, VSI_NN_TYPE_INT8, 35763808, 442368);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_23_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_12:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[197], attr, VSI_NN_TYPE_INT32, 35762272, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Conv2D_32_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Relu_28:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 448;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[198], attr, VSI_NN_TYPE_INT8, 37127008, 1548288);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Conv2D_32_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Relu_28:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[199], attr, VSI_NN_TYPE_INT32, 37125472, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_21_InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_9:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 2048;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[200], attr, VSI_NN_TYPE_INT8, 40448608, 393216);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_21_InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_9:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[201], attr, VSI_NN_TYPE_INT32, 40447840, 768);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_24_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_13:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[202], attr, VSI_NN_TYPE_INT8, 38676832, 1327104);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_24_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_13:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[203], attr, VSI_NN_TYPE_INT32, 38675296, 1536);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Conv2D_25_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Relu_14:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[204], attr, VSI_NN_TYPE_INT8, 40005472, 442368);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Conv2D_25_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Relu_14:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[205], attr, VSI_NN_TYPE_INT32, 40003936, 1536);

    /* @trans_InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3:weight */
    attr.size[0] = 2048;
    attr.size[1] = 1001;
    attr.dim_num = 2;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[206], attr, VSI_NN_TYPE_INT8, 116270468, 2050048);

    /* @trans_InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3:bias */
    attr.size[0] = 1001;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[207], attr, VSI_NN_TYPE_INT32, 116266464, 4004);



    /* @InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D_314_InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu_312:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Conv2d_2a_3x3/Conv2D_311_InceptionV3/InceptionV3/Conv2d_2a_3x3/Relu_309:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Conv2d_2b_3x3/Conv2D_308_InceptionV3/InceptionV3/Conv2d_2b_3x3/Relu_306:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/MaxPool_3a_3x3/MaxPool_305:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Conv2d_3b_1x1/Conv2D_304_InceptionV3/InceptionV3/Conv2d_3b_1x1/Relu_302:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Conv2d_4a_3x3/Conv2D_301_InceptionV3/InceptionV3/Conv2d_4a_3x3/Relu_299:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/MaxPool_5a_3x3/MaxPool_298:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_284_InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_276:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_293_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_288:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_297_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_295:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_290_conv_323:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Conv2D_285_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Relu_277:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_294_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_289:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_287_InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_279:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_286_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_278:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5b/concat_275:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_261_InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_253:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Conv2D_270_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Relu_265:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_274_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_272:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_267_conv_322:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Conv2D_262_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Relu_254:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_271_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_266:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_264_InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_256:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_263_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_255:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5c/concat_252:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_238_InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_230:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_247_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_242:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_251_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_249:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_244_conv_321:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Conv2D_239_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Relu_231:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_248_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_243:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_241_InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_233:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_240_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_232:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[32]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_5d/concat_229:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[33]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_2/MaxPool_1a_3x3/MaxPool_218:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[34]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Conv2D_221_InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Relu_216:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[35]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_228_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_226:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[36]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_225_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_223:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[37]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Conv2D_222_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Relu_217:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[38]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6a/concat_215:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[39]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_192_InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_184:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[40]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_207_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_203:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[41]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_214_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_212:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[42]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_198_conv_320:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[43]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_201_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_196:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[44]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_211_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_209:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[45]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_195_InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_187:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[46]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_193_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_185:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[47]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_208_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_204:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[48]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_202_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_197:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[49]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_194_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_186:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[50]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6b/concat_183:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[51]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_160_InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_152:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[52]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_175_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_171:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[53]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_182_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_180:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[54]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_166_conv_319:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[55]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_169_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_164:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[56]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_179_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_177:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[57]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_163_InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_155:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[58]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_161_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_153:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[59]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_176_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_172:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[60]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_170_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_165:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[61]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_162_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_154:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[62]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6c/concat_151:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[63]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_128_InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_120:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[64]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_143_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_139:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[65]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_150_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_148:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[66]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_134_conv_318:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[67]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_137_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_132:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[68]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_147_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_145:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[69]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_131_InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_123:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[70]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_129_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_121:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[71]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_144_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_140:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[72]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_138_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_133:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[73]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_130_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_122:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[74]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6d/concat_119:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[75]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_96_InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_88:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[76]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_111_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_107:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[77]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_118_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_116:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[78]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_102_conv_317:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[79]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_105_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_100:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[80]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_115_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_113:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[81]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_99_InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_91:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[82]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_97_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_89:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[83]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_112_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_108:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[84]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_106_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_101:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[85]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_98_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_90:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[86]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_6e/concat_87:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[87]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_2/MaxPool_1a_3x3/MaxPool_70:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[88]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_79_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_75:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[89]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_86_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_84:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[90]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_73_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_68:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[91]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_83_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_81:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[92]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_80_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_76:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[93]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_74_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_69:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[94]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7a/concat_67:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[95]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_47_InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_37:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[96]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_62_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_58:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[97]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_66_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_64:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[98]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_57_conv_316:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[99]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_53_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_42:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[100]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Conv2D_54_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Relu_43:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[101]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Conv2D_63_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Relu_59:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[102]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_52_InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_40:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[103]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_1/concat_38:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[104]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_55_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_44:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[105]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Conv2D_56_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Relu_45:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[106]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/Branch_2/concat_39:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[107]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7b/concat_36:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[108]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_16_InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_6:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[109]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_31_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_27:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[110]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_35_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_33:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[111]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/InceptionV3/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_26_conv_315:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[112]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_22_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_11:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[113]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_23_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_12:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[114]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Conv2D_32_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Relu_28:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[115]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_21_InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_9:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[116]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_1/concat_7:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[117]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_24_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_13:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[118]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Conv2D_25_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Relu_14:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[119]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/Branch_2/concat_8:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[120]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/InceptionV3/Mixed_7c/concat_5:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[121]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/Logits/AvgPool_1a_8x8/AvgPool_4:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[122]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[123]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3_reshape_10:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[124]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @permute_15:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[125]->output.tensors[0], attr, VSI_NN_TYPE_INT8);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[0]->input.tensors[0] = norm_tensor[0];
    node[126]->output.tensors[0] = norm_tensor[1];

    /* InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D_314_InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu_312 */
    node[0]->input.tensors[1] = const_tensor[0]; /* data_weight */
    node[0]->input.tensors[2] = const_tensor[1]; /* data_bias */

    /* InceptionV3/InceptionV3/Conv2d_2a_3x3/Conv2D_311_InceptionV3/InceptionV3/Conv2d_2a_3x3/Relu_309 */
    node[1]->input.tensors[0] = node[0]->output.tensors[0];
    node[1]->input.tensors[1] = const_tensor[2]; /* data_weight */
    node[1]->input.tensors[2] = const_tensor[3]; /* data_bias */

    /* InceptionV3/InceptionV3/Conv2d_2b_3x3/Conv2D_308_InceptionV3/InceptionV3/Conv2d_2b_3x3/Relu_306 */
    node[2]->input.tensors[0] = node[1]->output.tensors[0];
    node[2]->input.tensors[1] = const_tensor[4]; /* data_weight */
    node[2]->input.tensors[2] = const_tensor[5]; /* data_bias */

    /* InceptionV3/InceptionV3/MaxPool_3a_3x3/MaxPool_305 */
    node[3]->input.tensors[0] = node[2]->output.tensors[0];

    /* InceptionV3/InceptionV3/Conv2d_3b_1x1/Conv2D_304_InceptionV3/InceptionV3/Conv2d_3b_1x1/Relu_302 */
    node[4]->input.tensors[0] = node[3]->output.tensors[0];
    node[4]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[4]->input.tensors[2] = const_tensor[7]; /* data_bias */

    /* InceptionV3/InceptionV3/Conv2d_4a_3x3/Conv2D_301_InceptionV3/InceptionV3/Conv2d_4a_3x3/Relu_299 */
    node[5]->input.tensors[0] = node[4]->output.tensors[0];
    node[5]->input.tensors[1] = const_tensor[8]; /* data_weight */
    node[5]->input.tensors[2] = const_tensor[9]; /* data_bias */

    /* InceptionV3/InceptionV3/MaxPool_5a_3x3/MaxPool_298 */
    node[6]->input.tensors[0] = node[5]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_284_InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_276 */
    node[7]->input.tensors[0] = node[6]->output.tensors[0];
    node[7]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[7]->input.tensors[2] = const_tensor[11]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_293_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_288 */
    node[8]->input.tensors[0] = node[6]->output.tensors[0];
    node[8]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[8]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_297_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_295 */
    node[9]->input.tensors[0] = node[6]->output.tensors[0];
    node[9]->input.tensors[1] = const_tensor[14]; /* data_weight */
    node[9]->input.tensors[2] = const_tensor[15]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_290_conv_323 */
    node[10]->input.tensors[0] = node[6]->output.tensors[0];
    node[10]->input.tensors[1] = const_tensor[16]; /* data_weight */
    node[10]->input.tensors[2] = const_tensor[17]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Conv2D_285_InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/Relu_277 */
    node[11]->input.tensors[0] = node[8]->output.tensors[0];
    node[11]->input.tensors[1] = const_tensor[18]; /* data_weight */
    node[11]->input.tensors[2] = const_tensor[19]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_294_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_289 */
    node[12]->input.tensors[0] = node[9]->output.tensors[0];
    node[12]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[12]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_287_InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_279 */
    node[13]->input.tensors[0] = node[10]->output.tensors[0];
    node[13]->input.tensors[1] = const_tensor[22]; /* data_weight */
    node[13]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_286_InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_278 */
    node[14]->input.tensors[0] = node[12]->output.tensors[0];
    node[14]->input.tensors[1] = const_tensor[24]; /* data_weight */
    node[14]->input.tensors[2] = const_tensor[25]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5b/concat_275 */
    node[15]->input.tensors[0] = node[7]->output.tensors[0];
    node[15]->input.tensors[1] = node[11]->output.tensors[0];
    node[15]->input.tensors[2] = node[14]->output.tensors[0];
    node[15]->input.tensors[3] = node[13]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_261_InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_253 */
    node[16]->input.tensors[0] = node[15]->output.tensors[0];
    node[16]->input.tensors[1] = const_tensor[26]; /* data_weight */
    node[16]->input.tensors[2] = const_tensor[27]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Conv2D_270_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/Relu_265 */
    node[17]->input.tensors[0] = node[15]->output.tensors[0];
    node[17]->input.tensors[1] = const_tensor[28]; /* data_weight */
    node[17]->input.tensors[2] = const_tensor[29]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_274_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_272 */
    node[18]->input.tensors[0] = node[15]->output.tensors[0];
    node[18]->input.tensors[1] = const_tensor[30]; /* data_weight */
    node[18]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_267_conv_322 */
    node[19]->input.tensors[0] = node[15]->output.tensors[0];
    node[19]->input.tensors[1] = const_tensor[32]; /* data_weight */
    node[19]->input.tensors[2] = const_tensor[33]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Conv2D_262_InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/Relu_254 */
    node[20]->input.tensors[0] = node[17]->output.tensors[0];
    node[20]->input.tensors[1] = const_tensor[34]; /* data_weight */
    node[20]->input.tensors[2] = const_tensor[35]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_271_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_266 */
    node[21]->input.tensors[0] = node[18]->output.tensors[0];
    node[21]->input.tensors[1] = const_tensor[36]; /* data_weight */
    node[21]->input.tensors[2] = const_tensor[37]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_264_InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_256 */
    node[22]->input.tensors[0] = node[19]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[38]; /* data_weight */
    node[22]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_263_InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_255 */
    node[23]->input.tensors[0] = node[21]->output.tensors[0];
    node[23]->input.tensors[1] = const_tensor[40]; /* data_weight */
    node[23]->input.tensors[2] = const_tensor[41]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5c/concat_252 */
    node[24]->input.tensors[0] = node[16]->output.tensors[0];
    node[24]->input.tensors[1] = node[20]->output.tensors[0];
    node[24]->input.tensors[2] = node[23]->output.tensors[0];
    node[24]->input.tensors[3] = node[22]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_238_InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_230 */
    node[25]->input.tensors[0] = node[24]->output.tensors[0];
    node[25]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[25]->input.tensors[2] = const_tensor[43]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_247_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_242 */
    node[26]->input.tensors[0] = node[24]->output.tensors[0];
    node[26]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[26]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_251_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_249 */
    node[27]->input.tensors[0] = node[24]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[46]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[47]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_244_conv_321 */
    node[28]->input.tensors[0] = node[24]->output.tensors[0];
    node[28]->input.tensors[1] = const_tensor[48]; /* data_weight */
    node[28]->input.tensors[2] = const_tensor[49]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Conv2D_239_InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/Relu_231 */
    node[29]->input.tensors[0] = node[26]->output.tensors[0];
    node[29]->input.tensors[1] = const_tensor[50]; /* data_weight */
    node[29]->input.tensors[2] = const_tensor[51]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_248_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_243 */
    node[30]->input.tensors[0] = node[27]->output.tensors[0];
    node[30]->input.tensors[1] = const_tensor[52]; /* data_weight */
    node[30]->input.tensors[2] = const_tensor[53]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_241_InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_233 */
    node[31]->input.tensors[0] = node[28]->output.tensors[0];
    node[31]->input.tensors[1] = const_tensor[54]; /* data_weight */
    node[31]->input.tensors[2] = const_tensor[55]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_240_InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_232 */
    node[32]->input.tensors[0] = node[30]->output.tensors[0];
    node[32]->input.tensors[1] = const_tensor[56]; /* data_weight */
    node[32]->input.tensors[2] = const_tensor[57]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_5d/concat_229 */
    node[33]->input.tensors[0] = node[25]->output.tensors[0];
    node[33]->input.tensors[1] = node[29]->output.tensors[0];
    node[33]->input.tensors[2] = node[32]->output.tensors[0];
    node[33]->input.tensors[3] = node[31]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_6a/Branch_2/MaxPool_1a_3x3/MaxPool_218 */
    node[34]->input.tensors[0] = node[33]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Conv2D_221_InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/Relu_216 */
    node[35]->input.tensors[0] = node[33]->output.tensors[0];
    node[35]->input.tensors[1] = const_tensor[58]; /* data_weight */
    node[35]->input.tensors[2] = const_tensor[59]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_228_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_226 */
    node[36]->input.tensors[0] = node[33]->output.tensors[0];
    node[36]->input.tensors[1] = const_tensor[60]; /* data_weight */
    node[36]->input.tensors[2] = const_tensor[61]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_225_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_223 */
    node[37]->input.tensors[0] = node[36]->output.tensors[0];
    node[37]->input.tensors[1] = const_tensor[62]; /* data_weight */
    node[37]->input.tensors[2] = const_tensor[63]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Conv2D_222_InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/Relu_217 */
    node[38]->input.tensors[0] = node[37]->output.tensors[0];
    node[38]->input.tensors[1] = const_tensor[64]; /* data_weight */
    node[38]->input.tensors[2] = const_tensor[65]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6a/concat_215 */
    node[39]->input.tensors[0] = node[35]->output.tensors[0];
    node[39]->input.tensors[1] = node[38]->output.tensors[0];
    node[39]->input.tensors[2] = node[34]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_192_InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_184 */
    node[40]->input.tensors[0] = node[39]->output.tensors[0];
    node[40]->input.tensors[1] = const_tensor[66]; /* data_weight */
    node[40]->input.tensors[2] = const_tensor[67]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_207_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_203 */
    node[41]->input.tensors[0] = node[39]->output.tensors[0];
    node[41]->input.tensors[1] = const_tensor[68]; /* data_weight */
    node[41]->input.tensors[2] = const_tensor[69]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_214_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_212 */
    node[42]->input.tensors[0] = node[39]->output.tensors[0];
    node[42]->input.tensors[1] = const_tensor[70]; /* data_weight */
    node[42]->input.tensors[2] = const_tensor[71]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_198_conv_320 */
    node[43]->input.tensors[0] = node[39]->output.tensors[0];
    node[43]->input.tensors[1] = const_tensor[72]; /* data_weight */
    node[43]->input.tensors[2] = const_tensor[73]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_201_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_196 */
    node[44]->input.tensors[0] = node[41]->output.tensors[0];
    node[44]->input.tensors[1] = const_tensor[74]; /* data_weight */
    node[44]->input.tensors[2] = const_tensor[75]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_211_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_209 */
    node[45]->input.tensors[0] = node[42]->output.tensors[0];
    node[45]->input.tensors[1] = const_tensor[76]; /* data_weight */
    node[45]->input.tensors[2] = const_tensor[77]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_195_InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_187 */
    node[46]->input.tensors[0] = node[43]->output.tensors[0];
    node[46]->input.tensors[1] = const_tensor[78]; /* data_weight */
    node[46]->input.tensors[2] = const_tensor[79]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_193_InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_185 */
    node[47]->input.tensors[0] = node[44]->output.tensors[0];
    node[47]->input.tensors[1] = const_tensor[80]; /* data_weight */
    node[47]->input.tensors[2] = const_tensor[81]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_208_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_204 */
    node[48]->input.tensors[0] = node[45]->output.tensors[0];
    node[48]->input.tensors[1] = const_tensor[82]; /* data_weight */
    node[48]->input.tensors[2] = const_tensor[83]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_202_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_197 */
    node[49]->input.tensors[0] = node[48]->output.tensors[0];
    node[49]->input.tensors[1] = const_tensor[84]; /* data_weight */
    node[49]->input.tensors[2] = const_tensor[85]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_194_InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_186 */
    node[50]->input.tensors[0] = node[49]->output.tensors[0];
    node[50]->input.tensors[1] = const_tensor[86]; /* data_weight */
    node[50]->input.tensors[2] = const_tensor[87]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6b/concat_183 */
    node[51]->input.tensors[0] = node[40]->output.tensors[0];
    node[51]->input.tensors[1] = node[47]->output.tensors[0];
    node[51]->input.tensors[2] = node[50]->output.tensors[0];
    node[51]->input.tensors[3] = node[46]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_160_InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_152 */
    node[52]->input.tensors[0] = node[51]->output.tensors[0];
    node[52]->input.tensors[1] = const_tensor[88]; /* data_weight */
    node[52]->input.tensors[2] = const_tensor[89]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_175_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_171 */
    node[53]->input.tensors[0] = node[51]->output.tensors[0];
    node[53]->input.tensors[1] = const_tensor[90]; /* data_weight */
    node[53]->input.tensors[2] = const_tensor[91]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_182_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_180 */
    node[54]->input.tensors[0] = node[51]->output.tensors[0];
    node[54]->input.tensors[1] = const_tensor[92]; /* data_weight */
    node[54]->input.tensors[2] = const_tensor[93]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_166_conv_319 */
    node[55]->input.tensors[0] = node[51]->output.tensors[0];
    node[55]->input.tensors[1] = const_tensor[94]; /* data_weight */
    node[55]->input.tensors[2] = const_tensor[95]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_169_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_164 */
    node[56]->input.tensors[0] = node[53]->output.tensors[0];
    node[56]->input.tensors[1] = const_tensor[96]; /* data_weight */
    node[56]->input.tensors[2] = const_tensor[97]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_179_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_177 */
    node[57]->input.tensors[0] = node[54]->output.tensors[0];
    node[57]->input.tensors[1] = const_tensor[98]; /* data_weight */
    node[57]->input.tensors[2] = const_tensor[99]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_163_InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_155 */
    node[58]->input.tensors[0] = node[55]->output.tensors[0];
    node[58]->input.tensors[1] = const_tensor[100]; /* data_weight */
    node[58]->input.tensors[2] = const_tensor[101]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_161_InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_153 */
    node[59]->input.tensors[0] = node[56]->output.tensors[0];
    node[59]->input.tensors[1] = const_tensor[102]; /* data_weight */
    node[59]->input.tensors[2] = const_tensor[103]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_176_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_172 */
    node[60]->input.tensors[0] = node[57]->output.tensors[0];
    node[60]->input.tensors[1] = const_tensor[104]; /* data_weight */
    node[60]->input.tensors[2] = const_tensor[105]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_170_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_165 */
    node[61]->input.tensors[0] = node[60]->output.tensors[0];
    node[61]->input.tensors[1] = const_tensor[106]; /* data_weight */
    node[61]->input.tensors[2] = const_tensor[107]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_162_InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_154 */
    node[62]->input.tensors[0] = node[61]->output.tensors[0];
    node[62]->input.tensors[1] = const_tensor[108]; /* data_weight */
    node[62]->input.tensors[2] = const_tensor[109]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6c/concat_151 */
    node[63]->input.tensors[0] = node[52]->output.tensors[0];
    node[63]->input.tensors[1] = node[59]->output.tensors[0];
    node[63]->input.tensors[2] = node[62]->output.tensors[0];
    node[63]->input.tensors[3] = node[58]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_128_InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_120 */
    node[64]->input.tensors[0] = node[63]->output.tensors[0];
    node[64]->input.tensors[1] = const_tensor[110]; /* data_weight */
    node[64]->input.tensors[2] = const_tensor[111]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_143_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_139 */
    node[65]->input.tensors[0] = node[63]->output.tensors[0];
    node[65]->input.tensors[1] = const_tensor[112]; /* data_weight */
    node[65]->input.tensors[2] = const_tensor[113]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_150_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_148 */
    node[66]->input.tensors[0] = node[63]->output.tensors[0];
    node[66]->input.tensors[1] = const_tensor[114]; /* data_weight */
    node[66]->input.tensors[2] = const_tensor[115]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_134_conv_318 */
    node[67]->input.tensors[0] = node[63]->output.tensors[0];
    node[67]->input.tensors[1] = const_tensor[116]; /* data_weight */
    node[67]->input.tensors[2] = const_tensor[117]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_137_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_132 */
    node[68]->input.tensors[0] = node[65]->output.tensors[0];
    node[68]->input.tensors[1] = const_tensor[118]; /* data_weight */
    node[68]->input.tensors[2] = const_tensor[119]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_147_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_145 */
    node[69]->input.tensors[0] = node[66]->output.tensors[0];
    node[69]->input.tensors[1] = const_tensor[120]; /* data_weight */
    node[69]->input.tensors[2] = const_tensor[121]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_131_InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_123 */
    node[70]->input.tensors[0] = node[67]->output.tensors[0];
    node[70]->input.tensors[1] = const_tensor[122]; /* data_weight */
    node[70]->input.tensors[2] = const_tensor[123]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_129_InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_121 */
    node[71]->input.tensors[0] = node[68]->output.tensors[0];
    node[71]->input.tensors[1] = const_tensor[124]; /* data_weight */
    node[71]->input.tensors[2] = const_tensor[125]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_144_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_140 */
    node[72]->input.tensors[0] = node[69]->output.tensors[0];
    node[72]->input.tensors[1] = const_tensor[126]; /* data_weight */
    node[72]->input.tensors[2] = const_tensor[127]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_138_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_133 */
    node[73]->input.tensors[0] = node[72]->output.tensors[0];
    node[73]->input.tensors[1] = const_tensor[128]; /* data_weight */
    node[73]->input.tensors[2] = const_tensor[129]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_130_InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_122 */
    node[74]->input.tensors[0] = node[73]->output.tensors[0];
    node[74]->input.tensors[1] = const_tensor[130]; /* data_weight */
    node[74]->input.tensors[2] = const_tensor[131]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6d/concat_119 */
    node[75]->input.tensors[0] = node[64]->output.tensors[0];
    node[75]->input.tensors[1] = node[71]->output.tensors[0];
    node[75]->input.tensors[2] = node[74]->output.tensors[0];
    node[75]->input.tensors[3] = node[70]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_96_InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_88 */
    node[76]->input.tensors[0] = node[75]->output.tensors[0];
    node[76]->input.tensors[1] = const_tensor[132]; /* data_weight */
    node[76]->input.tensors[2] = const_tensor[133]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_111_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_107 */
    node[77]->input.tensors[0] = node[75]->output.tensors[0];
    node[77]->input.tensors[1] = const_tensor[134]; /* data_weight */
    node[77]->input.tensors[2] = const_tensor[135]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_118_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_116 */
    node[78]->input.tensors[0] = node[75]->output.tensors[0];
    node[78]->input.tensors[1] = const_tensor[136]; /* data_weight */
    node[78]->input.tensors[2] = const_tensor[137]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_102_conv_317 */
    node[79]->input.tensors[0] = node[75]->output.tensors[0];
    node[79]->input.tensors[1] = const_tensor[138]; /* data_weight */
    node[79]->input.tensors[2] = const_tensor[139]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_105_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_100 */
    node[80]->input.tensors[0] = node[77]->output.tensors[0];
    node[80]->input.tensors[1] = const_tensor[140]; /* data_weight */
    node[80]->input.tensors[2] = const_tensor[141]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_115_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_113 */
    node[81]->input.tensors[0] = node[78]->output.tensors[0];
    node[81]->input.tensors[1] = const_tensor[142]; /* data_weight */
    node[81]->input.tensors[2] = const_tensor[143]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_99_InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_91 */
    node[82]->input.tensors[0] = node[79]->output.tensors[0];
    node[82]->input.tensors[1] = const_tensor[144]; /* data_weight */
    node[82]->input.tensors[2] = const_tensor[145]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_97_InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_89 */
    node[83]->input.tensors[0] = node[80]->output.tensors[0];
    node[83]->input.tensors[1] = const_tensor[146]; /* data_weight */
    node[83]->input.tensors[2] = const_tensor[147]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_112_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_108 */
    node[84]->input.tensors[0] = node[81]->output.tensors[0];
    node[84]->input.tensors[1] = const_tensor[148]; /* data_weight */
    node[84]->input.tensors[2] = const_tensor[149]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_106_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_101 */
    node[85]->input.tensors[0] = node[84]->output.tensors[0];
    node[85]->input.tensors[1] = const_tensor[150]; /* data_weight */
    node[85]->input.tensors[2] = const_tensor[151]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_98_InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_90 */
    node[86]->input.tensors[0] = node[85]->output.tensors[0];
    node[86]->input.tensors[1] = const_tensor[152]; /* data_weight */
    node[86]->input.tensors[2] = const_tensor[153]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_6e/concat_87 */
    node[87]->input.tensors[0] = node[76]->output.tensors[0];
    node[87]->input.tensors[1] = node[83]->output.tensors[0];
    node[87]->input.tensors[2] = node[86]->output.tensors[0];
    node[87]->input.tensors[3] = node[82]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_7a/Branch_2/MaxPool_1a_3x3/MaxPool_70 */
    node[88]->input.tensors[0] = node[87]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_79_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_75 */
    node[89]->input.tensors[0] = node[87]->output.tensors[0];
    node[89]->input.tensors[1] = const_tensor[154]; /* data_weight */
    node[89]->input.tensors[2] = const_tensor[155]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_86_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_84 */
    node[90]->input.tensors[0] = node[87]->output.tensors[0];
    node[90]->input.tensors[1] = const_tensor[156]; /* data_weight */
    node[90]->input.tensors[2] = const_tensor[157]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_73_InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_68 */
    node[91]->input.tensors[0] = node[89]->output.tensors[0];
    node[91]->input.tensors[1] = const_tensor[158]; /* data_weight */
    node[91]->input.tensors[2] = const_tensor[159]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_83_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_81 */
    node[92]->input.tensors[0] = node[90]->output.tensors[0];
    node[92]->input.tensors[1] = const_tensor[160]; /* data_weight */
    node[92]->input.tensors[2] = const_tensor[161]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_80_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_76 */
    node[93]->input.tensors[0] = node[92]->output.tensors[0];
    node[93]->input.tensors[1] = const_tensor[162]; /* data_weight */
    node[93]->input.tensors[2] = const_tensor[163]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_74_InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_69 */
    node[94]->input.tensors[0] = node[93]->output.tensors[0];
    node[94]->input.tensors[1] = const_tensor[164]; /* data_weight */
    node[94]->input.tensors[2] = const_tensor[165]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7a/concat_67 */
    node[95]->input.tensors[0] = node[91]->output.tensors[0];
    node[95]->input.tensors[1] = node[94]->output.tensors[0];
    node[95]->input.tensors[2] = node[88]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_47_InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_37 */
    node[96]->input.tensors[0] = node[95]->output.tensors[0];
    node[96]->input.tensors[1] = const_tensor[166]; /* data_weight */
    node[96]->input.tensors[2] = const_tensor[167]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_62_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_58 */
    node[97]->input.tensors[0] = node[95]->output.tensors[0];
    node[97]->input.tensors[1] = const_tensor[168]; /* data_weight */
    node[97]->input.tensors[2] = const_tensor[169]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_66_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_64 */
    node[98]->input.tensors[0] = node[95]->output.tensors[0];
    node[98]->input.tensors[1] = const_tensor[170]; /* data_weight */
    node[98]->input.tensors[2] = const_tensor[171]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_57_conv_316 */
    node[99]->input.tensors[0] = node[95]->output.tensors[0];
    node[99]->input.tensors[1] = const_tensor[172]; /* data_weight */
    node[99]->input.tensors[2] = const_tensor[173]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_53_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_42 */
    node[100]->input.tensors[0] = node[97]->output.tensors[0];
    node[100]->input.tensors[1] = const_tensor[174]; /* data_weight */
    node[100]->input.tensors[2] = const_tensor[175]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Conv2D_54_InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/Relu_43 */
    node[101]->input.tensors[0] = node[97]->output.tensors[0];
    node[101]->input.tensors[1] = const_tensor[176]; /* data_weight */
    node[101]->input.tensors[2] = const_tensor[177]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Conv2D_63_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/Relu_59 */
    node[102]->input.tensors[0] = node[98]->output.tensors[0];
    node[102]->input.tensors[1] = const_tensor[178]; /* data_weight */
    node[102]->input.tensors[2] = const_tensor[179]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_52_InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_40 */
    node[103]->input.tensors[0] = node[99]->output.tensors[0];
    node[103]->input.tensors[1] = const_tensor[180]; /* data_weight */
    node[103]->input.tensors[2] = const_tensor[181]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_1/concat_38 */
    node[104]->input.tensors[0] = node[100]->output.tensors[0];
    node[104]->input.tensors[1] = node[101]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_55_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_44 */
    node[105]->input.tensors[0] = node[102]->output.tensors[0];
    node[105]->input.tensors[1] = const_tensor[182]; /* data_weight */
    node[105]->input.tensors[2] = const_tensor[183]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Conv2D_56_InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/Relu_45 */
    node[106]->input.tensors[0] = node[102]->output.tensors[0];
    node[106]->input.tensors[1] = const_tensor[184]; /* data_weight */
    node[106]->input.tensors[2] = const_tensor[185]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7b/Branch_2/concat_39 */
    node[107]->input.tensors[0] = node[105]->output.tensors[0];
    node[107]->input.tensors[1] = node[106]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_7b/concat_36 */
    node[108]->input.tensors[0] = node[96]->output.tensors[0];
    node[108]->input.tensors[1] = node[104]->output.tensors[0];
    node[108]->input.tensors[2] = node[107]->output.tensors[0];
    node[108]->input.tensors[3] = node[103]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_16_InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_6 */
    node[109]->input.tensors[0] = node[108]->output.tensors[0];
    node[109]->input.tensors[1] = const_tensor[186]; /* data_weight */
    node[109]->input.tensors[2] = const_tensor[187]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_31_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_27 */
    node[110]->input.tensors[0] = node[108]->output.tensors[0];
    node[110]->input.tensors[1] = const_tensor[188]; /* data_weight */
    node[110]->input.tensors[2] = const_tensor[189]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_35_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_33 */
    node[111]->input.tensors[0] = node[108]->output.tensors[0];
    node[111]->input.tensors[1] = const_tensor[190]; /* data_weight */
    node[111]->input.tensors[2] = const_tensor[191]; /* data_bias */

    /* trans_InceptionV3/InceptionV3/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_26_conv_315 */
    node[112]->input.tensors[0] = node[108]->output.tensors[0];
    node[112]->input.tensors[1] = const_tensor[192]; /* data_weight */
    node[112]->input.tensors[2] = const_tensor[193]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_22_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_11 */
    node[113]->input.tensors[0] = node[110]->output.tensors[0];
    node[113]->input.tensors[1] = const_tensor[194]; /* data_weight */
    node[113]->input.tensors[2] = const_tensor[195]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_23_InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_12 */
    node[114]->input.tensors[0] = node[110]->output.tensors[0];
    node[114]->input.tensors[1] = const_tensor[196]; /* data_weight */
    node[114]->input.tensors[2] = const_tensor[197]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Conv2D_32_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/Relu_28 */
    node[115]->input.tensors[0] = node[111]->output.tensors[0];
    node[115]->input.tensors[1] = const_tensor[198]; /* data_weight */
    node[115]->input.tensors[2] = const_tensor[199]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_21_InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_9 */
    node[116]->input.tensors[0] = node[112]->output.tensors[0];
    node[116]->input.tensors[1] = const_tensor[200]; /* data_weight */
    node[116]->input.tensors[2] = const_tensor[201]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_1/concat_7 */
    node[117]->input.tensors[0] = node[113]->output.tensors[0];
    node[117]->input.tensors[1] = node[114]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_24_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_13 */
    node[118]->input.tensors[0] = node[115]->output.tensors[0];
    node[118]->input.tensors[1] = const_tensor[202]; /* data_weight */
    node[118]->input.tensors[2] = const_tensor[203]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Conv2D_25_InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/Relu_14 */
    node[119]->input.tensors[0] = node[115]->output.tensors[0];
    node[119]->input.tensors[1] = const_tensor[204]; /* data_weight */
    node[119]->input.tensors[2] = const_tensor[205]; /* data_bias */

    /* InceptionV3/InceptionV3/Mixed_7c/Branch_2/concat_8 */
    node[120]->input.tensors[0] = node[118]->output.tensors[0];
    node[120]->input.tensors[1] = node[119]->output.tensors[0];

    /* InceptionV3/InceptionV3/Mixed_7c/concat_5 */
    node[121]->input.tensors[0] = node[109]->output.tensors[0];
    node[121]->input.tensors[1] = node[117]->output.tensors[0];
    node[121]->input.tensors[2] = node[120]->output.tensors[0];
    node[121]->input.tensors[3] = node[116]->output.tensors[0];

    /* InceptionV3/Logits/AvgPool_1a_8x8/AvgPool_4 */
    node[122]->input.tensors[0] = node[121]->output.tensors[0];

    /* trans_InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3 */
    node[123]->input.tensors[0] = node[122]->output.tensors[0];
    node[123]->input.tensors[1] = const_tensor[206]; /* data_weight */
    node[123]->input.tensors[2] = const_tensor[207]; /* data_bias */

    /* InceptionV3/Logits/Conv2d_1c_1x1/BiasAdd_3_reshape_10 */
    node[124]->input.tensors[0] = node[123]->output.tensors[0];

    /* permute_15 */
    node[125]->input.tensors[0] = node[124]->output.tensors[0];

    /* InceptionV3/Logits/SpatialSqueeze_2 */
    node[126]->input.tensors[0] = node[125]->output.tensors[0];



    graph->input.tensors[0] = norm_tensor[0];
    graph->output.tensors[0] = norm_tensor[1];


    status = vsi_nn_SetupGraph( graph, FALSE );
    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vnn_ReleaseInceptionv3( graph, release_ctx );

    return NULL;
} /* vsi_nn_CreateInceptionv3() */

void vnn_ReleaseInceptionv3
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vsi_nn_ReleaseInceptionv3() */

