/****************************************************************************
*   Generated by ACUITY 3.11.0
*   Match ovxlib 1.0.8
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_inceptionv4.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        _node->uid = (uint32_t)_uid; \
        if( NULL == _node ) {\
            goto error;\
        }\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(uint32_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (194)
#define NET_NORM_TENSOR_NUM     (2)
#define NET_CONST_TENSOR_NUM    (328)
#define NET_VIRTUAL_TENSOR_NUM  (194)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM + 32)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static void load_hw_config
    (
    vsi_nn_context_t ctx
    )
{
    ctx->config.evis.ver = VSI_NN_HW_EVIS_2;
    strncpy(ctx->config.target_name, "VIP8000", VSI_NN_MAX_TARGET_NAME);
}

static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    int32_t ret;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = fseek(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    ret = fread(data, 1, sz, fp);
    VSILOGI("Read %d data.", ret);
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateInceptionv4
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx
    )
{
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;



    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
        load_hw_config(ctx);
    }
    else
    {
        ctx = in_ctx;
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphInputs( graph, NULL, 1 );
    vsi_nn_SetGraphOutputs( graph, NULL, 1 );

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Conv2d_1a_3x3/Conv2D_493_InceptionV4/InceptionV4/Conv2d_1a_3x3/Relu_491
      var       - node[0]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[299, 299, 3, 1]]
      out_shape - [[149, 149, 32, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_CONV_RELU, 3, 1, 491);
    node[0]->nn_param.conv2d.ksize[0] = 3;
    node[0]->nn_param.conv2d.ksize[1] = 3;
    node[0]->nn_param.conv2d.weights = 32;
    node[0]->nn_param.conv2d.stride[0] = 2;
    node[0]->nn_param.conv2d.stride[1] = 2;
    node[0]->nn_param.conv2d.pad[0] = 0;
    node[0]->nn_param.conv2d.pad[1] = 0;
    node[0]->nn_param.conv2d.pad[2] = 0;
    node[0]->nn_param.conv2d.pad[3] = 0;
    node[0]->nn_param.conv2d.group = 1;
    node[0]->nn_param.conv2d.dilation[0] = 1;
    node[0]->nn_param.conv2d.dilation[1] = 1;
    node[0]->vx_param.has_relu = TRUE;
    node[0]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[0]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[0]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Conv2d_2a_3x3/Conv2D_490_InceptionV4/InceptionV4/Conv2d_2a_3x3/Relu_488
      var       - node[1]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[149, 149, 32, 1]]
      out_shape - [[147, 147, 32, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_CONV_RELU, 3, 1, 488);
    node[1]->nn_param.conv2d.ksize[0] = 3;
    node[1]->nn_param.conv2d.ksize[1] = 3;
    node[1]->nn_param.conv2d.weights = 32;
    node[1]->nn_param.conv2d.stride[0] = 1;
    node[1]->nn_param.conv2d.stride[1] = 1;
    node[1]->nn_param.conv2d.pad[0] = 0;
    node[1]->nn_param.conv2d.pad[1] = 0;
    node[1]->nn_param.conv2d.pad[2] = 0;
    node[1]->nn_param.conv2d.pad[3] = 0;
    node[1]->nn_param.conv2d.group = 1;
    node[1]->nn_param.conv2d.dilation[0] = 1;
    node[1]->nn_param.conv2d.dilation[1] = 1;
    node[1]->vx_param.has_relu = TRUE;
    node[1]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[1]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[1]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Conv2d_2b_3x3/Conv2D_487_InceptionV4/InceptionV4/Conv2d_2b_3x3/Relu_485
      var       - node[2]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[147, 147, 32, 1]]
      out_shape - [[147, 147, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_CONV_RELU, 3, 1, 485);
    node[2]->nn_param.conv2d.ksize[0] = 3;
    node[2]->nn_param.conv2d.ksize[1] = 3;
    node[2]->nn_param.conv2d.weights = 64;
    node[2]->nn_param.conv2d.stride[0] = 1;
    node[2]->nn_param.conv2d.stride[1] = 1;
    node[2]->nn_param.conv2d.pad[0] = 1;
    node[2]->nn_param.conv2d.pad[1] = 1;
    node[2]->nn_param.conv2d.pad[2] = 1;
    node[2]->nn_param.conv2d.pad[3] = 1;
    node[2]->nn_param.conv2d.group = 1;
    node[2]->nn_param.conv2d.dilation[0] = 1;
    node[2]->nn_param.conv2d.dilation[1] = 1;
    node[2]->vx_param.has_relu = TRUE;
    node[2]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[2]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[2]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_3a/Branch_0/MaxPool_0a_3x3/MaxPool_481
      var       - node[3]
      name      - InceptionV4/InceptionV4/Mixed_3a/Branch_0/MaxPool_0a_3x3/MaxPool
      operation - pooling
      in_shape  - [[147, 147, 64, 1]]
      out_shape - [[73, 73, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_POOL, 1, 1, 481);
    node[3]->nn_param.pool.ksize[0] = 3;
    node[3]->nn_param.pool.ksize[1] = 3;
    node[3]->nn_param.pool.stride[0] = 2;
    node[3]->nn_param.pool.stride[1] = 2;
    node[3]->nn_param.pool.pad[0] = 0;
    node[3]->nn_param.pool.pad[1] = 0;
    node[3]->nn_param.pool.pad[2] = 0;
    node[3]->nn_param.pool.pad[3] = 0;
    node[3]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[3]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[3]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Conv2D_484_InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Relu_482
      var       - node[4]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[147, 147, 64, 1]]
      out_shape - [[73, 73, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_CONV_RELU, 3, 1, 482);
    node[4]->nn_param.conv2d.ksize[0] = 3;
    node[4]->nn_param.conv2d.ksize[1] = 3;
    node[4]->nn_param.conv2d.weights = 96;
    node[4]->nn_param.conv2d.stride[0] = 2;
    node[4]->nn_param.conv2d.stride[1] = 2;
    node[4]->nn_param.conv2d.pad[0] = 0;
    node[4]->nn_param.conv2d.pad[1] = 0;
    node[4]->nn_param.conv2d.pad[2] = 0;
    node[4]->nn_param.conv2d.pad[3] = 0;
    node[4]->nn_param.conv2d.group = 1;
    node[4]->nn_param.conv2d.dilation[0] = 1;
    node[4]->nn_param.conv2d.dilation[1] = 1;
    node[4]->vx_param.has_relu = TRUE;
    node[4]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[4]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[4]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_3a/concat_480
      var       - node[5]
      name      - InceptionV4/InceptionV4/Mixed_3a/concat
      operation - concat
      in_shape  - [[73, 73, 64, 1]]
                  [[73, 73, 96, 1]]
      out_shape - [[73, 73, 160, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_CONCAT, 2, 1, 480);
    node[5]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Conv2D_472_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Relu_468
      var       - node[6]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[73, 73, 160, 1]]
      out_shape - [[73, 73, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_CONV_RELU, 3, 1, 468);
    node[6]->nn_param.conv2d.ksize[0] = 1;
    node[6]->nn_param.conv2d.ksize[1] = 1;
    node[6]->nn_param.conv2d.weights = 64;
    node[6]->nn_param.conv2d.stride[0] = 1;
    node[6]->nn_param.conv2d.stride[1] = 1;
    node[6]->nn_param.conv2d.pad[0] = 0;
    node[6]->nn_param.conv2d.pad[1] = 0;
    node[6]->nn_param.conv2d.pad[2] = 0;
    node[6]->nn_param.conv2d.pad[3] = 0;
    node[6]->nn_param.conv2d.group = 1;
    node[6]->nn_param.conv2d.dilation[0] = 1;
    node[6]->nn_param.conv2d.dilation[1] = 1;
    node[6]->vx_param.has_relu = TRUE;
    node[6]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[6]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[6]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Conv2D_479_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Relu_477
      var       - node[7]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[73, 73, 160, 1]]
      out_shape - [[73, 73, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_CONV_RELU, 3, 1, 477);
    node[7]->nn_param.conv2d.ksize[0] = 1;
    node[7]->nn_param.conv2d.ksize[1] = 1;
    node[7]->nn_param.conv2d.weights = 64;
    node[7]->nn_param.conv2d.stride[0] = 1;
    node[7]->nn_param.conv2d.stride[1] = 1;
    node[7]->nn_param.conv2d.pad[0] = 0;
    node[7]->nn_param.conv2d.pad[1] = 0;
    node[7]->nn_param.conv2d.pad[2] = 0;
    node[7]->nn_param.conv2d.pad[3] = 0;
    node[7]->nn_param.conv2d.group = 1;
    node[7]->nn_param.conv2d.dilation[0] = 1;
    node[7]->nn_param.conv2d.dilation[1] = 1;
    node[7]->vx_param.has_relu = TRUE;
    node[7]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[7]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[7]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Conv2D_466_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Relu_462
      var       - node[8]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[73, 73, 64, 1]]
      out_shape - [[71, 71, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_CONV_RELU, 3, 1, 462);
    node[8]->nn_param.conv2d.ksize[0] = 3;
    node[8]->nn_param.conv2d.ksize[1] = 3;
    node[8]->nn_param.conv2d.weights = 96;
    node[8]->nn_param.conv2d.stride[0] = 1;
    node[8]->nn_param.conv2d.stride[1] = 1;
    node[8]->nn_param.conv2d.pad[0] = 0;
    node[8]->nn_param.conv2d.pad[1] = 0;
    node[8]->nn_param.conv2d.pad[2] = 0;
    node[8]->nn_param.conv2d.pad[3] = 0;
    node[8]->nn_param.conv2d.group = 1;
    node[8]->nn_param.conv2d.dilation[0] = 1;
    node[8]->nn_param.conv2d.dilation[1] = 1;
    node[8]->vx_param.has_relu = TRUE;
    node[8]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[8]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[8]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Conv2D_476_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Relu_474
      var       - node[9]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[73, 73, 64, 1]]
      out_shape - [[73, 73, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_CONV_RELU, 3, 1, 474);
    node[9]->nn_param.conv2d.ksize[0] = 7;
    node[9]->nn_param.conv2d.ksize[1] = 7;
    node[9]->nn_param.conv2d.weights = 64;
    node[9]->nn_param.conv2d.stride[0] = 1;
    node[9]->nn_param.conv2d.stride[1] = 1;
    node[9]->nn_param.conv2d.pad[0] = 3;
    node[9]->nn_param.conv2d.pad[1] = 3;
    node[9]->nn_param.conv2d.pad[2] = 3;
    node[9]->nn_param.conv2d.pad[3] = 3;
    node[9]->nn_param.conv2d.group = 1;
    node[9]->nn_param.conv2d.dilation[0] = 1;
    node[9]->nn_param.conv2d.dilation[1] = 1;
    node[9]->vx_param.has_relu = TRUE;
    node[9]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[9]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[9]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Conv2D_473_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Relu_469
      var       - node[10]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[73, 73, 64, 1]]
      out_shape - [[73, 73, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_CONV_RELU, 3, 1, 469);
    node[10]->nn_param.conv2d.ksize[0] = 1;
    node[10]->nn_param.conv2d.ksize[1] = 7;
    node[10]->nn_param.conv2d.weights = 64;
    node[10]->nn_param.conv2d.stride[0] = 1;
    node[10]->nn_param.conv2d.stride[1] = 1;
    node[10]->nn_param.conv2d.pad[0] = 0;
    node[10]->nn_param.conv2d.pad[1] = 0;
    node[10]->nn_param.conv2d.pad[2] = 3;
    node[10]->nn_param.conv2d.pad[3] = 3;
    node[10]->nn_param.conv2d.group = 1;
    node[10]->nn_param.conv2d.dilation[0] = 1;
    node[10]->nn_param.conv2d.dilation[1] = 1;
    node[10]->vx_param.has_relu = TRUE;
    node[10]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[10]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[10]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Conv2D_467_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Relu_463
      var       - node[11]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[73, 73, 64, 1]]
      out_shape - [[71, 71, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_CONV_RELU, 3, 1, 463);
    node[11]->nn_param.conv2d.ksize[0] = 3;
    node[11]->nn_param.conv2d.ksize[1] = 3;
    node[11]->nn_param.conv2d.weights = 96;
    node[11]->nn_param.conv2d.stride[0] = 1;
    node[11]->nn_param.conv2d.stride[1] = 1;
    node[11]->nn_param.conv2d.pad[0] = 0;
    node[11]->nn_param.conv2d.pad[1] = 0;
    node[11]->nn_param.conv2d.pad[2] = 0;
    node[11]->nn_param.conv2d.pad[3] = 0;
    node[11]->nn_param.conv2d.group = 1;
    node[11]->nn_param.conv2d.dilation[0] = 1;
    node[11]->nn_param.conv2d.dilation[1] = 1;
    node[11]->vx_param.has_relu = TRUE;
    node[11]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[11]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[11]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_4a/concat_461
      var       - node[12]
      name      - InceptionV4/InceptionV4/Mixed_4a/concat
      operation - concat
      in_shape  - [[71, 71, 96, 1]]
                  [[71, 71, 96, 1]]
      out_shape - [[71, 71, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_CONCAT, 2, 1, 461);
    node[12]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5a/Branch_1/MaxPool_1a_3x3/MaxPool_458
      var       - node[13]
      name      - InceptionV4/InceptionV4/Mixed_5a/Branch_1/MaxPool_1a_3x3/MaxPool
      operation - pooling
      in_shape  - [[71, 71, 192, 1]]
      out_shape - [[35, 35, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_POOL, 1, 1, 458);
    node[13]->nn_param.pool.ksize[0] = 3;
    node[13]->nn_param.pool.ksize[1] = 3;
    node[13]->nn_param.pool.stride[0] = 2;
    node[13]->nn_param.pool.stride[1] = 2;
    node[13]->nn_param.pool.pad[0] = 0;
    node[13]->nn_param.pool.pad[1] = 0;
    node[13]->nn_param.pool.pad[2] = 0;
    node[13]->nn_param.pool.pad[3] = 0;
    node[13]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[13]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[13]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Conv2D_460_InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Relu_457
      var       - node[14]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[71, 71, 192, 1]]
      out_shape - [[35, 35, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_CONV_RELU, 3, 1, 457);
    node[14]->nn_param.conv2d.ksize[0] = 3;
    node[14]->nn_param.conv2d.ksize[1] = 3;
    node[14]->nn_param.conv2d.weights = 192;
    node[14]->nn_param.conv2d.stride[0] = 2;
    node[14]->nn_param.conv2d.stride[1] = 2;
    node[14]->nn_param.conv2d.pad[0] = 0;
    node[14]->nn_param.conv2d.pad[1] = 0;
    node[14]->nn_param.conv2d.pad[2] = 0;
    node[14]->nn_param.conv2d.pad[3] = 0;
    node[14]->nn_param.conv2d.group = 1;
    node[14]->nn_param.conv2d.dilation[0] = 1;
    node[14]->nn_param.conv2d.dilation[1] = 1;
    node[14]->vx_param.has_relu = TRUE;
    node[14]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[14]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[14]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5a/concat_456
      var       - node[15]
      name      - InceptionV4/InceptionV4/Mixed_5a/concat
      operation - concat
      in_shape  - [[35, 35, 192, 1]]
                  [[35, 35, 192, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_CONCAT, 2, 1, 456);
    node[15]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_442_InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_434
      var       - node[16]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_CONV_RELU, 3, 1, 434);
    node[16]->nn_param.conv2d.ksize[0] = 1;
    node[16]->nn_param.conv2d.ksize[1] = 1;
    node[16]->nn_param.conv2d.weights = 96;
    node[16]->nn_param.conv2d.stride[0] = 1;
    node[16]->nn_param.conv2d.stride[1] = 1;
    node[16]->nn_param.conv2d.pad[0] = 0;
    node[16]->nn_param.conv2d.pad[1] = 0;
    node[16]->nn_param.conv2d.pad[2] = 0;
    node[16]->nn_param.conv2d.pad[3] = 0;
    node[16]->nn_param.conv2d.group = 1;
    node[16]->nn_param.conv2d.dilation[0] = 1;
    node[16]->nn_param.conv2d.dilation[1] = 1;
    node[16]->vx_param.has_relu = TRUE;
    node[16]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[16]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[16]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_451_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_446
      var       - node[17]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_CONV_RELU, 3, 1, 446);
    node[17]->nn_param.conv2d.ksize[0] = 1;
    node[17]->nn_param.conv2d.ksize[1] = 1;
    node[17]->nn_param.conv2d.weights = 64;
    node[17]->nn_param.conv2d.stride[0] = 1;
    node[17]->nn_param.conv2d.stride[1] = 1;
    node[17]->nn_param.conv2d.pad[0] = 0;
    node[17]->nn_param.conv2d.pad[1] = 0;
    node[17]->nn_param.conv2d.pad[2] = 0;
    node[17]->nn_param.conv2d.pad[3] = 0;
    node[17]->nn_param.conv2d.group = 1;
    node[17]->nn_param.conv2d.dilation[0] = 1;
    node[17]->nn_param.conv2d.dilation[1] = 1;
    node[17]->vx_param.has_relu = TRUE;
    node[17]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[17]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[17]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_455_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_453
      var       - node[18]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_CONV_RELU, 3, 1, 453);
    node[18]->nn_param.conv2d.ksize[0] = 1;
    node[18]->nn_param.conv2d.ksize[1] = 1;
    node[18]->nn_param.conv2d.weights = 64;
    node[18]->nn_param.conv2d.stride[0] = 1;
    node[18]->nn_param.conv2d.stride[1] = 1;
    node[18]->nn_param.conv2d.pad[0] = 0;
    node[18]->nn_param.conv2d.pad[1] = 0;
    node[18]->nn_param.conv2d.pad[2] = 0;
    node[18]->nn_param.conv2d.pad[3] = 0;
    node[18]->nn_param.conv2d.group = 1;
    node[18]->nn_param.conv2d.dilation[0] = 1;
    node[18]->nn_param.conv2d.dilation[1] = 1;
    node[18]->vx_param.has_relu = TRUE;
    node[18]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[18]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[18]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_448_conv_507
      var       - node[19]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_CONV_RELU, 3, 1, 507);
    node[19]->nn_param.conv2d.ksize[0] = 3;
    node[19]->nn_param.conv2d.ksize[1] = 3;
    node[19]->nn_param.conv2d.weights = 384;
    node[19]->nn_param.conv2d.stride[0] = 1;
    node[19]->nn_param.conv2d.stride[1] = 1;
    node[19]->nn_param.conv2d.pad[0] = 1;
    node[19]->nn_param.conv2d.pad[1] = 1;
    node[19]->nn_param.conv2d.pad[2] = 1;
    node[19]->nn_param.conv2d.pad[3] = 1;
    node[19]->nn_param.conv2d.group = 1;
    node[19]->nn_param.conv2d.dilation[0] = 1;
    node[19]->nn_param.conv2d.dilation[1] = 1;
    node[19]->vx_param.has_relu = FALSE;
    node[19]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[19]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[19]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Conv2D_443_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Relu_435
      var       - node[20]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_CONV_RELU, 3, 1, 435);
    node[20]->nn_param.conv2d.ksize[0] = 3;
    node[20]->nn_param.conv2d.ksize[1] = 3;
    node[20]->nn_param.conv2d.weights = 96;
    node[20]->nn_param.conv2d.stride[0] = 1;
    node[20]->nn_param.conv2d.stride[1] = 1;
    node[20]->nn_param.conv2d.pad[0] = 1;
    node[20]->nn_param.conv2d.pad[1] = 1;
    node[20]->nn_param.conv2d.pad[2] = 1;
    node[20]->nn_param.conv2d.pad[3] = 1;
    node[20]->nn_param.conv2d.group = 1;
    node[20]->nn_param.conv2d.dilation[0] = 1;
    node[20]->nn_param.conv2d.dilation[1] = 1;
    node[20]->vx_param.has_relu = TRUE;
    node[20]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[20]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[20]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_452_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_447
      var       - node[21]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_CONV_RELU, 3, 1, 447);
    node[21]->nn_param.conv2d.ksize[0] = 3;
    node[21]->nn_param.conv2d.ksize[1] = 3;
    node[21]->nn_param.conv2d.weights = 96;
    node[21]->nn_param.conv2d.stride[0] = 1;
    node[21]->nn_param.conv2d.stride[1] = 1;
    node[21]->nn_param.conv2d.pad[0] = 1;
    node[21]->nn_param.conv2d.pad[1] = 1;
    node[21]->nn_param.conv2d.pad[2] = 1;
    node[21]->nn_param.conv2d.pad[3] = 1;
    node[21]->nn_param.conv2d.group = 1;
    node[21]->nn_param.conv2d.dilation[0] = 1;
    node[21]->nn_param.conv2d.dilation[1] = 1;
    node[21]->vx_param.has_relu = TRUE;
    node[21]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[21]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[21]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_445_InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_437
      var       - node[22]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_CONV_RELU, 3, 1, 437);
    node[22]->nn_param.conv2d.ksize[0] = 1;
    node[22]->nn_param.conv2d.ksize[1] = 1;
    node[22]->nn_param.conv2d.weights = 96;
    node[22]->nn_param.conv2d.stride[0] = 1;
    node[22]->nn_param.conv2d.stride[1] = 1;
    node[22]->nn_param.conv2d.pad[0] = 0;
    node[22]->nn_param.conv2d.pad[1] = 0;
    node[22]->nn_param.conv2d.pad[2] = 0;
    node[22]->nn_param.conv2d.pad[3] = 0;
    node[22]->nn_param.conv2d.group = 1;
    node[22]->nn_param.conv2d.dilation[0] = 1;
    node[22]->nn_param.conv2d.dilation[1] = 1;
    node[22]->vx_param.has_relu = TRUE;
    node[22]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[22]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[22]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_444_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_436
      var       - node[23]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 96, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_CONV_RELU, 3, 1, 436);
    node[23]->nn_param.conv2d.ksize[0] = 3;
    node[23]->nn_param.conv2d.ksize[1] = 3;
    node[23]->nn_param.conv2d.weights = 96;
    node[23]->nn_param.conv2d.stride[0] = 1;
    node[23]->nn_param.conv2d.stride[1] = 1;
    node[23]->nn_param.conv2d.pad[0] = 1;
    node[23]->nn_param.conv2d.pad[1] = 1;
    node[23]->nn_param.conv2d.pad[2] = 1;
    node[23]->nn_param.conv2d.pad[3] = 1;
    node[23]->nn_param.conv2d.group = 1;
    node[23]->nn_param.conv2d.dilation[0] = 1;
    node[23]->nn_param.conv2d.dilation[1] = 1;
    node[23]->vx_param.has_relu = TRUE;
    node[23]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[23]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[23]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5b/concat_433
      var       - node[24]
      name      - InceptionV4/InceptionV4/Mixed_5b/concat
      operation - concat
      in_shape  - [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_CONCAT, 4, 1, 433);
    node[24]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_419_InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_411
      var       - node[25]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_CONV_RELU, 3, 1, 411);
    node[25]->nn_param.conv2d.ksize[0] = 1;
    node[25]->nn_param.conv2d.ksize[1] = 1;
    node[25]->nn_param.conv2d.weights = 96;
    node[25]->nn_param.conv2d.stride[0] = 1;
    node[25]->nn_param.conv2d.stride[1] = 1;
    node[25]->nn_param.conv2d.pad[0] = 0;
    node[25]->nn_param.conv2d.pad[1] = 0;
    node[25]->nn_param.conv2d.pad[2] = 0;
    node[25]->nn_param.conv2d.pad[3] = 0;
    node[25]->nn_param.conv2d.group = 1;
    node[25]->nn_param.conv2d.dilation[0] = 1;
    node[25]->nn_param.conv2d.dilation[1] = 1;
    node[25]->vx_param.has_relu = TRUE;
    node[25]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[25]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[25]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Conv2D_428_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Relu_423
      var       - node[26]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_CONV_RELU, 3, 1, 423);
    node[26]->nn_param.conv2d.ksize[0] = 1;
    node[26]->nn_param.conv2d.ksize[1] = 1;
    node[26]->nn_param.conv2d.weights = 64;
    node[26]->nn_param.conv2d.stride[0] = 1;
    node[26]->nn_param.conv2d.stride[1] = 1;
    node[26]->nn_param.conv2d.pad[0] = 0;
    node[26]->nn_param.conv2d.pad[1] = 0;
    node[26]->nn_param.conv2d.pad[2] = 0;
    node[26]->nn_param.conv2d.pad[3] = 0;
    node[26]->nn_param.conv2d.group = 1;
    node[26]->nn_param.conv2d.dilation[0] = 1;
    node[26]->nn_param.conv2d.dilation[1] = 1;
    node[26]->vx_param.has_relu = TRUE;
    node[26]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[26]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[26]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_432_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_430
      var       - node[27]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_CONV_RELU, 3, 1, 430);
    node[27]->nn_param.conv2d.ksize[0] = 1;
    node[27]->nn_param.conv2d.ksize[1] = 1;
    node[27]->nn_param.conv2d.weights = 64;
    node[27]->nn_param.conv2d.stride[0] = 1;
    node[27]->nn_param.conv2d.stride[1] = 1;
    node[27]->nn_param.conv2d.pad[0] = 0;
    node[27]->nn_param.conv2d.pad[1] = 0;
    node[27]->nn_param.conv2d.pad[2] = 0;
    node[27]->nn_param.conv2d.pad[3] = 0;
    node[27]->nn_param.conv2d.group = 1;
    node[27]->nn_param.conv2d.dilation[0] = 1;
    node[27]->nn_param.conv2d.dilation[1] = 1;
    node[27]->vx_param.has_relu = TRUE;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_425_conv_506
      var       - node[28]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_CONV_RELU, 3, 1, 506);
    node[28]->nn_param.conv2d.ksize[0] = 3;
    node[28]->nn_param.conv2d.ksize[1] = 3;
    node[28]->nn_param.conv2d.weights = 384;
    node[28]->nn_param.conv2d.stride[0] = 1;
    node[28]->nn_param.conv2d.stride[1] = 1;
    node[28]->nn_param.conv2d.pad[0] = 1;
    node[28]->nn_param.conv2d.pad[1] = 1;
    node[28]->nn_param.conv2d.pad[2] = 1;
    node[28]->nn_param.conv2d.pad[3] = 1;
    node[28]->nn_param.conv2d.group = 1;
    node[28]->nn_param.conv2d.dilation[0] = 1;
    node[28]->nn_param.conv2d.dilation[1] = 1;
    node[28]->vx_param.has_relu = FALSE;
    node[28]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[28]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[28]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Conv2D_420_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Relu_412
      var       - node[29]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_CONV_RELU, 3, 1, 412);
    node[29]->nn_param.conv2d.ksize[0] = 3;
    node[29]->nn_param.conv2d.ksize[1] = 3;
    node[29]->nn_param.conv2d.weights = 96;
    node[29]->nn_param.conv2d.stride[0] = 1;
    node[29]->nn_param.conv2d.stride[1] = 1;
    node[29]->nn_param.conv2d.pad[0] = 1;
    node[29]->nn_param.conv2d.pad[1] = 1;
    node[29]->nn_param.conv2d.pad[2] = 1;
    node[29]->nn_param.conv2d.pad[3] = 1;
    node[29]->nn_param.conv2d.group = 1;
    node[29]->nn_param.conv2d.dilation[0] = 1;
    node[29]->nn_param.conv2d.dilation[1] = 1;
    node[29]->vx_param.has_relu = TRUE;
    node[29]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[29]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[29]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_429_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_424
      var       - node[30]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_CONV_RELU, 3, 1, 424);
    node[30]->nn_param.conv2d.ksize[0] = 3;
    node[30]->nn_param.conv2d.ksize[1] = 3;
    node[30]->nn_param.conv2d.weights = 96;
    node[30]->nn_param.conv2d.stride[0] = 1;
    node[30]->nn_param.conv2d.stride[1] = 1;
    node[30]->nn_param.conv2d.pad[0] = 1;
    node[30]->nn_param.conv2d.pad[1] = 1;
    node[30]->nn_param.conv2d.pad[2] = 1;
    node[30]->nn_param.conv2d.pad[3] = 1;
    node[30]->nn_param.conv2d.group = 1;
    node[30]->nn_param.conv2d.dilation[0] = 1;
    node[30]->nn_param.conv2d.dilation[1] = 1;
    node[30]->vx_param.has_relu = TRUE;
    node[30]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[30]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[30]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_422_InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_414
      var       - node[31]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_CONV_RELU, 3, 1, 414);
    node[31]->nn_param.conv2d.ksize[0] = 1;
    node[31]->nn_param.conv2d.ksize[1] = 1;
    node[31]->nn_param.conv2d.weights = 96;
    node[31]->nn_param.conv2d.stride[0] = 1;
    node[31]->nn_param.conv2d.stride[1] = 1;
    node[31]->nn_param.conv2d.pad[0] = 0;
    node[31]->nn_param.conv2d.pad[1] = 0;
    node[31]->nn_param.conv2d.pad[2] = 0;
    node[31]->nn_param.conv2d.pad[3] = 0;
    node[31]->nn_param.conv2d.group = 1;
    node[31]->nn_param.conv2d.dilation[0] = 1;
    node[31]->nn_param.conv2d.dilation[1] = 1;
    node[31]->vx_param.has_relu = TRUE;
    node[31]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[31]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[31]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_421_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_413
      var       - node[32]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 96, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_CONV_RELU, 3, 1, 413);
    node[32]->nn_param.conv2d.ksize[0] = 3;
    node[32]->nn_param.conv2d.ksize[1] = 3;
    node[32]->nn_param.conv2d.weights = 96;
    node[32]->nn_param.conv2d.stride[0] = 1;
    node[32]->nn_param.conv2d.stride[1] = 1;
    node[32]->nn_param.conv2d.pad[0] = 1;
    node[32]->nn_param.conv2d.pad[1] = 1;
    node[32]->nn_param.conv2d.pad[2] = 1;
    node[32]->nn_param.conv2d.pad[3] = 1;
    node[32]->nn_param.conv2d.group = 1;
    node[32]->nn_param.conv2d.dilation[0] = 1;
    node[32]->nn_param.conv2d.dilation[1] = 1;
    node[32]->vx_param.has_relu = TRUE;
    node[32]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[32]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[32]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5c/concat_410
      var       - node[33]
      name      - InceptionV4/InceptionV4/Mixed_5c/concat
      operation - concat
      in_shape  - [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[33], VSI_NN_OP_CONCAT, 4, 1, 410);
    node[33]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_396_InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_388
      var       - node[34]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[34], VSI_NN_OP_CONV_RELU, 3, 1, 388);
    node[34]->nn_param.conv2d.ksize[0] = 1;
    node[34]->nn_param.conv2d.ksize[1] = 1;
    node[34]->nn_param.conv2d.weights = 96;
    node[34]->nn_param.conv2d.stride[0] = 1;
    node[34]->nn_param.conv2d.stride[1] = 1;
    node[34]->nn_param.conv2d.pad[0] = 0;
    node[34]->nn_param.conv2d.pad[1] = 0;
    node[34]->nn_param.conv2d.pad[2] = 0;
    node[34]->nn_param.conv2d.pad[3] = 0;
    node[34]->nn_param.conv2d.group = 1;
    node[34]->nn_param.conv2d.dilation[0] = 1;
    node[34]->nn_param.conv2d.dilation[1] = 1;
    node[34]->vx_param.has_relu = TRUE;
    node[34]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[34]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[34]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_405_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_400
      var       - node[35]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[35], VSI_NN_OP_CONV_RELU, 3, 1, 400);
    node[35]->nn_param.conv2d.ksize[0] = 1;
    node[35]->nn_param.conv2d.ksize[1] = 1;
    node[35]->nn_param.conv2d.weights = 64;
    node[35]->nn_param.conv2d.stride[0] = 1;
    node[35]->nn_param.conv2d.stride[1] = 1;
    node[35]->nn_param.conv2d.pad[0] = 0;
    node[35]->nn_param.conv2d.pad[1] = 0;
    node[35]->nn_param.conv2d.pad[2] = 0;
    node[35]->nn_param.conv2d.pad[3] = 0;
    node[35]->nn_param.conv2d.group = 1;
    node[35]->nn_param.conv2d.dilation[0] = 1;
    node[35]->nn_param.conv2d.dilation[1] = 1;
    node[35]->vx_param.has_relu = TRUE;
    node[35]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[35]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[35]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_409_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_407
      var       - node[36]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[36], VSI_NN_OP_CONV_RELU, 3, 1, 407);
    node[36]->nn_param.conv2d.ksize[0] = 1;
    node[36]->nn_param.conv2d.ksize[1] = 1;
    node[36]->nn_param.conv2d.weights = 64;
    node[36]->nn_param.conv2d.stride[0] = 1;
    node[36]->nn_param.conv2d.stride[1] = 1;
    node[36]->nn_param.conv2d.pad[0] = 0;
    node[36]->nn_param.conv2d.pad[1] = 0;
    node[36]->nn_param.conv2d.pad[2] = 0;
    node[36]->nn_param.conv2d.pad[3] = 0;
    node[36]->nn_param.conv2d.group = 1;
    node[36]->nn_param.conv2d.dilation[0] = 1;
    node[36]->nn_param.conv2d.dilation[1] = 1;
    node[36]->vx_param.has_relu = TRUE;
    node[36]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[36]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[36]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_402_conv_505
      var       - node[37]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[37], VSI_NN_OP_CONV_RELU, 3, 1, 505);
    node[37]->nn_param.conv2d.ksize[0] = 3;
    node[37]->nn_param.conv2d.ksize[1] = 3;
    node[37]->nn_param.conv2d.weights = 384;
    node[37]->nn_param.conv2d.stride[0] = 1;
    node[37]->nn_param.conv2d.stride[1] = 1;
    node[37]->nn_param.conv2d.pad[0] = 1;
    node[37]->nn_param.conv2d.pad[1] = 1;
    node[37]->nn_param.conv2d.pad[2] = 1;
    node[37]->nn_param.conv2d.pad[3] = 1;
    node[37]->nn_param.conv2d.group = 1;
    node[37]->nn_param.conv2d.dilation[0] = 1;
    node[37]->nn_param.conv2d.dilation[1] = 1;
    node[37]->vx_param.has_relu = FALSE;
    node[37]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[37]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[37]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Conv2D_397_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Relu_389
      var       - node[38]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[38], VSI_NN_OP_CONV_RELU, 3, 1, 389);
    node[38]->nn_param.conv2d.ksize[0] = 3;
    node[38]->nn_param.conv2d.ksize[1] = 3;
    node[38]->nn_param.conv2d.weights = 96;
    node[38]->nn_param.conv2d.stride[0] = 1;
    node[38]->nn_param.conv2d.stride[1] = 1;
    node[38]->nn_param.conv2d.pad[0] = 1;
    node[38]->nn_param.conv2d.pad[1] = 1;
    node[38]->nn_param.conv2d.pad[2] = 1;
    node[38]->nn_param.conv2d.pad[3] = 1;
    node[38]->nn_param.conv2d.group = 1;
    node[38]->nn_param.conv2d.dilation[0] = 1;
    node[38]->nn_param.conv2d.dilation[1] = 1;
    node[38]->vx_param.has_relu = TRUE;
    node[38]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[38]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[38]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_406_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_401
      var       - node[39]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[39], VSI_NN_OP_CONV_RELU, 3, 1, 401);
    node[39]->nn_param.conv2d.ksize[0] = 3;
    node[39]->nn_param.conv2d.ksize[1] = 3;
    node[39]->nn_param.conv2d.weights = 96;
    node[39]->nn_param.conv2d.stride[0] = 1;
    node[39]->nn_param.conv2d.stride[1] = 1;
    node[39]->nn_param.conv2d.pad[0] = 1;
    node[39]->nn_param.conv2d.pad[1] = 1;
    node[39]->nn_param.conv2d.pad[2] = 1;
    node[39]->nn_param.conv2d.pad[3] = 1;
    node[39]->nn_param.conv2d.group = 1;
    node[39]->nn_param.conv2d.dilation[0] = 1;
    node[39]->nn_param.conv2d.dilation[1] = 1;
    node[39]->vx_param.has_relu = TRUE;
    node[39]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[39]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[39]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_399_InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_391
      var       - node[40]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[40], VSI_NN_OP_CONV_RELU, 3, 1, 391);
    node[40]->nn_param.conv2d.ksize[0] = 1;
    node[40]->nn_param.conv2d.ksize[1] = 1;
    node[40]->nn_param.conv2d.weights = 96;
    node[40]->nn_param.conv2d.stride[0] = 1;
    node[40]->nn_param.conv2d.stride[1] = 1;
    node[40]->nn_param.conv2d.pad[0] = 0;
    node[40]->nn_param.conv2d.pad[1] = 0;
    node[40]->nn_param.conv2d.pad[2] = 0;
    node[40]->nn_param.conv2d.pad[3] = 0;
    node[40]->nn_param.conv2d.group = 1;
    node[40]->nn_param.conv2d.dilation[0] = 1;
    node[40]->nn_param.conv2d.dilation[1] = 1;
    node[40]->vx_param.has_relu = TRUE;
    node[40]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[40]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[40]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_398_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_390
      var       - node[41]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 96, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[41], VSI_NN_OP_CONV_RELU, 3, 1, 390);
    node[41]->nn_param.conv2d.ksize[0] = 3;
    node[41]->nn_param.conv2d.ksize[1] = 3;
    node[41]->nn_param.conv2d.weights = 96;
    node[41]->nn_param.conv2d.stride[0] = 1;
    node[41]->nn_param.conv2d.stride[1] = 1;
    node[41]->nn_param.conv2d.pad[0] = 1;
    node[41]->nn_param.conv2d.pad[1] = 1;
    node[41]->nn_param.conv2d.pad[2] = 1;
    node[41]->nn_param.conv2d.pad[3] = 1;
    node[41]->nn_param.conv2d.group = 1;
    node[41]->nn_param.conv2d.dilation[0] = 1;
    node[41]->nn_param.conv2d.dilation[1] = 1;
    node[41]->vx_param.has_relu = TRUE;
    node[41]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[41]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[41]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5d/concat_387
      var       - node[42]
      name      - InceptionV4/InceptionV4/Mixed_5d/concat
      operation - concat
      in_shape  - [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[42], VSI_NN_OP_CONCAT, 4, 1, 387);
    node[42]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Conv2D_373_InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Relu_365
      var       - node[43]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[43], VSI_NN_OP_CONV_RELU, 3, 1, 365);
    node[43]->nn_param.conv2d.ksize[0] = 1;
    node[43]->nn_param.conv2d.ksize[1] = 1;
    node[43]->nn_param.conv2d.weights = 96;
    node[43]->nn_param.conv2d.stride[0] = 1;
    node[43]->nn_param.conv2d.stride[1] = 1;
    node[43]->nn_param.conv2d.pad[0] = 0;
    node[43]->nn_param.conv2d.pad[1] = 0;
    node[43]->nn_param.conv2d.pad[2] = 0;
    node[43]->nn_param.conv2d.pad[3] = 0;
    node[43]->nn_param.conv2d.group = 1;
    node[43]->nn_param.conv2d.dilation[0] = 1;
    node[43]->nn_param.conv2d.dilation[1] = 1;
    node[43]->vx_param.has_relu = TRUE;
    node[43]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[43]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[43]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Conv2D_382_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Relu_377
      var       - node[44]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[44], VSI_NN_OP_CONV_RELU, 3, 1, 377);
    node[44]->nn_param.conv2d.ksize[0] = 1;
    node[44]->nn_param.conv2d.ksize[1] = 1;
    node[44]->nn_param.conv2d.weights = 64;
    node[44]->nn_param.conv2d.stride[0] = 1;
    node[44]->nn_param.conv2d.stride[1] = 1;
    node[44]->nn_param.conv2d.pad[0] = 0;
    node[44]->nn_param.conv2d.pad[1] = 0;
    node[44]->nn_param.conv2d.pad[2] = 0;
    node[44]->nn_param.conv2d.pad[3] = 0;
    node[44]->nn_param.conv2d.group = 1;
    node[44]->nn_param.conv2d.dilation[0] = 1;
    node[44]->nn_param.conv2d.dilation[1] = 1;
    node[44]->vx_param.has_relu = TRUE;
    node[44]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[44]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[44]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Conv2D_386_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Relu_384
      var       - node[45]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 64, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[45], VSI_NN_OP_CONV_RELU, 3, 1, 384);
    node[45]->nn_param.conv2d.ksize[0] = 1;
    node[45]->nn_param.conv2d.ksize[1] = 1;
    node[45]->nn_param.conv2d.weights = 64;
    node[45]->nn_param.conv2d.stride[0] = 1;
    node[45]->nn_param.conv2d.stride[1] = 1;
    node[45]->nn_param.conv2d.pad[0] = 0;
    node[45]->nn_param.conv2d.pad[1] = 0;
    node[45]->nn_param.conv2d.pad[2] = 0;
    node[45]->nn_param.conv2d.pad[3] = 0;
    node[45]->nn_param.conv2d.group = 1;
    node[45]->nn_param.conv2d.dilation[0] = 1;
    node[45]->nn_param.conv2d.dilation[1] = 1;
    node[45]->vx_param.has_relu = TRUE;
    node[45]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[45]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[45]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_5e/Branch_3/AvgPool_0a_3x3/AvgPool_379_conv_504
      var       - node[46]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[46], VSI_NN_OP_CONV_RELU, 3, 1, 504);
    node[46]->nn_param.conv2d.ksize[0] = 3;
    node[46]->nn_param.conv2d.ksize[1] = 3;
    node[46]->nn_param.conv2d.weights = 384;
    node[46]->nn_param.conv2d.stride[0] = 1;
    node[46]->nn_param.conv2d.stride[1] = 1;
    node[46]->nn_param.conv2d.pad[0] = 1;
    node[46]->nn_param.conv2d.pad[1] = 1;
    node[46]->nn_param.conv2d.pad[2] = 1;
    node[46]->nn_param.conv2d.pad[3] = 1;
    node[46]->nn_param.conv2d.group = 1;
    node[46]->nn_param.conv2d.dilation[0] = 1;
    node[46]->nn_param.conv2d.dilation[1] = 1;
    node[46]->vx_param.has_relu = FALSE;
    node[46]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[46]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[46]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Conv2D_374_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Relu_366
      var       - node[47]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[47], VSI_NN_OP_CONV_RELU, 3, 1, 366);
    node[47]->nn_param.conv2d.ksize[0] = 3;
    node[47]->nn_param.conv2d.ksize[1] = 3;
    node[47]->nn_param.conv2d.weights = 96;
    node[47]->nn_param.conv2d.stride[0] = 1;
    node[47]->nn_param.conv2d.stride[1] = 1;
    node[47]->nn_param.conv2d.pad[0] = 1;
    node[47]->nn_param.conv2d.pad[1] = 1;
    node[47]->nn_param.conv2d.pad[2] = 1;
    node[47]->nn_param.conv2d.pad[3] = 1;
    node[47]->nn_param.conv2d.group = 1;
    node[47]->nn_param.conv2d.dilation[0] = 1;
    node[47]->nn_param.conv2d.dilation[1] = 1;
    node[47]->vx_param.has_relu = TRUE;
    node[47]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[47]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[47]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Conv2D_383_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Relu_378
      var       - node[48]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 64, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[48], VSI_NN_OP_CONV_RELU, 3, 1, 378);
    node[48]->nn_param.conv2d.ksize[0] = 3;
    node[48]->nn_param.conv2d.ksize[1] = 3;
    node[48]->nn_param.conv2d.weights = 96;
    node[48]->nn_param.conv2d.stride[0] = 1;
    node[48]->nn_param.conv2d.stride[1] = 1;
    node[48]->nn_param.conv2d.pad[0] = 1;
    node[48]->nn_param.conv2d.pad[1] = 1;
    node[48]->nn_param.conv2d.pad[2] = 1;
    node[48]->nn_param.conv2d.pad[3] = 1;
    node[48]->nn_param.conv2d.group = 1;
    node[48]->nn_param.conv2d.dilation[0] = 1;
    node[48]->nn_param.conv2d.dilation[1] = 1;
    node[48]->vx_param.has_relu = TRUE;
    node[48]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[48]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[48]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Conv2D_376_InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Relu_368
      var       - node[49]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[49], VSI_NN_OP_CONV_RELU, 3, 1, 368);
    node[49]->nn_param.conv2d.ksize[0] = 1;
    node[49]->nn_param.conv2d.ksize[1] = 1;
    node[49]->nn_param.conv2d.weights = 96;
    node[49]->nn_param.conv2d.stride[0] = 1;
    node[49]->nn_param.conv2d.stride[1] = 1;
    node[49]->nn_param.conv2d.pad[0] = 0;
    node[49]->nn_param.conv2d.pad[1] = 0;
    node[49]->nn_param.conv2d.pad[2] = 0;
    node[49]->nn_param.conv2d.pad[3] = 0;
    node[49]->nn_param.conv2d.group = 1;
    node[49]->nn_param.conv2d.dilation[0] = 1;
    node[49]->nn_param.conv2d.dilation[1] = 1;
    node[49]->vx_param.has_relu = TRUE;
    node[49]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[49]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[49]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Conv2D_375_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Relu_367
      var       - node[50]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 96, 1]]
      out_shape - [[35, 35, 96, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[50], VSI_NN_OP_CONV_RELU, 3, 1, 367);
    node[50]->nn_param.conv2d.ksize[0] = 3;
    node[50]->nn_param.conv2d.ksize[1] = 3;
    node[50]->nn_param.conv2d.weights = 96;
    node[50]->nn_param.conv2d.stride[0] = 1;
    node[50]->nn_param.conv2d.stride[1] = 1;
    node[50]->nn_param.conv2d.pad[0] = 1;
    node[50]->nn_param.conv2d.pad[1] = 1;
    node[50]->nn_param.conv2d.pad[2] = 1;
    node[50]->nn_param.conv2d.pad[3] = 1;
    node[50]->nn_param.conv2d.group = 1;
    node[50]->nn_param.conv2d.dilation[0] = 1;
    node[50]->nn_param.conv2d.dilation[1] = 1;
    node[50]->vx_param.has_relu = TRUE;
    node[50]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[50]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[50]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_5e/concat_364
      var       - node[51]
      name      - InceptionV4/InceptionV4/Mixed_5e/concat
      operation - concat
      in_shape  - [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
                  [[35, 35, 96, 1]]
      out_shape - [[35, 35, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[51], VSI_NN_OP_CONCAT, 4, 1, 364);
    node[51]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6a/Branch_2/MaxPool_1a_3x3/MaxPool_353
      var       - node[52]
      name      - InceptionV4/InceptionV4/Mixed_6a/Branch_2/MaxPool_1a_3x3/MaxPool
      operation - pooling
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[52], VSI_NN_OP_POOL, 1, 1, 353);
    node[52]->nn_param.pool.ksize[0] = 3;
    node[52]->nn_param.pool.ksize[1] = 3;
    node[52]->nn_param.pool.stride[0] = 2;
    node[52]->nn_param.pool.stride[1] = 2;
    node[52]->nn_param.pool.pad[0] = 0;
    node[52]->nn_param.pool.pad[1] = 0;
    node[52]->nn_param.pool.pad[2] = 0;
    node[52]->nn_param.pool.pad[3] = 0;
    node[52]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[52]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[52]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Conv2D_356_InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Relu_351
      var       - node[53]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[53], VSI_NN_OP_CONV_RELU, 3, 1, 351);
    node[53]->nn_param.conv2d.ksize[0] = 3;
    node[53]->nn_param.conv2d.ksize[1] = 3;
    node[53]->nn_param.conv2d.weights = 384;
    node[53]->nn_param.conv2d.stride[0] = 2;
    node[53]->nn_param.conv2d.stride[1] = 2;
    node[53]->nn_param.conv2d.pad[0] = 0;
    node[53]->nn_param.conv2d.pad[1] = 0;
    node[53]->nn_param.conv2d.pad[2] = 0;
    node[53]->nn_param.conv2d.pad[3] = 0;
    node[53]->nn_param.conv2d.group = 1;
    node[53]->nn_param.conv2d.dilation[0] = 1;
    node[53]->nn_param.conv2d.dilation[1] = 1;
    node[53]->vx_param.has_relu = TRUE;
    node[53]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[53]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[53]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_363_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_361
      var       - node[54]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 384, 1]]
      out_shape - [[35, 35, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[54], VSI_NN_OP_CONV_RELU, 3, 1, 361);
    node[54]->nn_param.conv2d.ksize[0] = 1;
    node[54]->nn_param.conv2d.ksize[1] = 1;
    node[54]->nn_param.conv2d.weights = 192;
    node[54]->nn_param.conv2d.stride[0] = 1;
    node[54]->nn_param.conv2d.stride[1] = 1;
    node[54]->nn_param.conv2d.pad[0] = 0;
    node[54]->nn_param.conv2d.pad[1] = 0;
    node[54]->nn_param.conv2d.pad[2] = 0;
    node[54]->nn_param.conv2d.pad[3] = 0;
    node[54]->nn_param.conv2d.group = 1;
    node[54]->nn_param.conv2d.dilation[0] = 1;
    node[54]->nn_param.conv2d.dilation[1] = 1;
    node[54]->vx_param.has_relu = TRUE;
    node[54]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[54]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[54]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_360_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_358
      var       - node[55]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 192, 1]]
      out_shape - [[35, 35, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[55], VSI_NN_OP_CONV_RELU, 3, 1, 358);
    node[55]->nn_param.conv2d.ksize[0] = 3;
    node[55]->nn_param.conv2d.ksize[1] = 3;
    node[55]->nn_param.conv2d.weights = 224;
    node[55]->nn_param.conv2d.stride[0] = 1;
    node[55]->nn_param.conv2d.stride[1] = 1;
    node[55]->nn_param.conv2d.pad[0] = 1;
    node[55]->nn_param.conv2d.pad[1] = 1;
    node[55]->nn_param.conv2d.pad[2] = 1;
    node[55]->nn_param.conv2d.pad[3] = 1;
    node[55]->nn_param.conv2d.group = 1;
    node[55]->nn_param.conv2d.dilation[0] = 1;
    node[55]->nn_param.conv2d.dilation[1] = 1;
    node[55]->vx_param.has_relu = TRUE;
    node[55]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[55]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[55]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Conv2D_357_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Relu_352
      var       - node[56]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[35, 35, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[56], VSI_NN_OP_CONV_RELU, 3, 1, 352);
    node[56]->nn_param.conv2d.ksize[0] = 3;
    node[56]->nn_param.conv2d.ksize[1] = 3;
    node[56]->nn_param.conv2d.weights = 256;
    node[56]->nn_param.conv2d.stride[0] = 2;
    node[56]->nn_param.conv2d.stride[1] = 2;
    node[56]->nn_param.conv2d.pad[0] = 0;
    node[56]->nn_param.conv2d.pad[1] = 0;
    node[56]->nn_param.conv2d.pad[2] = 0;
    node[56]->nn_param.conv2d.pad[3] = 0;
    node[56]->nn_param.conv2d.group = 1;
    node[56]->nn_param.conv2d.dilation[0] = 1;
    node[56]->nn_param.conv2d.dilation[1] = 1;
    node[56]->vx_param.has_relu = TRUE;
    node[56]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[56]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[56]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6a/concat_350
      var       - node[57]
      name      - InceptionV4/InceptionV4/Mixed_6a/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 384, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[57], VSI_NN_OP_CONCAT, 3, 1, 350);
    node[57]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_327_InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_319
      var       - node[58]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[58], VSI_NN_OP_CONV_RELU, 3, 1, 319);
    node[58]->nn_param.conv2d.ksize[0] = 1;
    node[58]->nn_param.conv2d.ksize[1] = 1;
    node[58]->nn_param.conv2d.weights = 384;
    node[58]->nn_param.conv2d.stride[0] = 1;
    node[58]->nn_param.conv2d.stride[1] = 1;
    node[58]->nn_param.conv2d.pad[0] = 0;
    node[58]->nn_param.conv2d.pad[1] = 0;
    node[58]->nn_param.conv2d.pad[2] = 0;
    node[58]->nn_param.conv2d.pad[3] = 0;
    node[58]->nn_param.conv2d.group = 1;
    node[58]->nn_param.conv2d.dilation[0] = 1;
    node[58]->nn_param.conv2d.dilation[1] = 1;
    node[58]->vx_param.has_relu = TRUE;
    node[58]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[58]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[58]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_342_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_338
      var       - node[59]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[59], VSI_NN_OP_CONV_RELU, 3, 1, 338);
    node[59]->nn_param.conv2d.ksize[0] = 1;
    node[59]->nn_param.conv2d.ksize[1] = 1;
    node[59]->nn_param.conv2d.weights = 192;
    node[59]->nn_param.conv2d.stride[0] = 1;
    node[59]->nn_param.conv2d.stride[1] = 1;
    node[59]->nn_param.conv2d.pad[0] = 0;
    node[59]->nn_param.conv2d.pad[1] = 0;
    node[59]->nn_param.conv2d.pad[2] = 0;
    node[59]->nn_param.conv2d.pad[3] = 0;
    node[59]->nn_param.conv2d.group = 1;
    node[59]->nn_param.conv2d.dilation[0] = 1;
    node[59]->nn_param.conv2d.dilation[1] = 1;
    node[59]->vx_param.has_relu = TRUE;
    node[59]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[59]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[59]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_349_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_347
      var       - node[60]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[60], VSI_NN_OP_CONV_RELU, 3, 1, 347);
    node[60]->nn_param.conv2d.ksize[0] = 1;
    node[60]->nn_param.conv2d.ksize[1] = 1;
    node[60]->nn_param.conv2d.weights = 192;
    node[60]->nn_param.conv2d.stride[0] = 1;
    node[60]->nn_param.conv2d.stride[1] = 1;
    node[60]->nn_param.conv2d.pad[0] = 0;
    node[60]->nn_param.conv2d.pad[1] = 0;
    node[60]->nn_param.conv2d.pad[2] = 0;
    node[60]->nn_param.conv2d.pad[3] = 0;
    node[60]->nn_param.conv2d.group = 1;
    node[60]->nn_param.conv2d.dilation[0] = 1;
    node[60]->nn_param.conv2d.dilation[1] = 1;
    node[60]->vx_param.has_relu = TRUE;
    node[60]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[60]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[60]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_333_conv_503
      var       - node[61]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[61], VSI_NN_OP_CONV_RELU, 3, 1, 503);
    node[61]->nn_param.conv2d.ksize[0] = 3;
    node[61]->nn_param.conv2d.ksize[1] = 3;
    node[61]->nn_param.conv2d.weights = 1024;
    node[61]->nn_param.conv2d.stride[0] = 1;
    node[61]->nn_param.conv2d.stride[1] = 1;
    node[61]->nn_param.conv2d.pad[0] = 1;
    node[61]->nn_param.conv2d.pad[1] = 1;
    node[61]->nn_param.conv2d.pad[2] = 1;
    node[61]->nn_param.conv2d.pad[3] = 1;
    node[61]->nn_param.conv2d.group = 1;
    node[61]->nn_param.conv2d.dilation[0] = 1;
    node[61]->nn_param.conv2d.dilation[1] = 1;
    node[61]->vx_param.has_relu = FALSE;
    node[61]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[61]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[61]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_336_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_331
      var       - node[62]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[62], VSI_NN_OP_CONV_RELU, 3, 1, 331);
    node[62]->nn_param.conv2d.ksize[0] = 7;
    node[62]->nn_param.conv2d.ksize[1] = 7;
    node[62]->nn_param.conv2d.weights = 224;
    node[62]->nn_param.conv2d.stride[0] = 1;
    node[62]->nn_param.conv2d.stride[1] = 1;
    node[62]->nn_param.conv2d.pad[0] = 3;
    node[62]->nn_param.conv2d.pad[1] = 3;
    node[62]->nn_param.conv2d.pad[2] = 3;
    node[62]->nn_param.conv2d.pad[3] = 3;
    node[62]->nn_param.conv2d.group = 1;
    node[62]->nn_param.conv2d.dilation[0] = 1;
    node[62]->nn_param.conv2d.dilation[1] = 1;
    node[62]->vx_param.has_relu = TRUE;
    node[62]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[62]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[62]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_346_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_344
      var       - node[63]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[63], VSI_NN_OP_CONV_RELU, 3, 1, 344);
    node[63]->nn_param.conv2d.ksize[0] = 1;
    node[63]->nn_param.conv2d.ksize[1] = 7;
    node[63]->nn_param.conv2d.weights = 192;
    node[63]->nn_param.conv2d.stride[0] = 1;
    node[63]->nn_param.conv2d.stride[1] = 1;
    node[63]->nn_param.conv2d.pad[0] = 0;
    node[63]->nn_param.conv2d.pad[1] = 0;
    node[63]->nn_param.conv2d.pad[2] = 3;
    node[63]->nn_param.conv2d.pad[3] = 3;
    node[63]->nn_param.conv2d.group = 1;
    node[63]->nn_param.conv2d.dilation[0] = 1;
    node[63]->nn_param.conv2d.dilation[1] = 1;
    node[63]->vx_param.has_relu = TRUE;
    node[63]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[63]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[63]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_330_InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_322
      var       - node[64]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[64], VSI_NN_OP_CONV_RELU, 3, 1, 322);
    node[64]->nn_param.conv2d.ksize[0] = 1;
    node[64]->nn_param.conv2d.ksize[1] = 1;
    node[64]->nn_param.conv2d.weights = 128;
    node[64]->nn_param.conv2d.stride[0] = 1;
    node[64]->nn_param.conv2d.stride[1] = 1;
    node[64]->nn_param.conv2d.pad[0] = 0;
    node[64]->nn_param.conv2d.pad[1] = 0;
    node[64]->nn_param.conv2d.pad[2] = 0;
    node[64]->nn_param.conv2d.pad[3] = 0;
    node[64]->nn_param.conv2d.group = 1;
    node[64]->nn_param.conv2d.dilation[0] = 1;
    node[64]->nn_param.conv2d.dilation[1] = 1;
    node[64]->vx_param.has_relu = TRUE;
    node[64]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[64]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[64]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_328_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_320
      var       - node[65]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[65], VSI_NN_OP_CONV_RELU, 3, 1, 320);
    node[65]->nn_param.conv2d.ksize[0] = 1;
    node[65]->nn_param.conv2d.ksize[1] = 7;
    node[65]->nn_param.conv2d.weights = 256;
    node[65]->nn_param.conv2d.stride[0] = 1;
    node[65]->nn_param.conv2d.stride[1] = 1;
    node[65]->nn_param.conv2d.pad[0] = 0;
    node[65]->nn_param.conv2d.pad[1] = 0;
    node[65]->nn_param.conv2d.pad[2] = 3;
    node[65]->nn_param.conv2d.pad[3] = 3;
    node[65]->nn_param.conv2d.group = 1;
    node[65]->nn_param.conv2d.dilation[0] = 1;
    node[65]->nn_param.conv2d.dilation[1] = 1;
    node[65]->vx_param.has_relu = TRUE;
    node[65]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[65]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[65]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_343_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_339
      var       - node[66]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[66], VSI_NN_OP_CONV_RELU, 3, 1, 339);
    node[66]->nn_param.conv2d.ksize[0] = 7;
    node[66]->nn_param.conv2d.ksize[1] = 7;
    node[66]->nn_param.conv2d.weights = 224;
    node[66]->nn_param.conv2d.stride[0] = 1;
    node[66]->nn_param.conv2d.stride[1] = 1;
    node[66]->nn_param.conv2d.pad[0] = 3;
    node[66]->nn_param.conv2d.pad[1] = 3;
    node[66]->nn_param.conv2d.pad[2] = 3;
    node[66]->nn_param.conv2d.pad[3] = 3;
    node[66]->nn_param.conv2d.group = 1;
    node[66]->nn_param.conv2d.dilation[0] = 1;
    node[66]->nn_param.conv2d.dilation[1] = 1;
    node[66]->vx_param.has_relu = TRUE;
    node[66]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[66]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[66]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_337_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_332
      var       - node[67]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[67], VSI_NN_OP_CONV_RELU, 3, 1, 332);
    node[67]->nn_param.conv2d.ksize[0] = 1;
    node[67]->nn_param.conv2d.ksize[1] = 7;
    node[67]->nn_param.conv2d.weights = 224;
    node[67]->nn_param.conv2d.stride[0] = 1;
    node[67]->nn_param.conv2d.stride[1] = 1;
    node[67]->nn_param.conv2d.pad[0] = 0;
    node[67]->nn_param.conv2d.pad[1] = 0;
    node[67]->nn_param.conv2d.pad[2] = 3;
    node[67]->nn_param.conv2d.pad[3] = 3;
    node[67]->nn_param.conv2d.group = 1;
    node[67]->nn_param.conv2d.dilation[0] = 1;
    node[67]->nn_param.conv2d.dilation[1] = 1;
    node[67]->vx_param.has_relu = TRUE;
    node[67]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[67]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[67]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_329_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_321
      var       - node[68]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[68], VSI_NN_OP_CONV_RELU, 3, 1, 321);
    node[68]->nn_param.conv2d.ksize[0] = 7;
    node[68]->nn_param.conv2d.ksize[1] = 7;
    node[68]->nn_param.conv2d.weights = 256;
    node[68]->nn_param.conv2d.stride[0] = 1;
    node[68]->nn_param.conv2d.stride[1] = 1;
    node[68]->nn_param.conv2d.pad[0] = 3;
    node[68]->nn_param.conv2d.pad[1] = 3;
    node[68]->nn_param.conv2d.pad[2] = 3;
    node[68]->nn_param.conv2d.pad[3] = 3;
    node[68]->nn_param.conv2d.group = 1;
    node[68]->nn_param.conv2d.dilation[0] = 1;
    node[68]->nn_param.conv2d.dilation[1] = 1;
    node[68]->vx_param.has_relu = TRUE;
    node[68]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[68]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[68]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6b/concat_318
      var       - node[69]
      name      - InceptionV4/InceptionV4/Mixed_6b/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 128, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[69], VSI_NN_OP_CONCAT, 4, 1, 318);
    node[69]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_295_InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_287
      var       - node[70]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[70], VSI_NN_OP_CONV_RELU, 3, 1, 287);
    node[70]->nn_param.conv2d.ksize[0] = 1;
    node[70]->nn_param.conv2d.ksize[1] = 1;
    node[70]->nn_param.conv2d.weights = 384;
    node[70]->nn_param.conv2d.stride[0] = 1;
    node[70]->nn_param.conv2d.stride[1] = 1;
    node[70]->nn_param.conv2d.pad[0] = 0;
    node[70]->nn_param.conv2d.pad[1] = 0;
    node[70]->nn_param.conv2d.pad[2] = 0;
    node[70]->nn_param.conv2d.pad[3] = 0;
    node[70]->nn_param.conv2d.group = 1;
    node[70]->nn_param.conv2d.dilation[0] = 1;
    node[70]->nn_param.conv2d.dilation[1] = 1;
    node[70]->vx_param.has_relu = TRUE;
    node[70]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[70]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[70]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_310_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_306
      var       - node[71]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[71], VSI_NN_OP_CONV_RELU, 3, 1, 306);
    node[71]->nn_param.conv2d.ksize[0] = 1;
    node[71]->nn_param.conv2d.ksize[1] = 1;
    node[71]->nn_param.conv2d.weights = 192;
    node[71]->nn_param.conv2d.stride[0] = 1;
    node[71]->nn_param.conv2d.stride[1] = 1;
    node[71]->nn_param.conv2d.pad[0] = 0;
    node[71]->nn_param.conv2d.pad[1] = 0;
    node[71]->nn_param.conv2d.pad[2] = 0;
    node[71]->nn_param.conv2d.pad[3] = 0;
    node[71]->nn_param.conv2d.group = 1;
    node[71]->nn_param.conv2d.dilation[0] = 1;
    node[71]->nn_param.conv2d.dilation[1] = 1;
    node[71]->vx_param.has_relu = TRUE;
    node[71]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[71]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[71]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_317_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_315
      var       - node[72]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[72], VSI_NN_OP_CONV_RELU, 3, 1, 315);
    node[72]->nn_param.conv2d.ksize[0] = 1;
    node[72]->nn_param.conv2d.ksize[1] = 1;
    node[72]->nn_param.conv2d.weights = 192;
    node[72]->nn_param.conv2d.stride[0] = 1;
    node[72]->nn_param.conv2d.stride[1] = 1;
    node[72]->nn_param.conv2d.pad[0] = 0;
    node[72]->nn_param.conv2d.pad[1] = 0;
    node[72]->nn_param.conv2d.pad[2] = 0;
    node[72]->nn_param.conv2d.pad[3] = 0;
    node[72]->nn_param.conv2d.group = 1;
    node[72]->nn_param.conv2d.dilation[0] = 1;
    node[72]->nn_param.conv2d.dilation[1] = 1;
    node[72]->vx_param.has_relu = TRUE;
    node[72]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[72]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[72]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_301_conv_502
      var       - node[73]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[73], VSI_NN_OP_CONV_RELU, 3, 1, 502);
    node[73]->nn_param.conv2d.ksize[0] = 3;
    node[73]->nn_param.conv2d.ksize[1] = 3;
    node[73]->nn_param.conv2d.weights = 1024;
    node[73]->nn_param.conv2d.stride[0] = 1;
    node[73]->nn_param.conv2d.stride[1] = 1;
    node[73]->nn_param.conv2d.pad[0] = 1;
    node[73]->nn_param.conv2d.pad[1] = 1;
    node[73]->nn_param.conv2d.pad[2] = 1;
    node[73]->nn_param.conv2d.pad[3] = 1;
    node[73]->nn_param.conv2d.group = 1;
    node[73]->nn_param.conv2d.dilation[0] = 1;
    node[73]->nn_param.conv2d.dilation[1] = 1;
    node[73]->vx_param.has_relu = FALSE;
    node[73]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[73]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[73]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_304_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_299
      var       - node[74]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[74], VSI_NN_OP_CONV_RELU, 3, 1, 299);
    node[74]->nn_param.conv2d.ksize[0] = 7;
    node[74]->nn_param.conv2d.ksize[1] = 7;
    node[74]->nn_param.conv2d.weights = 224;
    node[74]->nn_param.conv2d.stride[0] = 1;
    node[74]->nn_param.conv2d.stride[1] = 1;
    node[74]->nn_param.conv2d.pad[0] = 3;
    node[74]->nn_param.conv2d.pad[1] = 3;
    node[74]->nn_param.conv2d.pad[2] = 3;
    node[74]->nn_param.conv2d.pad[3] = 3;
    node[74]->nn_param.conv2d.group = 1;
    node[74]->nn_param.conv2d.dilation[0] = 1;
    node[74]->nn_param.conv2d.dilation[1] = 1;
    node[74]->vx_param.has_relu = TRUE;
    node[74]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[74]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[74]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_314_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_312
      var       - node[75]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[75], VSI_NN_OP_CONV_RELU, 3, 1, 312);
    node[75]->nn_param.conv2d.ksize[0] = 1;
    node[75]->nn_param.conv2d.ksize[1] = 7;
    node[75]->nn_param.conv2d.weights = 192;
    node[75]->nn_param.conv2d.stride[0] = 1;
    node[75]->nn_param.conv2d.stride[1] = 1;
    node[75]->nn_param.conv2d.pad[0] = 0;
    node[75]->nn_param.conv2d.pad[1] = 0;
    node[75]->nn_param.conv2d.pad[2] = 3;
    node[75]->nn_param.conv2d.pad[3] = 3;
    node[75]->nn_param.conv2d.group = 1;
    node[75]->nn_param.conv2d.dilation[0] = 1;
    node[75]->nn_param.conv2d.dilation[1] = 1;
    node[75]->vx_param.has_relu = TRUE;
    node[75]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[75]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[75]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_298_InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_290
      var       - node[76]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[76], VSI_NN_OP_CONV_RELU, 3, 1, 290);
    node[76]->nn_param.conv2d.ksize[0] = 1;
    node[76]->nn_param.conv2d.ksize[1] = 1;
    node[76]->nn_param.conv2d.weights = 128;
    node[76]->nn_param.conv2d.stride[0] = 1;
    node[76]->nn_param.conv2d.stride[1] = 1;
    node[76]->nn_param.conv2d.pad[0] = 0;
    node[76]->nn_param.conv2d.pad[1] = 0;
    node[76]->nn_param.conv2d.pad[2] = 0;
    node[76]->nn_param.conv2d.pad[3] = 0;
    node[76]->nn_param.conv2d.group = 1;
    node[76]->nn_param.conv2d.dilation[0] = 1;
    node[76]->nn_param.conv2d.dilation[1] = 1;
    node[76]->vx_param.has_relu = TRUE;
    node[76]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[76]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[76]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_296_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_288
      var       - node[77]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[77], VSI_NN_OP_CONV_RELU, 3, 1, 288);
    node[77]->nn_param.conv2d.ksize[0] = 1;
    node[77]->nn_param.conv2d.ksize[1] = 7;
    node[77]->nn_param.conv2d.weights = 256;
    node[77]->nn_param.conv2d.stride[0] = 1;
    node[77]->nn_param.conv2d.stride[1] = 1;
    node[77]->nn_param.conv2d.pad[0] = 0;
    node[77]->nn_param.conv2d.pad[1] = 0;
    node[77]->nn_param.conv2d.pad[2] = 3;
    node[77]->nn_param.conv2d.pad[3] = 3;
    node[77]->nn_param.conv2d.group = 1;
    node[77]->nn_param.conv2d.dilation[0] = 1;
    node[77]->nn_param.conv2d.dilation[1] = 1;
    node[77]->vx_param.has_relu = TRUE;
    node[77]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[77]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[77]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_311_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_307
      var       - node[78]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[78], VSI_NN_OP_CONV_RELU, 3, 1, 307);
    node[78]->nn_param.conv2d.ksize[0] = 7;
    node[78]->nn_param.conv2d.ksize[1] = 7;
    node[78]->nn_param.conv2d.weights = 224;
    node[78]->nn_param.conv2d.stride[0] = 1;
    node[78]->nn_param.conv2d.stride[1] = 1;
    node[78]->nn_param.conv2d.pad[0] = 3;
    node[78]->nn_param.conv2d.pad[1] = 3;
    node[78]->nn_param.conv2d.pad[2] = 3;
    node[78]->nn_param.conv2d.pad[3] = 3;
    node[78]->nn_param.conv2d.group = 1;
    node[78]->nn_param.conv2d.dilation[0] = 1;
    node[78]->nn_param.conv2d.dilation[1] = 1;
    node[78]->vx_param.has_relu = TRUE;
    node[78]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[78]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[78]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_305_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_300
      var       - node[79]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[79], VSI_NN_OP_CONV_RELU, 3, 1, 300);
    node[79]->nn_param.conv2d.ksize[0] = 1;
    node[79]->nn_param.conv2d.ksize[1] = 7;
    node[79]->nn_param.conv2d.weights = 224;
    node[79]->nn_param.conv2d.stride[0] = 1;
    node[79]->nn_param.conv2d.stride[1] = 1;
    node[79]->nn_param.conv2d.pad[0] = 0;
    node[79]->nn_param.conv2d.pad[1] = 0;
    node[79]->nn_param.conv2d.pad[2] = 3;
    node[79]->nn_param.conv2d.pad[3] = 3;
    node[79]->nn_param.conv2d.group = 1;
    node[79]->nn_param.conv2d.dilation[0] = 1;
    node[79]->nn_param.conv2d.dilation[1] = 1;
    node[79]->vx_param.has_relu = TRUE;
    node[79]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[79]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[79]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_297_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_289
      var       - node[80]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[80], VSI_NN_OP_CONV_RELU, 3, 1, 289);
    node[80]->nn_param.conv2d.ksize[0] = 7;
    node[80]->nn_param.conv2d.ksize[1] = 7;
    node[80]->nn_param.conv2d.weights = 256;
    node[80]->nn_param.conv2d.stride[0] = 1;
    node[80]->nn_param.conv2d.stride[1] = 1;
    node[80]->nn_param.conv2d.pad[0] = 3;
    node[80]->nn_param.conv2d.pad[1] = 3;
    node[80]->nn_param.conv2d.pad[2] = 3;
    node[80]->nn_param.conv2d.pad[3] = 3;
    node[80]->nn_param.conv2d.group = 1;
    node[80]->nn_param.conv2d.dilation[0] = 1;
    node[80]->nn_param.conv2d.dilation[1] = 1;
    node[80]->vx_param.has_relu = TRUE;
    node[80]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[80]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[80]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6c/concat_286
      var       - node[81]
      name      - InceptionV4/InceptionV4/Mixed_6c/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 128, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[81], VSI_NN_OP_CONCAT, 4, 1, 286);
    node[81]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_263_InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_255
      var       - node[82]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[82], VSI_NN_OP_CONV_RELU, 3, 1, 255);
    node[82]->nn_param.conv2d.ksize[0] = 1;
    node[82]->nn_param.conv2d.ksize[1] = 1;
    node[82]->nn_param.conv2d.weights = 384;
    node[82]->nn_param.conv2d.stride[0] = 1;
    node[82]->nn_param.conv2d.stride[1] = 1;
    node[82]->nn_param.conv2d.pad[0] = 0;
    node[82]->nn_param.conv2d.pad[1] = 0;
    node[82]->nn_param.conv2d.pad[2] = 0;
    node[82]->nn_param.conv2d.pad[3] = 0;
    node[82]->nn_param.conv2d.group = 1;
    node[82]->nn_param.conv2d.dilation[0] = 1;
    node[82]->nn_param.conv2d.dilation[1] = 1;
    node[82]->vx_param.has_relu = TRUE;
    node[82]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[82]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[82]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_278_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_274
      var       - node[83]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[83], VSI_NN_OP_CONV_RELU, 3, 1, 274);
    node[83]->nn_param.conv2d.ksize[0] = 1;
    node[83]->nn_param.conv2d.ksize[1] = 1;
    node[83]->nn_param.conv2d.weights = 192;
    node[83]->nn_param.conv2d.stride[0] = 1;
    node[83]->nn_param.conv2d.stride[1] = 1;
    node[83]->nn_param.conv2d.pad[0] = 0;
    node[83]->nn_param.conv2d.pad[1] = 0;
    node[83]->nn_param.conv2d.pad[2] = 0;
    node[83]->nn_param.conv2d.pad[3] = 0;
    node[83]->nn_param.conv2d.group = 1;
    node[83]->nn_param.conv2d.dilation[0] = 1;
    node[83]->nn_param.conv2d.dilation[1] = 1;
    node[83]->vx_param.has_relu = TRUE;
    node[83]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[83]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[83]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_285_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_283
      var       - node[84]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[84], VSI_NN_OP_CONV_RELU, 3, 1, 283);
    node[84]->nn_param.conv2d.ksize[0] = 1;
    node[84]->nn_param.conv2d.ksize[1] = 1;
    node[84]->nn_param.conv2d.weights = 192;
    node[84]->nn_param.conv2d.stride[0] = 1;
    node[84]->nn_param.conv2d.stride[1] = 1;
    node[84]->nn_param.conv2d.pad[0] = 0;
    node[84]->nn_param.conv2d.pad[1] = 0;
    node[84]->nn_param.conv2d.pad[2] = 0;
    node[84]->nn_param.conv2d.pad[3] = 0;
    node[84]->nn_param.conv2d.group = 1;
    node[84]->nn_param.conv2d.dilation[0] = 1;
    node[84]->nn_param.conv2d.dilation[1] = 1;
    node[84]->vx_param.has_relu = TRUE;
    node[84]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[84]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[84]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_269_conv_501
      var       - node[85]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[85], VSI_NN_OP_CONV_RELU, 3, 1, 501);
    node[85]->nn_param.conv2d.ksize[0] = 3;
    node[85]->nn_param.conv2d.ksize[1] = 3;
    node[85]->nn_param.conv2d.weights = 1024;
    node[85]->nn_param.conv2d.stride[0] = 1;
    node[85]->nn_param.conv2d.stride[1] = 1;
    node[85]->nn_param.conv2d.pad[0] = 1;
    node[85]->nn_param.conv2d.pad[1] = 1;
    node[85]->nn_param.conv2d.pad[2] = 1;
    node[85]->nn_param.conv2d.pad[3] = 1;
    node[85]->nn_param.conv2d.group = 1;
    node[85]->nn_param.conv2d.dilation[0] = 1;
    node[85]->nn_param.conv2d.dilation[1] = 1;
    node[85]->vx_param.has_relu = FALSE;
    node[85]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[85]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[85]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_272_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_267
      var       - node[86]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[86], VSI_NN_OP_CONV_RELU, 3, 1, 267);
    node[86]->nn_param.conv2d.ksize[0] = 7;
    node[86]->nn_param.conv2d.ksize[1] = 7;
    node[86]->nn_param.conv2d.weights = 224;
    node[86]->nn_param.conv2d.stride[0] = 1;
    node[86]->nn_param.conv2d.stride[1] = 1;
    node[86]->nn_param.conv2d.pad[0] = 3;
    node[86]->nn_param.conv2d.pad[1] = 3;
    node[86]->nn_param.conv2d.pad[2] = 3;
    node[86]->nn_param.conv2d.pad[3] = 3;
    node[86]->nn_param.conv2d.group = 1;
    node[86]->nn_param.conv2d.dilation[0] = 1;
    node[86]->nn_param.conv2d.dilation[1] = 1;
    node[86]->vx_param.has_relu = TRUE;
    node[86]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[86]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[86]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_282_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_280
      var       - node[87]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[87], VSI_NN_OP_CONV_RELU, 3, 1, 280);
    node[87]->nn_param.conv2d.ksize[0] = 1;
    node[87]->nn_param.conv2d.ksize[1] = 7;
    node[87]->nn_param.conv2d.weights = 192;
    node[87]->nn_param.conv2d.stride[0] = 1;
    node[87]->nn_param.conv2d.stride[1] = 1;
    node[87]->nn_param.conv2d.pad[0] = 0;
    node[87]->nn_param.conv2d.pad[1] = 0;
    node[87]->nn_param.conv2d.pad[2] = 3;
    node[87]->nn_param.conv2d.pad[3] = 3;
    node[87]->nn_param.conv2d.group = 1;
    node[87]->nn_param.conv2d.dilation[0] = 1;
    node[87]->nn_param.conv2d.dilation[1] = 1;
    node[87]->vx_param.has_relu = TRUE;
    node[87]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[87]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[87]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_266_InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_258
      var       - node[88]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[88], VSI_NN_OP_CONV_RELU, 3, 1, 258);
    node[88]->nn_param.conv2d.ksize[0] = 1;
    node[88]->nn_param.conv2d.ksize[1] = 1;
    node[88]->nn_param.conv2d.weights = 128;
    node[88]->nn_param.conv2d.stride[0] = 1;
    node[88]->nn_param.conv2d.stride[1] = 1;
    node[88]->nn_param.conv2d.pad[0] = 0;
    node[88]->nn_param.conv2d.pad[1] = 0;
    node[88]->nn_param.conv2d.pad[2] = 0;
    node[88]->nn_param.conv2d.pad[3] = 0;
    node[88]->nn_param.conv2d.group = 1;
    node[88]->nn_param.conv2d.dilation[0] = 1;
    node[88]->nn_param.conv2d.dilation[1] = 1;
    node[88]->vx_param.has_relu = TRUE;
    node[88]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[88]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[88]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_264_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_256
      var       - node[89]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[89], VSI_NN_OP_CONV_RELU, 3, 1, 256);
    node[89]->nn_param.conv2d.ksize[0] = 1;
    node[89]->nn_param.conv2d.ksize[1] = 7;
    node[89]->nn_param.conv2d.weights = 256;
    node[89]->nn_param.conv2d.stride[0] = 1;
    node[89]->nn_param.conv2d.stride[1] = 1;
    node[89]->nn_param.conv2d.pad[0] = 0;
    node[89]->nn_param.conv2d.pad[1] = 0;
    node[89]->nn_param.conv2d.pad[2] = 3;
    node[89]->nn_param.conv2d.pad[3] = 3;
    node[89]->nn_param.conv2d.group = 1;
    node[89]->nn_param.conv2d.dilation[0] = 1;
    node[89]->nn_param.conv2d.dilation[1] = 1;
    node[89]->vx_param.has_relu = TRUE;
    node[89]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[89]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[89]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_279_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_275
      var       - node[90]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[90], VSI_NN_OP_CONV_RELU, 3, 1, 275);
    node[90]->nn_param.conv2d.ksize[0] = 7;
    node[90]->nn_param.conv2d.ksize[1] = 7;
    node[90]->nn_param.conv2d.weights = 224;
    node[90]->nn_param.conv2d.stride[0] = 1;
    node[90]->nn_param.conv2d.stride[1] = 1;
    node[90]->nn_param.conv2d.pad[0] = 3;
    node[90]->nn_param.conv2d.pad[1] = 3;
    node[90]->nn_param.conv2d.pad[2] = 3;
    node[90]->nn_param.conv2d.pad[3] = 3;
    node[90]->nn_param.conv2d.group = 1;
    node[90]->nn_param.conv2d.dilation[0] = 1;
    node[90]->nn_param.conv2d.dilation[1] = 1;
    node[90]->vx_param.has_relu = TRUE;
    node[90]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[90]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[90]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_273_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_268
      var       - node[91]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[91], VSI_NN_OP_CONV_RELU, 3, 1, 268);
    node[91]->nn_param.conv2d.ksize[0] = 1;
    node[91]->nn_param.conv2d.ksize[1] = 7;
    node[91]->nn_param.conv2d.weights = 224;
    node[91]->nn_param.conv2d.stride[0] = 1;
    node[91]->nn_param.conv2d.stride[1] = 1;
    node[91]->nn_param.conv2d.pad[0] = 0;
    node[91]->nn_param.conv2d.pad[1] = 0;
    node[91]->nn_param.conv2d.pad[2] = 3;
    node[91]->nn_param.conv2d.pad[3] = 3;
    node[91]->nn_param.conv2d.group = 1;
    node[91]->nn_param.conv2d.dilation[0] = 1;
    node[91]->nn_param.conv2d.dilation[1] = 1;
    node[91]->vx_param.has_relu = TRUE;
    node[91]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[91]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[91]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_265_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_257
      var       - node[92]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[92], VSI_NN_OP_CONV_RELU, 3, 1, 257);
    node[92]->nn_param.conv2d.ksize[0] = 7;
    node[92]->nn_param.conv2d.ksize[1] = 7;
    node[92]->nn_param.conv2d.weights = 256;
    node[92]->nn_param.conv2d.stride[0] = 1;
    node[92]->nn_param.conv2d.stride[1] = 1;
    node[92]->nn_param.conv2d.pad[0] = 3;
    node[92]->nn_param.conv2d.pad[1] = 3;
    node[92]->nn_param.conv2d.pad[2] = 3;
    node[92]->nn_param.conv2d.pad[3] = 3;
    node[92]->nn_param.conv2d.group = 1;
    node[92]->nn_param.conv2d.dilation[0] = 1;
    node[92]->nn_param.conv2d.dilation[1] = 1;
    node[92]->vx_param.has_relu = TRUE;
    node[92]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[92]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[92]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6d/concat_254
      var       - node[93]
      name      - InceptionV4/InceptionV4/Mixed_6d/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 128, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[93], VSI_NN_OP_CONCAT, 4, 1, 254);
    node[93]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_231_InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_223
      var       - node[94]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[94], VSI_NN_OP_CONV_RELU, 3, 1, 223);
    node[94]->nn_param.conv2d.ksize[0] = 1;
    node[94]->nn_param.conv2d.ksize[1] = 1;
    node[94]->nn_param.conv2d.weights = 384;
    node[94]->nn_param.conv2d.stride[0] = 1;
    node[94]->nn_param.conv2d.stride[1] = 1;
    node[94]->nn_param.conv2d.pad[0] = 0;
    node[94]->nn_param.conv2d.pad[1] = 0;
    node[94]->nn_param.conv2d.pad[2] = 0;
    node[94]->nn_param.conv2d.pad[3] = 0;
    node[94]->nn_param.conv2d.group = 1;
    node[94]->nn_param.conv2d.dilation[0] = 1;
    node[94]->nn_param.conv2d.dilation[1] = 1;
    node[94]->vx_param.has_relu = TRUE;
    node[94]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[94]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[94]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_246_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_242
      var       - node[95]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[95], VSI_NN_OP_CONV_RELU, 3, 1, 242);
    node[95]->nn_param.conv2d.ksize[0] = 1;
    node[95]->nn_param.conv2d.ksize[1] = 1;
    node[95]->nn_param.conv2d.weights = 192;
    node[95]->nn_param.conv2d.stride[0] = 1;
    node[95]->nn_param.conv2d.stride[1] = 1;
    node[95]->nn_param.conv2d.pad[0] = 0;
    node[95]->nn_param.conv2d.pad[1] = 0;
    node[95]->nn_param.conv2d.pad[2] = 0;
    node[95]->nn_param.conv2d.pad[3] = 0;
    node[95]->nn_param.conv2d.group = 1;
    node[95]->nn_param.conv2d.dilation[0] = 1;
    node[95]->nn_param.conv2d.dilation[1] = 1;
    node[95]->vx_param.has_relu = TRUE;
    node[95]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[95]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[95]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_253_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_251
      var       - node[96]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[96], VSI_NN_OP_CONV_RELU, 3, 1, 251);
    node[96]->nn_param.conv2d.ksize[0] = 1;
    node[96]->nn_param.conv2d.ksize[1] = 1;
    node[96]->nn_param.conv2d.weights = 192;
    node[96]->nn_param.conv2d.stride[0] = 1;
    node[96]->nn_param.conv2d.stride[1] = 1;
    node[96]->nn_param.conv2d.pad[0] = 0;
    node[96]->nn_param.conv2d.pad[1] = 0;
    node[96]->nn_param.conv2d.pad[2] = 0;
    node[96]->nn_param.conv2d.pad[3] = 0;
    node[96]->nn_param.conv2d.group = 1;
    node[96]->nn_param.conv2d.dilation[0] = 1;
    node[96]->nn_param.conv2d.dilation[1] = 1;
    node[96]->vx_param.has_relu = TRUE;
    node[96]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[96]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[96]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_237_conv_500
      var       - node[97]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[97], VSI_NN_OP_CONV_RELU, 3, 1, 500);
    node[97]->nn_param.conv2d.ksize[0] = 3;
    node[97]->nn_param.conv2d.ksize[1] = 3;
    node[97]->nn_param.conv2d.weights = 1024;
    node[97]->nn_param.conv2d.stride[0] = 1;
    node[97]->nn_param.conv2d.stride[1] = 1;
    node[97]->nn_param.conv2d.pad[0] = 1;
    node[97]->nn_param.conv2d.pad[1] = 1;
    node[97]->nn_param.conv2d.pad[2] = 1;
    node[97]->nn_param.conv2d.pad[3] = 1;
    node[97]->nn_param.conv2d.group = 1;
    node[97]->nn_param.conv2d.dilation[0] = 1;
    node[97]->nn_param.conv2d.dilation[1] = 1;
    node[97]->vx_param.has_relu = FALSE;
    node[97]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[97]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[97]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_240_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_235
      var       - node[98]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[98], VSI_NN_OP_CONV_RELU, 3, 1, 235);
    node[98]->nn_param.conv2d.ksize[0] = 7;
    node[98]->nn_param.conv2d.ksize[1] = 7;
    node[98]->nn_param.conv2d.weights = 224;
    node[98]->nn_param.conv2d.stride[0] = 1;
    node[98]->nn_param.conv2d.stride[1] = 1;
    node[98]->nn_param.conv2d.pad[0] = 3;
    node[98]->nn_param.conv2d.pad[1] = 3;
    node[98]->nn_param.conv2d.pad[2] = 3;
    node[98]->nn_param.conv2d.pad[3] = 3;
    node[98]->nn_param.conv2d.group = 1;
    node[98]->nn_param.conv2d.dilation[0] = 1;
    node[98]->nn_param.conv2d.dilation[1] = 1;
    node[98]->vx_param.has_relu = TRUE;
    node[98]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[98]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[98]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_250_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_248
      var       - node[99]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[99], VSI_NN_OP_CONV_RELU, 3, 1, 248);
    node[99]->nn_param.conv2d.ksize[0] = 1;
    node[99]->nn_param.conv2d.ksize[1] = 7;
    node[99]->nn_param.conv2d.weights = 192;
    node[99]->nn_param.conv2d.stride[0] = 1;
    node[99]->nn_param.conv2d.stride[1] = 1;
    node[99]->nn_param.conv2d.pad[0] = 0;
    node[99]->nn_param.conv2d.pad[1] = 0;
    node[99]->nn_param.conv2d.pad[2] = 3;
    node[99]->nn_param.conv2d.pad[3] = 3;
    node[99]->nn_param.conv2d.group = 1;
    node[99]->nn_param.conv2d.dilation[0] = 1;
    node[99]->nn_param.conv2d.dilation[1] = 1;
    node[99]->vx_param.has_relu = TRUE;
    node[99]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[99]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[99]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_234_InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_226
      var       - node[100]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[100], VSI_NN_OP_CONV_RELU, 3, 1, 226);
    node[100]->nn_param.conv2d.ksize[0] = 1;
    node[100]->nn_param.conv2d.ksize[1] = 1;
    node[100]->nn_param.conv2d.weights = 128;
    node[100]->nn_param.conv2d.stride[0] = 1;
    node[100]->nn_param.conv2d.stride[1] = 1;
    node[100]->nn_param.conv2d.pad[0] = 0;
    node[100]->nn_param.conv2d.pad[1] = 0;
    node[100]->nn_param.conv2d.pad[2] = 0;
    node[100]->nn_param.conv2d.pad[3] = 0;
    node[100]->nn_param.conv2d.group = 1;
    node[100]->nn_param.conv2d.dilation[0] = 1;
    node[100]->nn_param.conv2d.dilation[1] = 1;
    node[100]->vx_param.has_relu = TRUE;
    node[100]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[100]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[100]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_232_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_224
      var       - node[101]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[101], VSI_NN_OP_CONV_RELU, 3, 1, 224);
    node[101]->nn_param.conv2d.ksize[0] = 1;
    node[101]->nn_param.conv2d.ksize[1] = 7;
    node[101]->nn_param.conv2d.weights = 256;
    node[101]->nn_param.conv2d.stride[0] = 1;
    node[101]->nn_param.conv2d.stride[1] = 1;
    node[101]->nn_param.conv2d.pad[0] = 0;
    node[101]->nn_param.conv2d.pad[1] = 0;
    node[101]->nn_param.conv2d.pad[2] = 3;
    node[101]->nn_param.conv2d.pad[3] = 3;
    node[101]->nn_param.conv2d.group = 1;
    node[101]->nn_param.conv2d.dilation[0] = 1;
    node[101]->nn_param.conv2d.dilation[1] = 1;
    node[101]->vx_param.has_relu = TRUE;
    node[101]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[101]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[101]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_247_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_243
      var       - node[102]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[102], VSI_NN_OP_CONV_RELU, 3, 1, 243);
    node[102]->nn_param.conv2d.ksize[0] = 7;
    node[102]->nn_param.conv2d.ksize[1] = 7;
    node[102]->nn_param.conv2d.weights = 224;
    node[102]->nn_param.conv2d.stride[0] = 1;
    node[102]->nn_param.conv2d.stride[1] = 1;
    node[102]->nn_param.conv2d.pad[0] = 3;
    node[102]->nn_param.conv2d.pad[1] = 3;
    node[102]->nn_param.conv2d.pad[2] = 3;
    node[102]->nn_param.conv2d.pad[3] = 3;
    node[102]->nn_param.conv2d.group = 1;
    node[102]->nn_param.conv2d.dilation[0] = 1;
    node[102]->nn_param.conv2d.dilation[1] = 1;
    node[102]->vx_param.has_relu = TRUE;
    node[102]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[102]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[102]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_241_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_236
      var       - node[103]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[103], VSI_NN_OP_CONV_RELU, 3, 1, 236);
    node[103]->nn_param.conv2d.ksize[0] = 1;
    node[103]->nn_param.conv2d.ksize[1] = 7;
    node[103]->nn_param.conv2d.weights = 224;
    node[103]->nn_param.conv2d.stride[0] = 1;
    node[103]->nn_param.conv2d.stride[1] = 1;
    node[103]->nn_param.conv2d.pad[0] = 0;
    node[103]->nn_param.conv2d.pad[1] = 0;
    node[103]->nn_param.conv2d.pad[2] = 3;
    node[103]->nn_param.conv2d.pad[3] = 3;
    node[103]->nn_param.conv2d.group = 1;
    node[103]->nn_param.conv2d.dilation[0] = 1;
    node[103]->nn_param.conv2d.dilation[1] = 1;
    node[103]->vx_param.has_relu = TRUE;
    node[103]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[103]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[103]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_233_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_225
      var       - node[104]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[104], VSI_NN_OP_CONV_RELU, 3, 1, 225);
    node[104]->nn_param.conv2d.ksize[0] = 7;
    node[104]->nn_param.conv2d.ksize[1] = 7;
    node[104]->nn_param.conv2d.weights = 256;
    node[104]->nn_param.conv2d.stride[0] = 1;
    node[104]->nn_param.conv2d.stride[1] = 1;
    node[104]->nn_param.conv2d.pad[0] = 3;
    node[104]->nn_param.conv2d.pad[1] = 3;
    node[104]->nn_param.conv2d.pad[2] = 3;
    node[104]->nn_param.conv2d.pad[3] = 3;
    node[104]->nn_param.conv2d.group = 1;
    node[104]->nn_param.conv2d.dilation[0] = 1;
    node[104]->nn_param.conv2d.dilation[1] = 1;
    node[104]->vx_param.has_relu = TRUE;
    node[104]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[104]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[104]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6e/concat_222
      var       - node[105]
      name      - InceptionV4/InceptionV4/Mixed_6e/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 128, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[105], VSI_NN_OP_CONCAT, 4, 1, 222);
    node[105]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Conv2D_199_InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Relu_191
      var       - node[106]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[106], VSI_NN_OP_CONV_RELU, 3, 1, 191);
    node[106]->nn_param.conv2d.ksize[0] = 1;
    node[106]->nn_param.conv2d.ksize[1] = 1;
    node[106]->nn_param.conv2d.weights = 384;
    node[106]->nn_param.conv2d.stride[0] = 1;
    node[106]->nn_param.conv2d.stride[1] = 1;
    node[106]->nn_param.conv2d.pad[0] = 0;
    node[106]->nn_param.conv2d.pad[1] = 0;
    node[106]->nn_param.conv2d.pad[2] = 0;
    node[106]->nn_param.conv2d.pad[3] = 0;
    node[106]->nn_param.conv2d.group = 1;
    node[106]->nn_param.conv2d.dilation[0] = 1;
    node[106]->nn_param.conv2d.dilation[1] = 1;
    node[106]->vx_param.has_relu = TRUE;
    node[106]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[106]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[106]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Conv2D_214_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Relu_210
      var       - node[107]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[107], VSI_NN_OP_CONV_RELU, 3, 1, 210);
    node[107]->nn_param.conv2d.ksize[0] = 1;
    node[107]->nn_param.conv2d.ksize[1] = 1;
    node[107]->nn_param.conv2d.weights = 192;
    node[107]->nn_param.conv2d.stride[0] = 1;
    node[107]->nn_param.conv2d.stride[1] = 1;
    node[107]->nn_param.conv2d.pad[0] = 0;
    node[107]->nn_param.conv2d.pad[1] = 0;
    node[107]->nn_param.conv2d.pad[2] = 0;
    node[107]->nn_param.conv2d.pad[3] = 0;
    node[107]->nn_param.conv2d.group = 1;
    node[107]->nn_param.conv2d.dilation[0] = 1;
    node[107]->nn_param.conv2d.dilation[1] = 1;
    node[107]->vx_param.has_relu = TRUE;
    node[107]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[107]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[107]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Conv2D_221_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Relu_219
      var       - node[108]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[108], VSI_NN_OP_CONV_RELU, 3, 1, 219);
    node[108]->nn_param.conv2d.ksize[0] = 1;
    node[108]->nn_param.conv2d.ksize[1] = 1;
    node[108]->nn_param.conv2d.weights = 192;
    node[108]->nn_param.conv2d.stride[0] = 1;
    node[108]->nn_param.conv2d.stride[1] = 1;
    node[108]->nn_param.conv2d.pad[0] = 0;
    node[108]->nn_param.conv2d.pad[1] = 0;
    node[108]->nn_param.conv2d.pad[2] = 0;
    node[108]->nn_param.conv2d.pad[3] = 0;
    node[108]->nn_param.conv2d.group = 1;
    node[108]->nn_param.conv2d.dilation[0] = 1;
    node[108]->nn_param.conv2d.dilation[1] = 1;
    node[108]->vx_param.has_relu = TRUE;
    node[108]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[108]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[108]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_6f/Branch_3/AvgPool_0a_3x3/AvgPool_205_conv_499
      var       - node[109]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[109], VSI_NN_OP_CONV_RELU, 3, 1, 499);
    node[109]->nn_param.conv2d.ksize[0] = 3;
    node[109]->nn_param.conv2d.ksize[1] = 3;
    node[109]->nn_param.conv2d.weights = 1024;
    node[109]->nn_param.conv2d.stride[0] = 1;
    node[109]->nn_param.conv2d.stride[1] = 1;
    node[109]->nn_param.conv2d.pad[0] = 1;
    node[109]->nn_param.conv2d.pad[1] = 1;
    node[109]->nn_param.conv2d.pad[2] = 1;
    node[109]->nn_param.conv2d.pad[3] = 1;
    node[109]->nn_param.conv2d.group = 1;
    node[109]->nn_param.conv2d.dilation[0] = 1;
    node[109]->nn_param.conv2d.dilation[1] = 1;
    node[109]->vx_param.has_relu = FALSE;
    node[109]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[109]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[109]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Conv2D_208_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Relu_203
      var       - node[110]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[110], VSI_NN_OP_CONV_RELU, 3, 1, 203);
    node[110]->nn_param.conv2d.ksize[0] = 7;
    node[110]->nn_param.conv2d.ksize[1] = 7;
    node[110]->nn_param.conv2d.weights = 224;
    node[110]->nn_param.conv2d.stride[0] = 1;
    node[110]->nn_param.conv2d.stride[1] = 1;
    node[110]->nn_param.conv2d.pad[0] = 3;
    node[110]->nn_param.conv2d.pad[1] = 3;
    node[110]->nn_param.conv2d.pad[2] = 3;
    node[110]->nn_param.conv2d.pad[3] = 3;
    node[110]->nn_param.conv2d.group = 1;
    node[110]->nn_param.conv2d.dilation[0] = 1;
    node[110]->nn_param.conv2d.dilation[1] = 1;
    node[110]->vx_param.has_relu = TRUE;
    node[110]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[110]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[110]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Conv2D_218_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Relu_216
      var       - node[111]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[111], VSI_NN_OP_CONV_RELU, 3, 1, 216);
    node[111]->nn_param.conv2d.ksize[0] = 1;
    node[111]->nn_param.conv2d.ksize[1] = 7;
    node[111]->nn_param.conv2d.weights = 192;
    node[111]->nn_param.conv2d.stride[0] = 1;
    node[111]->nn_param.conv2d.stride[1] = 1;
    node[111]->nn_param.conv2d.pad[0] = 0;
    node[111]->nn_param.conv2d.pad[1] = 0;
    node[111]->nn_param.conv2d.pad[2] = 3;
    node[111]->nn_param.conv2d.pad[3] = 3;
    node[111]->nn_param.conv2d.group = 1;
    node[111]->nn_param.conv2d.dilation[0] = 1;
    node[111]->nn_param.conv2d.dilation[1] = 1;
    node[111]->vx_param.has_relu = TRUE;
    node[111]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[111]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[111]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Conv2D_202_InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Relu_194
      var       - node[112]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[112], VSI_NN_OP_CONV_RELU, 3, 1, 194);
    node[112]->nn_param.conv2d.ksize[0] = 1;
    node[112]->nn_param.conv2d.ksize[1] = 1;
    node[112]->nn_param.conv2d.weights = 128;
    node[112]->nn_param.conv2d.stride[0] = 1;
    node[112]->nn_param.conv2d.stride[1] = 1;
    node[112]->nn_param.conv2d.pad[0] = 0;
    node[112]->nn_param.conv2d.pad[1] = 0;
    node[112]->nn_param.conv2d.pad[2] = 0;
    node[112]->nn_param.conv2d.pad[3] = 0;
    node[112]->nn_param.conv2d.group = 1;
    node[112]->nn_param.conv2d.dilation[0] = 1;
    node[112]->nn_param.conv2d.dilation[1] = 1;
    node[112]->vx_param.has_relu = TRUE;
    node[112]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[112]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[112]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Conv2D_200_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Relu_192
      var       - node[113]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[113], VSI_NN_OP_CONV_RELU, 3, 1, 192);
    node[113]->nn_param.conv2d.ksize[0] = 1;
    node[113]->nn_param.conv2d.ksize[1] = 7;
    node[113]->nn_param.conv2d.weights = 256;
    node[113]->nn_param.conv2d.stride[0] = 1;
    node[113]->nn_param.conv2d.stride[1] = 1;
    node[113]->nn_param.conv2d.pad[0] = 0;
    node[113]->nn_param.conv2d.pad[1] = 0;
    node[113]->nn_param.conv2d.pad[2] = 3;
    node[113]->nn_param.conv2d.pad[3] = 3;
    node[113]->nn_param.conv2d.group = 1;
    node[113]->nn_param.conv2d.dilation[0] = 1;
    node[113]->nn_param.conv2d.dilation[1] = 1;
    node[113]->vx_param.has_relu = TRUE;
    node[113]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[113]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[113]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Conv2D_215_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Relu_211
      var       - node[114]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[114], VSI_NN_OP_CONV_RELU, 3, 1, 211);
    node[114]->nn_param.conv2d.ksize[0] = 7;
    node[114]->nn_param.conv2d.ksize[1] = 7;
    node[114]->nn_param.conv2d.weights = 224;
    node[114]->nn_param.conv2d.stride[0] = 1;
    node[114]->nn_param.conv2d.stride[1] = 1;
    node[114]->nn_param.conv2d.pad[0] = 3;
    node[114]->nn_param.conv2d.pad[1] = 3;
    node[114]->nn_param.conv2d.pad[2] = 3;
    node[114]->nn_param.conv2d.pad[3] = 3;
    node[114]->nn_param.conv2d.group = 1;
    node[114]->nn_param.conv2d.dilation[0] = 1;
    node[114]->nn_param.conv2d.dilation[1] = 1;
    node[114]->vx_param.has_relu = TRUE;
    node[114]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[114]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[114]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Conv2D_209_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Relu_204
      var       - node[115]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[115], VSI_NN_OP_CONV_RELU, 3, 1, 204);
    node[115]->nn_param.conv2d.ksize[0] = 1;
    node[115]->nn_param.conv2d.ksize[1] = 7;
    node[115]->nn_param.conv2d.weights = 224;
    node[115]->nn_param.conv2d.stride[0] = 1;
    node[115]->nn_param.conv2d.stride[1] = 1;
    node[115]->nn_param.conv2d.pad[0] = 0;
    node[115]->nn_param.conv2d.pad[1] = 0;
    node[115]->nn_param.conv2d.pad[2] = 3;
    node[115]->nn_param.conv2d.pad[3] = 3;
    node[115]->nn_param.conv2d.group = 1;
    node[115]->nn_param.conv2d.dilation[0] = 1;
    node[115]->nn_param.conv2d.dilation[1] = 1;
    node[115]->vx_param.has_relu = TRUE;
    node[115]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[115]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[115]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Conv2D_201_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Relu_193
      var       - node[116]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[116], VSI_NN_OP_CONV_RELU, 3, 1, 193);
    node[116]->nn_param.conv2d.ksize[0] = 7;
    node[116]->nn_param.conv2d.ksize[1] = 7;
    node[116]->nn_param.conv2d.weights = 256;
    node[116]->nn_param.conv2d.stride[0] = 1;
    node[116]->nn_param.conv2d.stride[1] = 1;
    node[116]->nn_param.conv2d.pad[0] = 3;
    node[116]->nn_param.conv2d.pad[1] = 3;
    node[116]->nn_param.conv2d.pad[2] = 3;
    node[116]->nn_param.conv2d.pad[3] = 3;
    node[116]->nn_param.conv2d.group = 1;
    node[116]->nn_param.conv2d.dilation[0] = 1;
    node[116]->nn_param.conv2d.dilation[1] = 1;
    node[116]->vx_param.has_relu = TRUE;
    node[116]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[116]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[116]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6f/concat_190
      var       - node[117]
      name      - InceptionV4/InceptionV4/Mixed_6f/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 128, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[117], VSI_NN_OP_CONCAT, 4, 1, 190);
    node[117]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Conv2D_167_InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Relu_159
      var       - node[118]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[118], VSI_NN_OP_CONV_RELU, 3, 1, 159);
    node[118]->nn_param.conv2d.ksize[0] = 1;
    node[118]->nn_param.conv2d.ksize[1] = 1;
    node[118]->nn_param.conv2d.weights = 384;
    node[118]->nn_param.conv2d.stride[0] = 1;
    node[118]->nn_param.conv2d.stride[1] = 1;
    node[118]->nn_param.conv2d.pad[0] = 0;
    node[118]->nn_param.conv2d.pad[1] = 0;
    node[118]->nn_param.conv2d.pad[2] = 0;
    node[118]->nn_param.conv2d.pad[3] = 0;
    node[118]->nn_param.conv2d.group = 1;
    node[118]->nn_param.conv2d.dilation[0] = 1;
    node[118]->nn_param.conv2d.dilation[1] = 1;
    node[118]->vx_param.has_relu = TRUE;
    node[118]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[118]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[118]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Conv2D_182_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Relu_178
      var       - node[119]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[119], VSI_NN_OP_CONV_RELU, 3, 1, 178);
    node[119]->nn_param.conv2d.ksize[0] = 1;
    node[119]->nn_param.conv2d.ksize[1] = 1;
    node[119]->nn_param.conv2d.weights = 192;
    node[119]->nn_param.conv2d.stride[0] = 1;
    node[119]->nn_param.conv2d.stride[1] = 1;
    node[119]->nn_param.conv2d.pad[0] = 0;
    node[119]->nn_param.conv2d.pad[1] = 0;
    node[119]->nn_param.conv2d.pad[2] = 0;
    node[119]->nn_param.conv2d.pad[3] = 0;
    node[119]->nn_param.conv2d.group = 1;
    node[119]->nn_param.conv2d.dilation[0] = 1;
    node[119]->nn_param.conv2d.dilation[1] = 1;
    node[119]->vx_param.has_relu = TRUE;
    node[119]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[119]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[119]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Conv2D_189_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Relu_187
      var       - node[120]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[120], VSI_NN_OP_CONV_RELU, 3, 1, 187);
    node[120]->nn_param.conv2d.ksize[0] = 1;
    node[120]->nn_param.conv2d.ksize[1] = 1;
    node[120]->nn_param.conv2d.weights = 192;
    node[120]->nn_param.conv2d.stride[0] = 1;
    node[120]->nn_param.conv2d.stride[1] = 1;
    node[120]->nn_param.conv2d.pad[0] = 0;
    node[120]->nn_param.conv2d.pad[1] = 0;
    node[120]->nn_param.conv2d.pad[2] = 0;
    node[120]->nn_param.conv2d.pad[3] = 0;
    node[120]->nn_param.conv2d.group = 1;
    node[120]->nn_param.conv2d.dilation[0] = 1;
    node[120]->nn_param.conv2d.dilation[1] = 1;
    node[120]->vx_param.has_relu = TRUE;
    node[120]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[120]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[120]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_6g/Branch_3/AvgPool_0a_3x3/AvgPool_173_conv_498
      var       - node[121]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[121], VSI_NN_OP_CONV_RELU, 3, 1, 498);
    node[121]->nn_param.conv2d.ksize[0] = 3;
    node[121]->nn_param.conv2d.ksize[1] = 3;
    node[121]->nn_param.conv2d.weights = 1024;
    node[121]->nn_param.conv2d.stride[0] = 1;
    node[121]->nn_param.conv2d.stride[1] = 1;
    node[121]->nn_param.conv2d.pad[0] = 1;
    node[121]->nn_param.conv2d.pad[1] = 1;
    node[121]->nn_param.conv2d.pad[2] = 1;
    node[121]->nn_param.conv2d.pad[3] = 1;
    node[121]->nn_param.conv2d.group = 1;
    node[121]->nn_param.conv2d.dilation[0] = 1;
    node[121]->nn_param.conv2d.dilation[1] = 1;
    node[121]->vx_param.has_relu = FALSE;
    node[121]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[121]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[121]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Conv2D_176_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Relu_171
      var       - node[122]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[122], VSI_NN_OP_CONV_RELU, 3, 1, 171);
    node[122]->nn_param.conv2d.ksize[0] = 7;
    node[122]->nn_param.conv2d.ksize[1] = 7;
    node[122]->nn_param.conv2d.weights = 224;
    node[122]->nn_param.conv2d.stride[0] = 1;
    node[122]->nn_param.conv2d.stride[1] = 1;
    node[122]->nn_param.conv2d.pad[0] = 3;
    node[122]->nn_param.conv2d.pad[1] = 3;
    node[122]->nn_param.conv2d.pad[2] = 3;
    node[122]->nn_param.conv2d.pad[3] = 3;
    node[122]->nn_param.conv2d.group = 1;
    node[122]->nn_param.conv2d.dilation[0] = 1;
    node[122]->nn_param.conv2d.dilation[1] = 1;
    node[122]->vx_param.has_relu = TRUE;
    node[122]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[122]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[122]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Conv2D_186_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Relu_184
      var       - node[123]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[123], VSI_NN_OP_CONV_RELU, 3, 1, 184);
    node[123]->nn_param.conv2d.ksize[0] = 1;
    node[123]->nn_param.conv2d.ksize[1] = 7;
    node[123]->nn_param.conv2d.weights = 192;
    node[123]->nn_param.conv2d.stride[0] = 1;
    node[123]->nn_param.conv2d.stride[1] = 1;
    node[123]->nn_param.conv2d.pad[0] = 0;
    node[123]->nn_param.conv2d.pad[1] = 0;
    node[123]->nn_param.conv2d.pad[2] = 3;
    node[123]->nn_param.conv2d.pad[3] = 3;
    node[123]->nn_param.conv2d.group = 1;
    node[123]->nn_param.conv2d.dilation[0] = 1;
    node[123]->nn_param.conv2d.dilation[1] = 1;
    node[123]->vx_param.has_relu = TRUE;
    node[123]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[123]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[123]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Conv2D_170_InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Relu_162
      var       - node[124]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[124], VSI_NN_OP_CONV_RELU, 3, 1, 162);
    node[124]->nn_param.conv2d.ksize[0] = 1;
    node[124]->nn_param.conv2d.ksize[1] = 1;
    node[124]->nn_param.conv2d.weights = 128;
    node[124]->nn_param.conv2d.stride[0] = 1;
    node[124]->nn_param.conv2d.stride[1] = 1;
    node[124]->nn_param.conv2d.pad[0] = 0;
    node[124]->nn_param.conv2d.pad[1] = 0;
    node[124]->nn_param.conv2d.pad[2] = 0;
    node[124]->nn_param.conv2d.pad[3] = 0;
    node[124]->nn_param.conv2d.group = 1;
    node[124]->nn_param.conv2d.dilation[0] = 1;
    node[124]->nn_param.conv2d.dilation[1] = 1;
    node[124]->vx_param.has_relu = TRUE;
    node[124]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[124]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[124]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Conv2D_168_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Relu_160
      var       - node[125]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[125], VSI_NN_OP_CONV_RELU, 3, 1, 160);
    node[125]->nn_param.conv2d.ksize[0] = 1;
    node[125]->nn_param.conv2d.ksize[1] = 7;
    node[125]->nn_param.conv2d.weights = 256;
    node[125]->nn_param.conv2d.stride[0] = 1;
    node[125]->nn_param.conv2d.stride[1] = 1;
    node[125]->nn_param.conv2d.pad[0] = 0;
    node[125]->nn_param.conv2d.pad[1] = 0;
    node[125]->nn_param.conv2d.pad[2] = 3;
    node[125]->nn_param.conv2d.pad[3] = 3;
    node[125]->nn_param.conv2d.group = 1;
    node[125]->nn_param.conv2d.dilation[0] = 1;
    node[125]->nn_param.conv2d.dilation[1] = 1;
    node[125]->vx_param.has_relu = TRUE;
    node[125]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[125]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[125]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Conv2D_183_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Relu_179
      var       - node[126]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[126], VSI_NN_OP_CONV_RELU, 3, 1, 179);
    node[126]->nn_param.conv2d.ksize[0] = 7;
    node[126]->nn_param.conv2d.ksize[1] = 7;
    node[126]->nn_param.conv2d.weights = 224;
    node[126]->nn_param.conv2d.stride[0] = 1;
    node[126]->nn_param.conv2d.stride[1] = 1;
    node[126]->nn_param.conv2d.pad[0] = 3;
    node[126]->nn_param.conv2d.pad[1] = 3;
    node[126]->nn_param.conv2d.pad[2] = 3;
    node[126]->nn_param.conv2d.pad[3] = 3;
    node[126]->nn_param.conv2d.group = 1;
    node[126]->nn_param.conv2d.dilation[0] = 1;
    node[126]->nn_param.conv2d.dilation[1] = 1;
    node[126]->vx_param.has_relu = TRUE;
    node[126]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[126]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[126]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Conv2D_177_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Relu_172
      var       - node[127]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[127], VSI_NN_OP_CONV_RELU, 3, 1, 172);
    node[127]->nn_param.conv2d.ksize[0] = 1;
    node[127]->nn_param.conv2d.ksize[1] = 7;
    node[127]->nn_param.conv2d.weights = 224;
    node[127]->nn_param.conv2d.stride[0] = 1;
    node[127]->nn_param.conv2d.stride[1] = 1;
    node[127]->nn_param.conv2d.pad[0] = 0;
    node[127]->nn_param.conv2d.pad[1] = 0;
    node[127]->nn_param.conv2d.pad[2] = 3;
    node[127]->nn_param.conv2d.pad[3] = 3;
    node[127]->nn_param.conv2d.group = 1;
    node[127]->nn_param.conv2d.dilation[0] = 1;
    node[127]->nn_param.conv2d.dilation[1] = 1;
    node[127]->vx_param.has_relu = TRUE;
    node[127]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[127]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[127]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Conv2D_169_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Relu_161
      var       - node[128]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[128], VSI_NN_OP_CONV_RELU, 3, 1, 161);
    node[128]->nn_param.conv2d.ksize[0] = 7;
    node[128]->nn_param.conv2d.ksize[1] = 7;
    node[128]->nn_param.conv2d.weights = 256;
    node[128]->nn_param.conv2d.stride[0] = 1;
    node[128]->nn_param.conv2d.stride[1] = 1;
    node[128]->nn_param.conv2d.pad[0] = 3;
    node[128]->nn_param.conv2d.pad[1] = 3;
    node[128]->nn_param.conv2d.pad[2] = 3;
    node[128]->nn_param.conv2d.pad[3] = 3;
    node[128]->nn_param.conv2d.group = 1;
    node[128]->nn_param.conv2d.dilation[0] = 1;
    node[128]->nn_param.conv2d.dilation[1] = 1;
    node[128]->vx_param.has_relu = TRUE;
    node[128]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[128]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[128]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6g/concat_158
      var       - node[129]
      name      - InceptionV4/InceptionV4/Mixed_6g/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 128, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[129], VSI_NN_OP_CONCAT, 4, 1, 158);
    node[129]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Conv2D_135_InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Relu_127
      var       - node[130]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[130], VSI_NN_OP_CONV_RELU, 3, 1, 127);
    node[130]->nn_param.conv2d.ksize[0] = 1;
    node[130]->nn_param.conv2d.ksize[1] = 1;
    node[130]->nn_param.conv2d.weights = 384;
    node[130]->nn_param.conv2d.stride[0] = 1;
    node[130]->nn_param.conv2d.stride[1] = 1;
    node[130]->nn_param.conv2d.pad[0] = 0;
    node[130]->nn_param.conv2d.pad[1] = 0;
    node[130]->nn_param.conv2d.pad[2] = 0;
    node[130]->nn_param.conv2d.pad[3] = 0;
    node[130]->nn_param.conv2d.group = 1;
    node[130]->nn_param.conv2d.dilation[0] = 1;
    node[130]->nn_param.conv2d.dilation[1] = 1;
    node[130]->vx_param.has_relu = TRUE;
    node[130]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[130]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[130]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Conv2D_150_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Relu_146
      var       - node[131]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[131], VSI_NN_OP_CONV_RELU, 3, 1, 146);
    node[131]->nn_param.conv2d.ksize[0] = 1;
    node[131]->nn_param.conv2d.ksize[1] = 1;
    node[131]->nn_param.conv2d.weights = 192;
    node[131]->nn_param.conv2d.stride[0] = 1;
    node[131]->nn_param.conv2d.stride[1] = 1;
    node[131]->nn_param.conv2d.pad[0] = 0;
    node[131]->nn_param.conv2d.pad[1] = 0;
    node[131]->nn_param.conv2d.pad[2] = 0;
    node[131]->nn_param.conv2d.pad[3] = 0;
    node[131]->nn_param.conv2d.group = 1;
    node[131]->nn_param.conv2d.dilation[0] = 1;
    node[131]->nn_param.conv2d.dilation[1] = 1;
    node[131]->vx_param.has_relu = TRUE;
    node[131]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[131]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[131]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Conv2D_157_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Relu_155
      var       - node[132]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[132], VSI_NN_OP_CONV_RELU, 3, 1, 155);
    node[132]->nn_param.conv2d.ksize[0] = 1;
    node[132]->nn_param.conv2d.ksize[1] = 1;
    node[132]->nn_param.conv2d.weights = 192;
    node[132]->nn_param.conv2d.stride[0] = 1;
    node[132]->nn_param.conv2d.stride[1] = 1;
    node[132]->nn_param.conv2d.pad[0] = 0;
    node[132]->nn_param.conv2d.pad[1] = 0;
    node[132]->nn_param.conv2d.pad[2] = 0;
    node[132]->nn_param.conv2d.pad[3] = 0;
    node[132]->nn_param.conv2d.group = 1;
    node[132]->nn_param.conv2d.dilation[0] = 1;
    node[132]->nn_param.conv2d.dilation[1] = 1;
    node[132]->vx_param.has_relu = TRUE;
    node[132]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[132]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[132]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_6h/Branch_3/AvgPool_0a_3x3/AvgPool_141_conv_497
      var       - node[133]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[133], VSI_NN_OP_CONV_RELU, 3, 1, 497);
    node[133]->nn_param.conv2d.ksize[0] = 3;
    node[133]->nn_param.conv2d.ksize[1] = 3;
    node[133]->nn_param.conv2d.weights = 1024;
    node[133]->nn_param.conv2d.stride[0] = 1;
    node[133]->nn_param.conv2d.stride[1] = 1;
    node[133]->nn_param.conv2d.pad[0] = 1;
    node[133]->nn_param.conv2d.pad[1] = 1;
    node[133]->nn_param.conv2d.pad[2] = 1;
    node[133]->nn_param.conv2d.pad[3] = 1;
    node[133]->nn_param.conv2d.group = 1;
    node[133]->nn_param.conv2d.dilation[0] = 1;
    node[133]->nn_param.conv2d.dilation[1] = 1;
    node[133]->vx_param.has_relu = FALSE;
    node[133]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[133]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[133]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Conv2D_144_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Relu_139
      var       - node[134]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[134], VSI_NN_OP_CONV_RELU, 3, 1, 139);
    node[134]->nn_param.conv2d.ksize[0] = 7;
    node[134]->nn_param.conv2d.ksize[1] = 7;
    node[134]->nn_param.conv2d.weights = 224;
    node[134]->nn_param.conv2d.stride[0] = 1;
    node[134]->nn_param.conv2d.stride[1] = 1;
    node[134]->nn_param.conv2d.pad[0] = 3;
    node[134]->nn_param.conv2d.pad[1] = 3;
    node[134]->nn_param.conv2d.pad[2] = 3;
    node[134]->nn_param.conv2d.pad[3] = 3;
    node[134]->nn_param.conv2d.group = 1;
    node[134]->nn_param.conv2d.dilation[0] = 1;
    node[134]->nn_param.conv2d.dilation[1] = 1;
    node[134]->vx_param.has_relu = TRUE;
    node[134]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[134]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[134]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Conv2D_154_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Relu_152
      var       - node[135]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[135], VSI_NN_OP_CONV_RELU, 3, 1, 152);
    node[135]->nn_param.conv2d.ksize[0] = 1;
    node[135]->nn_param.conv2d.ksize[1] = 7;
    node[135]->nn_param.conv2d.weights = 192;
    node[135]->nn_param.conv2d.stride[0] = 1;
    node[135]->nn_param.conv2d.stride[1] = 1;
    node[135]->nn_param.conv2d.pad[0] = 0;
    node[135]->nn_param.conv2d.pad[1] = 0;
    node[135]->nn_param.conv2d.pad[2] = 3;
    node[135]->nn_param.conv2d.pad[3] = 3;
    node[135]->nn_param.conv2d.group = 1;
    node[135]->nn_param.conv2d.dilation[0] = 1;
    node[135]->nn_param.conv2d.dilation[1] = 1;
    node[135]->vx_param.has_relu = TRUE;
    node[135]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[135]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[135]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Conv2D_138_InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Relu_130
      var       - node[136]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 128, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[136], VSI_NN_OP_CONV_RELU, 3, 1, 130);
    node[136]->nn_param.conv2d.ksize[0] = 1;
    node[136]->nn_param.conv2d.ksize[1] = 1;
    node[136]->nn_param.conv2d.weights = 128;
    node[136]->nn_param.conv2d.stride[0] = 1;
    node[136]->nn_param.conv2d.stride[1] = 1;
    node[136]->nn_param.conv2d.pad[0] = 0;
    node[136]->nn_param.conv2d.pad[1] = 0;
    node[136]->nn_param.conv2d.pad[2] = 0;
    node[136]->nn_param.conv2d.pad[3] = 0;
    node[136]->nn_param.conv2d.group = 1;
    node[136]->nn_param.conv2d.dilation[0] = 1;
    node[136]->nn_param.conv2d.dilation[1] = 1;
    node[136]->vx_param.has_relu = TRUE;
    node[136]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[136]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[136]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Conv2D_136_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Relu_128
      var       - node[137]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[137], VSI_NN_OP_CONV_RELU, 3, 1, 128);
    node[137]->nn_param.conv2d.ksize[0] = 1;
    node[137]->nn_param.conv2d.ksize[1] = 7;
    node[137]->nn_param.conv2d.weights = 256;
    node[137]->nn_param.conv2d.stride[0] = 1;
    node[137]->nn_param.conv2d.stride[1] = 1;
    node[137]->nn_param.conv2d.pad[0] = 0;
    node[137]->nn_param.conv2d.pad[1] = 0;
    node[137]->nn_param.conv2d.pad[2] = 3;
    node[137]->nn_param.conv2d.pad[3] = 3;
    node[137]->nn_param.conv2d.group = 1;
    node[137]->nn_param.conv2d.dilation[0] = 1;
    node[137]->nn_param.conv2d.dilation[1] = 1;
    node[137]->vx_param.has_relu = TRUE;
    node[137]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[137]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[137]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Conv2D_151_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Relu_147
      var       - node[138]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[138], VSI_NN_OP_CONV_RELU, 3, 1, 147);
    node[138]->nn_param.conv2d.ksize[0] = 7;
    node[138]->nn_param.conv2d.ksize[1] = 7;
    node[138]->nn_param.conv2d.weights = 224;
    node[138]->nn_param.conv2d.stride[0] = 1;
    node[138]->nn_param.conv2d.stride[1] = 1;
    node[138]->nn_param.conv2d.pad[0] = 3;
    node[138]->nn_param.conv2d.pad[1] = 3;
    node[138]->nn_param.conv2d.pad[2] = 3;
    node[138]->nn_param.conv2d.pad[3] = 3;
    node[138]->nn_param.conv2d.group = 1;
    node[138]->nn_param.conv2d.dilation[0] = 1;
    node[138]->nn_param.conv2d.dilation[1] = 1;
    node[138]->vx_param.has_relu = TRUE;
    node[138]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[138]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[138]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Conv2D_145_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Relu_140
      var       - node[139]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 224, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[139], VSI_NN_OP_CONV_RELU, 3, 1, 140);
    node[139]->nn_param.conv2d.ksize[0] = 1;
    node[139]->nn_param.conv2d.ksize[1] = 7;
    node[139]->nn_param.conv2d.weights = 224;
    node[139]->nn_param.conv2d.stride[0] = 1;
    node[139]->nn_param.conv2d.stride[1] = 1;
    node[139]->nn_param.conv2d.pad[0] = 0;
    node[139]->nn_param.conv2d.pad[1] = 0;
    node[139]->nn_param.conv2d.pad[2] = 3;
    node[139]->nn_param.conv2d.pad[3] = 3;
    node[139]->nn_param.conv2d.group = 1;
    node[139]->nn_param.conv2d.dilation[0] = 1;
    node[139]->nn_param.conv2d.dilation[1] = 1;
    node[139]->vx_param.has_relu = TRUE;
    node[139]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[139]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[139]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Conv2D_137_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Relu_129
      var       - node[140]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 224, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[140], VSI_NN_OP_CONV_RELU, 3, 1, 129);
    node[140]->nn_param.conv2d.ksize[0] = 7;
    node[140]->nn_param.conv2d.ksize[1] = 7;
    node[140]->nn_param.conv2d.weights = 256;
    node[140]->nn_param.conv2d.stride[0] = 1;
    node[140]->nn_param.conv2d.stride[1] = 1;
    node[140]->nn_param.conv2d.pad[0] = 3;
    node[140]->nn_param.conv2d.pad[1] = 3;
    node[140]->nn_param.conv2d.pad[2] = 3;
    node[140]->nn_param.conv2d.pad[3] = 3;
    node[140]->nn_param.conv2d.group = 1;
    node[140]->nn_param.conv2d.dilation[0] = 1;
    node[140]->nn_param.conv2d.dilation[1] = 1;
    node[140]->vx_param.has_relu = TRUE;
    node[140]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[140]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[140]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_6h/concat_126
      var       - node[141]
      name      - InceptionV4/InceptionV4/Mixed_6h/concat
      operation - concat
      in_shape  - [[17, 17, 384, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 256, 1]]
                  [[17, 17, 128, 1]]
      out_shape - [[17, 17, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[141], VSI_NN_OP_CONCAT, 4, 1, 126);
    node[141]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7a/Branch_2/MaxPool_1a_3x3/MaxPool_109
      var       - node[142]
      name      - InceptionV4/InceptionV4/Mixed_7a/Branch_2/MaxPool_1a_3x3/MaxPool
      operation - pooling
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[8, 8, 1024, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[142], VSI_NN_OP_POOL, 1, 1, 109);
    node[142]->nn_param.pool.ksize[0] = 3;
    node[142]->nn_param.pool.ksize[1] = 3;
    node[142]->nn_param.pool.stride[0] = 2;
    node[142]->nn_param.pool.stride[1] = 2;
    node[142]->nn_param.pool.pad[0] = 0;
    node[142]->nn_param.pool.pad[1] = 0;
    node[142]->nn_param.pool.pad[2] = 0;
    node[142]->nn_param.pool.pad[3] = 0;
    node[142]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[142]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[142]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_118_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_114
      var       - node[143]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[143], VSI_NN_OP_CONV_RELU, 3, 1, 114);
    node[143]->nn_param.conv2d.ksize[0] = 1;
    node[143]->nn_param.conv2d.ksize[1] = 1;
    node[143]->nn_param.conv2d.weights = 192;
    node[143]->nn_param.conv2d.stride[0] = 1;
    node[143]->nn_param.conv2d.stride[1] = 1;
    node[143]->nn_param.conv2d.pad[0] = 0;
    node[143]->nn_param.conv2d.pad[1] = 0;
    node[143]->nn_param.conv2d.pad[2] = 0;
    node[143]->nn_param.conv2d.pad[3] = 0;
    node[143]->nn_param.conv2d.group = 1;
    node[143]->nn_param.conv2d.dilation[0] = 1;
    node[143]->nn_param.conv2d.dilation[1] = 1;
    node[143]->vx_param.has_relu = TRUE;
    node[143]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[143]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[143]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_125_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_123
      var       - node[144]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 1024, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[144], VSI_NN_OP_CONV_RELU, 3, 1, 123);
    node[144]->nn_param.conv2d.ksize[0] = 1;
    node[144]->nn_param.conv2d.ksize[1] = 1;
    node[144]->nn_param.conv2d.weights = 256;
    node[144]->nn_param.conv2d.stride[0] = 1;
    node[144]->nn_param.conv2d.stride[1] = 1;
    node[144]->nn_param.conv2d.pad[0] = 0;
    node[144]->nn_param.conv2d.pad[1] = 0;
    node[144]->nn_param.conv2d.pad[2] = 0;
    node[144]->nn_param.conv2d.pad[3] = 0;
    node[144]->nn_param.conv2d.group = 1;
    node[144]->nn_param.conv2d.dilation[0] = 1;
    node[144]->nn_param.conv2d.dilation[1] = 1;
    node[144]->vx_param.has_relu = TRUE;
    node[144]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[144]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[144]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_112_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_107
      var       - node[145]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 192, 1]]
      out_shape - [[8, 8, 192, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[145], VSI_NN_OP_CONV_RELU, 3, 1, 107);
    node[145]->nn_param.conv2d.ksize[0] = 3;
    node[145]->nn_param.conv2d.ksize[1] = 3;
    node[145]->nn_param.conv2d.weights = 192;
    node[145]->nn_param.conv2d.stride[0] = 2;
    node[145]->nn_param.conv2d.stride[1] = 2;
    node[145]->nn_param.conv2d.pad[0] = 0;
    node[145]->nn_param.conv2d.pad[1] = 0;
    node[145]->nn_param.conv2d.pad[2] = 0;
    node[145]->nn_param.conv2d.pad[3] = 0;
    node[145]->nn_param.conv2d.group = 1;
    node[145]->nn_param.conv2d.dilation[0] = 1;
    node[145]->nn_param.conv2d.dilation[1] = 1;
    node[145]->vx_param.has_relu = TRUE;
    node[145]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[145]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[145]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_122_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_120
      var       - node[146]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 256, 1]]
      out_shape - [[17, 17, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[146], VSI_NN_OP_CONV_RELU, 3, 1, 120);
    node[146]->nn_param.conv2d.ksize[0] = 7;
    node[146]->nn_param.conv2d.ksize[1] = 7;
    node[146]->nn_param.conv2d.weights = 256;
    node[146]->nn_param.conv2d.stride[0] = 1;
    node[146]->nn_param.conv2d.stride[1] = 1;
    node[146]->nn_param.conv2d.pad[0] = 3;
    node[146]->nn_param.conv2d.pad[1] = 3;
    node[146]->nn_param.conv2d.pad[2] = 3;
    node[146]->nn_param.conv2d.pad[3] = 3;
    node[146]->nn_param.conv2d.group = 1;
    node[146]->nn_param.conv2d.dilation[0] = 1;
    node[146]->nn_param.conv2d.dilation[1] = 1;
    node[146]->vx_param.has_relu = TRUE;
    node[146]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[146]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[146]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_119_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_115
      var       - node[147]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 256, 1]]
      out_shape - [[17, 17, 320, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[147], VSI_NN_OP_CONV_RELU, 3, 1, 115);
    node[147]->nn_param.conv2d.ksize[0] = 1;
    node[147]->nn_param.conv2d.ksize[1] = 7;
    node[147]->nn_param.conv2d.weights = 320;
    node[147]->nn_param.conv2d.stride[0] = 1;
    node[147]->nn_param.conv2d.stride[1] = 1;
    node[147]->nn_param.conv2d.pad[0] = 0;
    node[147]->nn_param.conv2d.pad[1] = 0;
    node[147]->nn_param.conv2d.pad[2] = 3;
    node[147]->nn_param.conv2d.pad[3] = 3;
    node[147]->nn_param.conv2d.group = 1;
    node[147]->nn_param.conv2d.dilation[0] = 1;
    node[147]->nn_param.conv2d.dilation[1] = 1;
    node[147]->vx_param.has_relu = TRUE;
    node[147]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[147]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[147]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_113_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_108
      var       - node[148]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[17, 17, 320, 1]]
      out_shape - [[8, 8, 320, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[148], VSI_NN_OP_CONV_RELU, 3, 1, 108);
    node[148]->nn_param.conv2d.ksize[0] = 3;
    node[148]->nn_param.conv2d.ksize[1] = 3;
    node[148]->nn_param.conv2d.weights = 320;
    node[148]->nn_param.conv2d.stride[0] = 2;
    node[148]->nn_param.conv2d.stride[1] = 2;
    node[148]->nn_param.conv2d.pad[0] = 0;
    node[148]->nn_param.conv2d.pad[1] = 0;
    node[148]->nn_param.conv2d.pad[2] = 0;
    node[148]->nn_param.conv2d.pad[3] = 0;
    node[148]->nn_param.conv2d.group = 1;
    node[148]->nn_param.conv2d.dilation[0] = 1;
    node[148]->nn_param.conv2d.dilation[1] = 1;
    node[148]->vx_param.has_relu = TRUE;
    node[148]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[148]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[148]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7a/concat_106
      var       - node[149]
      name      - InceptionV4/InceptionV4/Mixed_7a/concat
      operation - concat
      in_shape  - [[8, 8, 192, 1]]
                  [[8, 8, 320, 1]]
                  [[8, 8, 1024, 1]]
      out_shape - [[8, 8, 1536, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[149], VSI_NN_OP_CONCAT, 3, 1, 106);
    node[149]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_83_InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_73
      var       - node[150]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[150], VSI_NN_OP_CONV_RELU, 3, 1, 73);
    node[150]->nn_param.conv2d.ksize[0] = 1;
    node[150]->nn_param.conv2d.ksize[1] = 1;
    node[150]->nn_param.conv2d.weights = 256;
    node[150]->nn_param.conv2d.stride[0] = 1;
    node[150]->nn_param.conv2d.stride[1] = 1;
    node[150]->nn_param.conv2d.pad[0] = 0;
    node[150]->nn_param.conv2d.pad[1] = 0;
    node[150]->nn_param.conv2d.pad[2] = 0;
    node[150]->nn_param.conv2d.pad[3] = 0;
    node[150]->nn_param.conv2d.group = 1;
    node[150]->nn_param.conv2d.dilation[0] = 1;
    node[150]->nn_param.conv2d.dilation[1] = 1;
    node[150]->vx_param.has_relu = TRUE;
    node[150]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[150]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[150]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_98_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_94
      var       - node[151]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[151], VSI_NN_OP_CONV_RELU, 3, 1, 94);
    node[151]->nn_param.conv2d.ksize[0] = 1;
    node[151]->nn_param.conv2d.ksize[1] = 1;
    node[151]->nn_param.conv2d.weights = 384;
    node[151]->nn_param.conv2d.stride[0] = 1;
    node[151]->nn_param.conv2d.stride[1] = 1;
    node[151]->nn_param.conv2d.pad[0] = 0;
    node[151]->nn_param.conv2d.pad[1] = 0;
    node[151]->nn_param.conv2d.pad[2] = 0;
    node[151]->nn_param.conv2d.pad[3] = 0;
    node[151]->nn_param.conv2d.group = 1;
    node[151]->nn_param.conv2d.dilation[0] = 1;
    node[151]->nn_param.conv2d.dilation[1] = 1;
    node[151]->vx_param.has_relu = TRUE;
    node[151]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[151]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[151]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_105_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_103
      var       - node[152]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[152], VSI_NN_OP_CONV_RELU, 3, 1, 103);
    node[152]->nn_param.conv2d.ksize[0] = 1;
    node[152]->nn_param.conv2d.ksize[1] = 1;
    node[152]->nn_param.conv2d.weights = 384;
    node[152]->nn_param.conv2d.stride[0] = 1;
    node[152]->nn_param.conv2d.stride[1] = 1;
    node[152]->nn_param.conv2d.pad[0] = 0;
    node[152]->nn_param.conv2d.pad[1] = 0;
    node[152]->nn_param.conv2d.pad[2] = 0;
    node[152]->nn_param.conv2d.pad[3] = 0;
    node[152]->nn_param.conv2d.group = 1;
    node[152]->nn_param.conv2d.dilation[0] = 1;
    node[152]->nn_param.conv2d.dilation[1] = 1;
    node[152]->vx_param.has_relu = TRUE;
    node[152]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[152]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[152]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_93_conv_496
      var       - node[153]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 1536, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[153], VSI_NN_OP_CONV_RELU, 3, 1, 496);
    node[153]->nn_param.conv2d.ksize[0] = 3;
    node[153]->nn_param.conv2d.ksize[1] = 3;
    node[153]->nn_param.conv2d.weights = 1536;
    node[153]->nn_param.conv2d.stride[0] = 1;
    node[153]->nn_param.conv2d.stride[1] = 1;
    node[153]->nn_param.conv2d.pad[0] = 1;
    node[153]->nn_param.conv2d.pad[1] = 1;
    node[153]->nn_param.conv2d.pad[2] = 1;
    node[153]->nn_param.conv2d.pad[3] = 1;
    node[153]->nn_param.conv2d.group = 1;
    node[153]->nn_param.conv2d.dilation[0] = 1;
    node[153]->nn_param.conv2d.dilation[1] = 1;
    node[153]->vx_param.has_relu = FALSE;
    node[153]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[153]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[153]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_89_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_78
      var       - node[154]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[154], VSI_NN_OP_CONV_RELU, 3, 1, 78);
    node[154]->nn_param.conv2d.ksize[0] = 3;
    node[154]->nn_param.conv2d.ksize[1] = 3;
    node[154]->nn_param.conv2d.weights = 256;
    node[154]->nn_param.conv2d.stride[0] = 1;
    node[154]->nn_param.conv2d.stride[1] = 1;
    node[154]->nn_param.conv2d.pad[0] = 1;
    node[154]->nn_param.conv2d.pad[1] = 1;
    node[154]->nn_param.conv2d.pad[2] = 1;
    node[154]->nn_param.conv2d.pad[3] = 1;
    node[154]->nn_param.conv2d.group = 1;
    node[154]->nn_param.conv2d.dilation[0] = 1;
    node[154]->nn_param.conv2d.dilation[1] = 1;
    node[154]->vx_param.has_relu = TRUE;
    node[154]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[154]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[154]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Conv2D_90_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Relu_79
      var       - node[155]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[155], VSI_NN_OP_CONV_RELU, 3, 1, 79);
    node[155]->nn_param.conv2d.ksize[0] = 1;
    node[155]->nn_param.conv2d.ksize[1] = 3;
    node[155]->nn_param.conv2d.weights = 256;
    node[155]->nn_param.conv2d.stride[0] = 1;
    node[155]->nn_param.conv2d.stride[1] = 1;
    node[155]->nn_param.conv2d.pad[0] = 0;
    node[155]->nn_param.conv2d.pad[1] = 0;
    node[155]->nn_param.conv2d.pad[2] = 1;
    node[155]->nn_param.conv2d.pad[3] = 1;
    node[155]->nn_param.conv2d.group = 1;
    node[155]->nn_param.conv2d.dilation[0] = 1;
    node[155]->nn_param.conv2d.dilation[1] = 1;
    node[155]->vx_param.has_relu = TRUE;
    node[155]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[155]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[155]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Conv2D_102_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Relu_100
      var       - node[156]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 448, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[156], VSI_NN_OP_CONV_RELU, 3, 1, 100);
    node[156]->nn_param.conv2d.ksize[0] = 1;
    node[156]->nn_param.conv2d.ksize[1] = 3;
    node[156]->nn_param.conv2d.weights = 448;
    node[156]->nn_param.conv2d.stride[0] = 1;
    node[156]->nn_param.conv2d.stride[1] = 1;
    node[156]->nn_param.conv2d.pad[0] = 0;
    node[156]->nn_param.conv2d.pad[1] = 0;
    node[156]->nn_param.conv2d.pad[2] = 1;
    node[156]->nn_param.conv2d.pad[3] = 1;
    node[156]->nn_param.conv2d.group = 1;
    node[156]->nn_param.conv2d.dilation[0] = 1;
    node[156]->nn_param.conv2d.dilation[1] = 1;
    node[156]->vx_param.has_relu = TRUE;
    node[156]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[156]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[156]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_88_InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_76
      var       - node[157]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[157], VSI_NN_OP_CONV_RELU, 3, 1, 76);
    node[157]->nn_param.conv2d.ksize[0] = 1;
    node[157]->nn_param.conv2d.ksize[1] = 1;
    node[157]->nn_param.conv2d.weights = 256;
    node[157]->nn_param.conv2d.stride[0] = 1;
    node[157]->nn_param.conv2d.stride[1] = 1;
    node[157]->nn_param.conv2d.pad[0] = 0;
    node[157]->nn_param.conv2d.pad[1] = 0;
    node[157]->nn_param.conv2d.pad[2] = 0;
    node[157]->nn_param.conv2d.pad[3] = 0;
    node[157]->nn_param.conv2d.group = 1;
    node[157]->nn_param.conv2d.dilation[0] = 1;
    node[157]->nn_param.conv2d.dilation[1] = 1;
    node[157]->vx_param.has_relu = TRUE;
    node[157]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[157]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[157]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_1/concat_74
      var       - node[158]
      name      - InceptionV4/InceptionV4/Mixed_7b/Branch_1/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[158], VSI_NN_OP_CONCAT, 2, 1, 74);
    node[158]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_99_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_95
      var       - node[159]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 448, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[159], VSI_NN_OP_CONV_RELU, 3, 1, 95);
    node[159]->nn_param.conv2d.ksize[0] = 3;
    node[159]->nn_param.conv2d.ksize[1] = 3;
    node[159]->nn_param.conv2d.weights = 512;
    node[159]->nn_param.conv2d.stride[0] = 1;
    node[159]->nn_param.conv2d.stride[1] = 1;
    node[159]->nn_param.conv2d.pad[0] = 1;
    node[159]->nn_param.conv2d.pad[1] = 1;
    node[159]->nn_param.conv2d.pad[2] = 1;
    node[159]->nn_param.conv2d.pad[3] = 1;
    node[159]->nn_param.conv2d.group = 1;
    node[159]->nn_param.conv2d.dilation[0] = 1;
    node[159]->nn_param.conv2d.dilation[1] = 1;
    node[159]->vx_param.has_relu = TRUE;
    node[159]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[159]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[159]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Conv2D_91_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Relu_80
      var       - node[160]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 512, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[160], VSI_NN_OP_CONV_RELU, 3, 1, 80);
    node[160]->nn_param.conv2d.ksize[0] = 3;
    node[160]->nn_param.conv2d.ksize[1] = 3;
    node[160]->nn_param.conv2d.weights = 256;
    node[160]->nn_param.conv2d.stride[0] = 1;
    node[160]->nn_param.conv2d.stride[1] = 1;
    node[160]->nn_param.conv2d.pad[0] = 1;
    node[160]->nn_param.conv2d.pad[1] = 1;
    node[160]->nn_param.conv2d.pad[2] = 1;
    node[160]->nn_param.conv2d.pad[3] = 1;
    node[160]->nn_param.conv2d.group = 1;
    node[160]->nn_param.conv2d.dilation[0] = 1;
    node[160]->nn_param.conv2d.dilation[1] = 1;
    node[160]->vx_param.has_relu = TRUE;
    node[160]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[160]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[160]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Conv2D_92_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Relu_81
      var       - node[161]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 512, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[161], VSI_NN_OP_CONV_RELU, 3, 1, 81);
    node[161]->nn_param.conv2d.ksize[0] = 1;
    node[161]->nn_param.conv2d.ksize[1] = 3;
    node[161]->nn_param.conv2d.weights = 256;
    node[161]->nn_param.conv2d.stride[0] = 1;
    node[161]->nn_param.conv2d.stride[1] = 1;
    node[161]->nn_param.conv2d.pad[0] = 0;
    node[161]->nn_param.conv2d.pad[1] = 0;
    node[161]->nn_param.conv2d.pad[2] = 1;
    node[161]->nn_param.conv2d.pad[3] = 1;
    node[161]->nn_param.conv2d.group = 1;
    node[161]->nn_param.conv2d.dilation[0] = 1;
    node[161]->nn_param.conv2d.dilation[1] = 1;
    node[161]->vx_param.has_relu = TRUE;
    node[161]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[161]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[161]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/Branch_2/concat_75
      var       - node[162]
      name      - InceptionV4/InceptionV4/Mixed_7b/Branch_2/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[162], VSI_NN_OP_CONCAT, 2, 1, 75);
    node[162]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7b/concat_72
      var       - node[163]
      name      - InceptionV4/InceptionV4/Mixed_7b/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 512, 1]]
                  [[8, 8, 512, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 1536, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[163], VSI_NN_OP_CONCAT, 4, 1, 72);
    node[163]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_49_InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_39
      var       - node[164]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[164], VSI_NN_OP_CONV_RELU, 3, 1, 39);
    node[164]->nn_param.conv2d.ksize[0] = 1;
    node[164]->nn_param.conv2d.ksize[1] = 1;
    node[164]->nn_param.conv2d.weights = 256;
    node[164]->nn_param.conv2d.stride[0] = 1;
    node[164]->nn_param.conv2d.stride[1] = 1;
    node[164]->nn_param.conv2d.pad[0] = 0;
    node[164]->nn_param.conv2d.pad[1] = 0;
    node[164]->nn_param.conv2d.pad[2] = 0;
    node[164]->nn_param.conv2d.pad[3] = 0;
    node[164]->nn_param.conv2d.group = 1;
    node[164]->nn_param.conv2d.dilation[0] = 1;
    node[164]->nn_param.conv2d.dilation[1] = 1;
    node[164]->vx_param.has_relu = TRUE;
    node[164]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[164]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[164]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_64_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_60
      var       - node[165]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[165], VSI_NN_OP_CONV_RELU, 3, 1, 60);
    node[165]->nn_param.conv2d.ksize[0] = 1;
    node[165]->nn_param.conv2d.ksize[1] = 1;
    node[165]->nn_param.conv2d.weights = 384;
    node[165]->nn_param.conv2d.stride[0] = 1;
    node[165]->nn_param.conv2d.stride[1] = 1;
    node[165]->nn_param.conv2d.pad[0] = 0;
    node[165]->nn_param.conv2d.pad[1] = 0;
    node[165]->nn_param.conv2d.pad[2] = 0;
    node[165]->nn_param.conv2d.pad[3] = 0;
    node[165]->nn_param.conv2d.group = 1;
    node[165]->nn_param.conv2d.dilation[0] = 1;
    node[165]->nn_param.conv2d.dilation[1] = 1;
    node[165]->vx_param.has_relu = TRUE;
    node[165]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[165]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[165]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_71_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_69
      var       - node[166]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[166], VSI_NN_OP_CONV_RELU, 3, 1, 69);
    node[166]->nn_param.conv2d.ksize[0] = 1;
    node[166]->nn_param.conv2d.ksize[1] = 1;
    node[166]->nn_param.conv2d.weights = 384;
    node[166]->nn_param.conv2d.stride[0] = 1;
    node[166]->nn_param.conv2d.stride[1] = 1;
    node[166]->nn_param.conv2d.pad[0] = 0;
    node[166]->nn_param.conv2d.pad[1] = 0;
    node[166]->nn_param.conv2d.pad[2] = 0;
    node[166]->nn_param.conv2d.pad[3] = 0;
    node[166]->nn_param.conv2d.group = 1;
    node[166]->nn_param.conv2d.dilation[0] = 1;
    node[166]->nn_param.conv2d.dilation[1] = 1;
    node[166]->vx_param.has_relu = TRUE;
    node[166]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[166]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[166]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_59_conv_495
      var       - node[167]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 1536, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[167], VSI_NN_OP_CONV_RELU, 3, 1, 495);
    node[167]->nn_param.conv2d.ksize[0] = 3;
    node[167]->nn_param.conv2d.ksize[1] = 3;
    node[167]->nn_param.conv2d.weights = 1536;
    node[167]->nn_param.conv2d.stride[0] = 1;
    node[167]->nn_param.conv2d.stride[1] = 1;
    node[167]->nn_param.conv2d.pad[0] = 1;
    node[167]->nn_param.conv2d.pad[1] = 1;
    node[167]->nn_param.conv2d.pad[2] = 1;
    node[167]->nn_param.conv2d.pad[3] = 1;
    node[167]->nn_param.conv2d.group = 1;
    node[167]->nn_param.conv2d.dilation[0] = 1;
    node[167]->nn_param.conv2d.dilation[1] = 1;
    node[167]->vx_param.has_relu = FALSE;
    node[167]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[167]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[167]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_55_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_44
      var       - node[168]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[168], VSI_NN_OP_CONV_RELU, 3, 1, 44);
    node[168]->nn_param.conv2d.ksize[0] = 3;
    node[168]->nn_param.conv2d.ksize[1] = 3;
    node[168]->nn_param.conv2d.weights = 256;
    node[168]->nn_param.conv2d.stride[0] = 1;
    node[168]->nn_param.conv2d.stride[1] = 1;
    node[168]->nn_param.conv2d.pad[0] = 1;
    node[168]->nn_param.conv2d.pad[1] = 1;
    node[168]->nn_param.conv2d.pad[2] = 1;
    node[168]->nn_param.conv2d.pad[3] = 1;
    node[168]->nn_param.conv2d.group = 1;
    node[168]->nn_param.conv2d.dilation[0] = 1;
    node[168]->nn_param.conv2d.dilation[1] = 1;
    node[168]->vx_param.has_relu = TRUE;
    node[168]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[168]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[168]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_56_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_45
      var       - node[169]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[169], VSI_NN_OP_CONV_RELU, 3, 1, 45);
    node[169]->nn_param.conv2d.ksize[0] = 1;
    node[169]->nn_param.conv2d.ksize[1] = 3;
    node[169]->nn_param.conv2d.weights = 256;
    node[169]->nn_param.conv2d.stride[0] = 1;
    node[169]->nn_param.conv2d.stride[1] = 1;
    node[169]->nn_param.conv2d.pad[0] = 0;
    node[169]->nn_param.conv2d.pad[1] = 0;
    node[169]->nn_param.conv2d.pad[2] = 1;
    node[169]->nn_param.conv2d.pad[3] = 1;
    node[169]->nn_param.conv2d.group = 1;
    node[169]->nn_param.conv2d.dilation[0] = 1;
    node[169]->nn_param.conv2d.dilation[1] = 1;
    node[169]->vx_param.has_relu = TRUE;
    node[169]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[169]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[169]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Conv2D_68_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Relu_66
      var       - node[170]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 448, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[170], VSI_NN_OP_CONV_RELU, 3, 1, 66);
    node[170]->nn_param.conv2d.ksize[0] = 1;
    node[170]->nn_param.conv2d.ksize[1] = 3;
    node[170]->nn_param.conv2d.weights = 448;
    node[170]->nn_param.conv2d.stride[0] = 1;
    node[170]->nn_param.conv2d.stride[1] = 1;
    node[170]->nn_param.conv2d.pad[0] = 0;
    node[170]->nn_param.conv2d.pad[1] = 0;
    node[170]->nn_param.conv2d.pad[2] = 1;
    node[170]->nn_param.conv2d.pad[3] = 1;
    node[170]->nn_param.conv2d.group = 1;
    node[170]->nn_param.conv2d.dilation[0] = 1;
    node[170]->nn_param.conv2d.dilation[1] = 1;
    node[170]->vx_param.has_relu = TRUE;
    node[170]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[170]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[170]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_54_InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_42
      var       - node[171]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[171], VSI_NN_OP_CONV_RELU, 3, 1, 42);
    node[171]->nn_param.conv2d.ksize[0] = 1;
    node[171]->nn_param.conv2d.ksize[1] = 1;
    node[171]->nn_param.conv2d.weights = 256;
    node[171]->nn_param.conv2d.stride[0] = 1;
    node[171]->nn_param.conv2d.stride[1] = 1;
    node[171]->nn_param.conv2d.pad[0] = 0;
    node[171]->nn_param.conv2d.pad[1] = 0;
    node[171]->nn_param.conv2d.pad[2] = 0;
    node[171]->nn_param.conv2d.pad[3] = 0;
    node[171]->nn_param.conv2d.group = 1;
    node[171]->nn_param.conv2d.dilation[0] = 1;
    node[171]->nn_param.conv2d.dilation[1] = 1;
    node[171]->vx_param.has_relu = TRUE;
    node[171]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[171]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[171]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_1/concat_40
      var       - node[172]
      name      - InceptionV4/InceptionV4/Mixed_7c/Branch_1/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[172], VSI_NN_OP_CONCAT, 2, 1, 40);
    node[172]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_65_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_61
      var       - node[173]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 448, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[173], VSI_NN_OP_CONV_RELU, 3, 1, 61);
    node[173]->nn_param.conv2d.ksize[0] = 3;
    node[173]->nn_param.conv2d.ksize[1] = 3;
    node[173]->nn_param.conv2d.weights = 512;
    node[173]->nn_param.conv2d.stride[0] = 1;
    node[173]->nn_param.conv2d.stride[1] = 1;
    node[173]->nn_param.conv2d.pad[0] = 1;
    node[173]->nn_param.conv2d.pad[1] = 1;
    node[173]->nn_param.conv2d.pad[2] = 1;
    node[173]->nn_param.conv2d.pad[3] = 1;
    node[173]->nn_param.conv2d.group = 1;
    node[173]->nn_param.conv2d.dilation[0] = 1;
    node[173]->nn_param.conv2d.dilation[1] = 1;
    node[173]->vx_param.has_relu = TRUE;
    node[173]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[173]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[173]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Conv2D_57_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Relu_46
      var       - node[174]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 512, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[174], VSI_NN_OP_CONV_RELU, 3, 1, 46);
    node[174]->nn_param.conv2d.ksize[0] = 3;
    node[174]->nn_param.conv2d.ksize[1] = 3;
    node[174]->nn_param.conv2d.weights = 256;
    node[174]->nn_param.conv2d.stride[0] = 1;
    node[174]->nn_param.conv2d.stride[1] = 1;
    node[174]->nn_param.conv2d.pad[0] = 1;
    node[174]->nn_param.conv2d.pad[1] = 1;
    node[174]->nn_param.conv2d.pad[2] = 1;
    node[174]->nn_param.conv2d.pad[3] = 1;
    node[174]->nn_param.conv2d.group = 1;
    node[174]->nn_param.conv2d.dilation[0] = 1;
    node[174]->nn_param.conv2d.dilation[1] = 1;
    node[174]->vx_param.has_relu = TRUE;
    node[174]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[174]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[174]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Conv2D_58_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Relu_47
      var       - node[175]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 512, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[175], VSI_NN_OP_CONV_RELU, 3, 1, 47);
    node[175]->nn_param.conv2d.ksize[0] = 1;
    node[175]->nn_param.conv2d.ksize[1] = 3;
    node[175]->nn_param.conv2d.weights = 256;
    node[175]->nn_param.conv2d.stride[0] = 1;
    node[175]->nn_param.conv2d.stride[1] = 1;
    node[175]->nn_param.conv2d.pad[0] = 0;
    node[175]->nn_param.conv2d.pad[1] = 0;
    node[175]->nn_param.conv2d.pad[2] = 1;
    node[175]->nn_param.conv2d.pad[3] = 1;
    node[175]->nn_param.conv2d.group = 1;
    node[175]->nn_param.conv2d.dilation[0] = 1;
    node[175]->nn_param.conv2d.dilation[1] = 1;
    node[175]->vx_param.has_relu = TRUE;
    node[175]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[175]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[175]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/Branch_2/concat_41
      var       - node[176]
      name      - InceptionV4/InceptionV4/Mixed_7c/Branch_2/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[176], VSI_NN_OP_CONCAT, 2, 1, 41);
    node[176]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7c/concat_38
      var       - node[177]
      name      - InceptionV4/InceptionV4/Mixed_7c/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 512, 1]]
                  [[8, 8, 512, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 1536, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[177], VSI_NN_OP_CONCAT, 4, 1, 38);
    node[177]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Conv2D_15_InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Relu_5
      var       - node[178]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[178], VSI_NN_OP_CONV_RELU, 3, 1, 5);
    node[178]->nn_param.conv2d.ksize[0] = 1;
    node[178]->nn_param.conv2d.ksize[1] = 1;
    node[178]->nn_param.conv2d.weights = 256;
    node[178]->nn_param.conv2d.stride[0] = 1;
    node[178]->nn_param.conv2d.stride[1] = 1;
    node[178]->nn_param.conv2d.pad[0] = 0;
    node[178]->nn_param.conv2d.pad[1] = 0;
    node[178]->nn_param.conv2d.pad[2] = 0;
    node[178]->nn_param.conv2d.pad[3] = 0;
    node[178]->nn_param.conv2d.group = 1;
    node[178]->nn_param.conv2d.dilation[0] = 1;
    node[178]->nn_param.conv2d.dilation[1] = 1;
    node[178]->vx_param.has_relu = TRUE;
    node[178]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[178]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[178]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Conv2D_30_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Relu_26
      var       - node[179]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[179], VSI_NN_OP_CONV_RELU, 3, 1, 26);
    node[179]->nn_param.conv2d.ksize[0] = 1;
    node[179]->nn_param.conv2d.ksize[1] = 1;
    node[179]->nn_param.conv2d.weights = 384;
    node[179]->nn_param.conv2d.stride[0] = 1;
    node[179]->nn_param.conv2d.stride[1] = 1;
    node[179]->nn_param.conv2d.pad[0] = 0;
    node[179]->nn_param.conv2d.pad[1] = 0;
    node[179]->nn_param.conv2d.pad[2] = 0;
    node[179]->nn_param.conv2d.pad[3] = 0;
    node[179]->nn_param.conv2d.group = 1;
    node[179]->nn_param.conv2d.dilation[0] = 1;
    node[179]->nn_param.conv2d.dilation[1] = 1;
    node[179]->vx_param.has_relu = TRUE;
    node[179]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[179]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[179]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Conv2D_37_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Relu_35
      var       - node[180]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 384, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[180], VSI_NN_OP_CONV_RELU, 3, 1, 35);
    node[180]->nn_param.conv2d.ksize[0] = 1;
    node[180]->nn_param.conv2d.ksize[1] = 1;
    node[180]->nn_param.conv2d.weights = 384;
    node[180]->nn_param.conv2d.stride[0] = 1;
    node[180]->nn_param.conv2d.stride[1] = 1;
    node[180]->nn_param.conv2d.pad[0] = 0;
    node[180]->nn_param.conv2d.pad[1] = 0;
    node[180]->nn_param.conv2d.pad[2] = 0;
    node[180]->nn_param.conv2d.pad[3] = 0;
    node[180]->nn_param.conv2d.group = 1;
    node[180]->nn_param.conv2d.dilation[0] = 1;
    node[180]->nn_param.conv2d.dilation[1] = 1;
    node[180]->vx_param.has_relu = TRUE;
    node[180]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[180]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[180]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/InceptionV4/Mixed_7d/Branch_3/AvgPool_0a_3x3/AvgPool_25_conv_494
      var       - node[181]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 1536, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[181], VSI_NN_OP_CONV_RELU, 3, 1, 494);
    node[181]->nn_param.conv2d.ksize[0] = 3;
    node[181]->nn_param.conv2d.ksize[1] = 3;
    node[181]->nn_param.conv2d.weights = 1536;
    node[181]->nn_param.conv2d.stride[0] = 1;
    node[181]->nn_param.conv2d.stride[1] = 1;
    node[181]->nn_param.conv2d.pad[0] = 1;
    node[181]->nn_param.conv2d.pad[1] = 1;
    node[181]->nn_param.conv2d.pad[2] = 1;
    node[181]->nn_param.conv2d.pad[3] = 1;
    node[181]->nn_param.conv2d.group = 1;
    node[181]->nn_param.conv2d.dilation[0] = 1;
    node[181]->nn_param.conv2d.dilation[1] = 1;
    node[181]->vx_param.has_relu = FALSE;
    node[181]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[181]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[181]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Conv2D_21_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Relu_10
      var       - node[182]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[182], VSI_NN_OP_CONV_RELU, 3, 1, 10);
    node[182]->nn_param.conv2d.ksize[0] = 3;
    node[182]->nn_param.conv2d.ksize[1] = 3;
    node[182]->nn_param.conv2d.weights = 256;
    node[182]->nn_param.conv2d.stride[0] = 1;
    node[182]->nn_param.conv2d.stride[1] = 1;
    node[182]->nn_param.conv2d.pad[0] = 1;
    node[182]->nn_param.conv2d.pad[1] = 1;
    node[182]->nn_param.conv2d.pad[2] = 1;
    node[182]->nn_param.conv2d.pad[3] = 1;
    node[182]->nn_param.conv2d.group = 1;
    node[182]->nn_param.conv2d.dilation[0] = 1;
    node[182]->nn_param.conv2d.dilation[1] = 1;
    node[182]->vx_param.has_relu = TRUE;
    node[182]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[182]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[182]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Conv2D_22_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Relu_11
      var       - node[183]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[183], VSI_NN_OP_CONV_RELU, 3, 1, 11);
    node[183]->nn_param.conv2d.ksize[0] = 1;
    node[183]->nn_param.conv2d.ksize[1] = 3;
    node[183]->nn_param.conv2d.weights = 256;
    node[183]->nn_param.conv2d.stride[0] = 1;
    node[183]->nn_param.conv2d.stride[1] = 1;
    node[183]->nn_param.conv2d.pad[0] = 0;
    node[183]->nn_param.conv2d.pad[1] = 0;
    node[183]->nn_param.conv2d.pad[2] = 1;
    node[183]->nn_param.conv2d.pad[3] = 1;
    node[183]->nn_param.conv2d.group = 1;
    node[183]->nn_param.conv2d.dilation[0] = 1;
    node[183]->nn_param.conv2d.dilation[1] = 1;
    node[183]->vx_param.has_relu = TRUE;
    node[183]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[183]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[183]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Conv2D_34_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Relu_32
      var       - node[184]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 384, 1]]
      out_shape - [[8, 8, 448, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[184], VSI_NN_OP_CONV_RELU, 3, 1, 32);
    node[184]->nn_param.conv2d.ksize[0] = 1;
    node[184]->nn_param.conv2d.ksize[1] = 3;
    node[184]->nn_param.conv2d.weights = 448;
    node[184]->nn_param.conv2d.stride[0] = 1;
    node[184]->nn_param.conv2d.stride[1] = 1;
    node[184]->nn_param.conv2d.pad[0] = 0;
    node[184]->nn_param.conv2d.pad[1] = 0;
    node[184]->nn_param.conv2d.pad[2] = 1;
    node[184]->nn_param.conv2d.pad[3] = 1;
    node[184]->nn_param.conv2d.group = 1;
    node[184]->nn_param.conv2d.dilation[0] = 1;
    node[184]->nn_param.conv2d.dilation[1] = 1;
    node[184]->vx_param.has_relu = TRUE;
    node[184]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[184]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[184]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Conv2D_20_InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Relu_8
      var       - node[185]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[185], VSI_NN_OP_CONV_RELU, 3, 1, 8);
    node[185]->nn_param.conv2d.ksize[0] = 1;
    node[185]->nn_param.conv2d.ksize[1] = 1;
    node[185]->nn_param.conv2d.weights = 256;
    node[185]->nn_param.conv2d.stride[0] = 1;
    node[185]->nn_param.conv2d.stride[1] = 1;
    node[185]->nn_param.conv2d.pad[0] = 0;
    node[185]->nn_param.conv2d.pad[1] = 0;
    node[185]->nn_param.conv2d.pad[2] = 0;
    node[185]->nn_param.conv2d.pad[3] = 0;
    node[185]->nn_param.conv2d.group = 1;
    node[185]->nn_param.conv2d.dilation[0] = 1;
    node[185]->nn_param.conv2d.dilation[1] = 1;
    node[185]->vx_param.has_relu = TRUE;
    node[185]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[185]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[185]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_1/concat_6
      var       - node[186]
      name      - InceptionV4/InceptionV4/Mixed_7d/Branch_1/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[186], VSI_NN_OP_CONCAT, 2, 1, 6);
    node[186]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Conv2D_31_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Relu_27
      var       - node[187]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 448, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[187], VSI_NN_OP_CONV_RELU, 3, 1, 27);
    node[187]->nn_param.conv2d.ksize[0] = 3;
    node[187]->nn_param.conv2d.ksize[1] = 3;
    node[187]->nn_param.conv2d.weights = 512;
    node[187]->nn_param.conv2d.stride[0] = 1;
    node[187]->nn_param.conv2d.stride[1] = 1;
    node[187]->nn_param.conv2d.pad[0] = 1;
    node[187]->nn_param.conv2d.pad[1] = 1;
    node[187]->nn_param.conv2d.pad[2] = 1;
    node[187]->nn_param.conv2d.pad[3] = 1;
    node[187]->nn_param.conv2d.group = 1;
    node[187]->nn_param.conv2d.dilation[0] = 1;
    node[187]->nn_param.conv2d.dilation[1] = 1;
    node[187]->vx_param.has_relu = TRUE;
    node[187]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[187]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[187]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Conv2D_23_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Relu_12
      var       - node[188]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 512, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[188], VSI_NN_OP_CONV_RELU, 3, 1, 12);
    node[188]->nn_param.conv2d.ksize[0] = 3;
    node[188]->nn_param.conv2d.ksize[1] = 3;
    node[188]->nn_param.conv2d.weights = 256;
    node[188]->nn_param.conv2d.stride[0] = 1;
    node[188]->nn_param.conv2d.stride[1] = 1;
    node[188]->nn_param.conv2d.pad[0] = 1;
    node[188]->nn_param.conv2d.pad[1] = 1;
    node[188]->nn_param.conv2d.pad[2] = 1;
    node[188]->nn_param.conv2d.pad[3] = 1;
    node[188]->nn_param.conv2d.group = 1;
    node[188]->nn_param.conv2d.dilation[0] = 1;
    node[188]->nn_param.conv2d.dilation[1] = 1;
    node[188]->vx_param.has_relu = TRUE;
    node[188]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[188]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[188]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Conv2D_24_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Relu_13
      var       - node[189]
      name      - convolutionrelu
      operation - convolutionrelu
      in_shape  - [[8, 8, 512, 1]]
      out_shape - [[8, 8, 256, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[189], VSI_NN_OP_CONV_RELU, 3, 1, 13);
    node[189]->nn_param.conv2d.ksize[0] = 1;
    node[189]->nn_param.conv2d.ksize[1] = 3;
    node[189]->nn_param.conv2d.weights = 256;
    node[189]->nn_param.conv2d.stride[0] = 1;
    node[189]->nn_param.conv2d.stride[1] = 1;
    node[189]->nn_param.conv2d.pad[0] = 0;
    node[189]->nn_param.conv2d.pad[1] = 0;
    node[189]->nn_param.conv2d.pad[2] = 1;
    node[189]->nn_param.conv2d.pad[3] = 1;
    node[189]->nn_param.conv2d.group = 1;
    node[189]->nn_param.conv2d.dilation[0] = 1;
    node[189]->nn_param.conv2d.dilation[1] = 1;
    node[189]->vx_param.has_relu = TRUE;
    node[189]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[189]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[189]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/Branch_2/concat_7
      var       - node[190]
      name      - InceptionV4/InceptionV4/Mixed_7d/Branch_2/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 512, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[190], VSI_NN_OP_CONCAT, 2, 1, 7);
    node[190]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/InceptionV4/Mixed_7d/concat_4
      var       - node[191]
      name      - InceptionV4/InceptionV4/Mixed_7d/concat
      operation - concat
      in_shape  - [[8, 8, 256, 1]]
                  [[8, 8, 512, 1]]
                  [[8, 8, 512, 1]]
                  [[8, 8, 256, 1]]
      out_shape - [[8, 8, 1536, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[191], VSI_NN_OP_CONCAT, 4, 1, 4);
    node[191]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - InceptionV4/Logits/AvgPool_1a/AvgPool_3
      var       - node[192]
      name      - InceptionV4/Logits/AvgPool_1a/AvgPool
      operation - pooling
      in_shape  - [[8, 8, 1536, 1]]
      out_shape - [[1, 1, 1536, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[192], VSI_NN_OP_POOL, 1, 1, 3);
    node[192]->nn_param.pool.ksize[0] = 8;
    node[192]->nn_param.pool.ksize[1] = 8;
    node[192]->nn_param.pool.stride[0] = 1;
    node[192]->nn_param.pool.stride[1] = 1;
    node[192]->nn_param.pool.pad[0] = 0;
    node[192]->nn_param.pool.pad[1] = 0;
    node[192]->nn_param.pool.pad[2] = 0;
    node[192]->nn_param.pool.pad[3] = 0;
    node[192]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[192]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[192]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - trans_InceptionV4/Logits/Logits/BiasAdd_2
      var       - node[193]
      name      - fullconnectrelu
      operation - fullconnectrelu
      in_shape  - [[1, 1, 1536, 1]]
      out_shape - [[1001, 1]]
    -----------------------------------------*/
    NEW_VXNODE(node[193], VSI_NN_OP_FCL_RELU, 3, 1, 2);
    node[193]->nn_param.fcl.weights = 1001;
    node[193]->vx_param.has_relu = FALSE;
    node[193]->vx_param.overflow_policy = VX_CONVERT_POLICY_WRAP;
    node[193]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[193]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;


/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @input_1:out0 */
    attr.size[0] = 299;
    attr.size[1] = 299;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_INT8);

    /* @output_0:out0 */
    attr.size[0] = 1001;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_INT8);



    /* @InceptionV4/InceptionV4/Conv2d_1a_3x3/Conv2D_493_InceptionV4/InceptionV4/Conv2d_1a_3x3/Relu_491:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 3;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_INT8, 128, 864);

    /* @InceptionV4/InceptionV4/Conv2d_1a_3x3/Conv2D_493_InceptionV4/InceptionV4/Conv2d_1a_3x3/Relu_491:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_INT32, 0, 128);

    /* @InceptionV4/InceptionV4/Conv2d_2a_3x3/Conv2D_490_InceptionV4/InceptionV4/Conv2d_2a_3x3/Relu_488:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_INT8, 1120, 9216);

    /* @InceptionV4/InceptionV4/Conv2d_2a_3x3/Conv2D_490_InceptionV4/InceptionV4/Conv2d_2a_3x3/Relu_488:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_INT32, 992, 128);

    /* @InceptionV4/InceptionV4/Conv2d_2b_3x3/Conv2D_487_InceptionV4/InceptionV4/Conv2d_2b_3x3/Relu_485:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_INT8, 10592, 18432);

    /* @InceptionV4/InceptionV4/Conv2d_2b_3x3/Conv2D_487_InceptionV4/InceptionV4/Conv2d_2b_3x3/Relu_485:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_INT32, 10336, 256);

    /* @InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Conv2D_484_InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Relu_482:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_INT8, 29408, 55296);

    /* @InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Conv2D_484_InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Relu_482:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_INT32, 29024, 384);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Conv2D_472_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Relu_468:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 160;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_INT8, 84960, 10240);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Conv2D_472_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Relu_468:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_INT32, 84704, 256);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Conv2D_479_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Relu_477:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 160;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_INT8, 151136, 10240);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Conv2D_479_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Relu_477:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_INT32, 150880, 256);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Conv2D_466_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Relu_462:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_INT8, 95584, 55296);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Conv2D_466_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Relu_462:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_INT32, 95200, 384);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Conv2D_476_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Relu_474:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_INT8, 161632, 200704);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Conv2D_476_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Relu_474:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_INT32, 161376, 256);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Conv2D_473_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Relu_469:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_INT8, 362592, 28672);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Conv2D_473_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Relu_469:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_INT32, 362336, 256);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Conv2D_467_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Relu_463:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_INT8, 391648, 55296);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Conv2D_467_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Relu_463:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_INT32, 391264, 384);

    /* @InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Conv2D_460_InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Relu_457:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_INT8, 447712, 331776);

    /* @InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Conv2D_460_InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Relu_457:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_INT32, 446944, 768);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_442_InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_434:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_INT8, 779872, 36864);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_442_InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_434:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_INT32, 779488, 384);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_451_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_446:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_INT8, 816992, 24576);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_451_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_446:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_INT32, 816736, 256);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_455_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_453:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_INT8, 897504, 24576);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_455_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_453:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_INT32, 897248, 256);

    /* @trans_InceptionV4/InceptionV4/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_448_conv_507:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_INT8, 94537440, 1327104);

    /* @trans_InceptionV4/InceptionV4/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_448_conv_507:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_INT32, 94535904, 1536);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Conv2D_443_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Relu_435:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_INT8, 841952, 55296);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Conv2D_443_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Relu_435:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_INT32, 841568, 384);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_452_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_447:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_INT8, 922464, 55296);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_452_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_447:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_INT32, 922080, 384);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_445_InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_437:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_INT8, 1061472, 36864);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_445_InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_437:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_INT32, 1061088, 384);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_444_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_436:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_INT8, 978144, 82944);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_444_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_436:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_INT32, 977760, 384);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_419_InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_411:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_INT8, 1098720, 36864);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_419_InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_411:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_INT32, 1098336, 384);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Conv2D_428_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Relu_423:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_INT8, 1135840, 24576);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Conv2D_428_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Relu_423:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_INT32, 1135584, 256);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_432_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_430:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_INT8, 1216352, 24576);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_432_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_430:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_INT32, 1216096, 256);

    /* @trans_InceptionV4/InceptionV4/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_425_conv_506:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_INT8, 95866080, 1327104);

    /* @trans_InceptionV4/InceptionV4/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_425_conv_506:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_INT32, 95864544, 1536);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Conv2D_420_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Relu_412:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_INT8, 1160800, 55296);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Conv2D_420_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Relu_412:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_INT32, 1160416, 384);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_429_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_424:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_INT8, 1241312, 55296);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_429_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_424:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_INT32, 1240928, 384);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_422_InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_414:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_INT8, 1380320, 36864);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_422_InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_414:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_INT32, 1379936, 384);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_421_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_413:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[52], attr, VSI_NN_TYPE_INT8, 1296992, 82944);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_421_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_413:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[53], attr, VSI_NN_TYPE_INT32, 1296608, 384);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_396_InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_388:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[54], attr, VSI_NN_TYPE_INT8, 1417568, 36864);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_396_InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_388:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[55], attr, VSI_NN_TYPE_INT32, 1417184, 384);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_405_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_400:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[56], attr, VSI_NN_TYPE_INT8, 1454688, 24576);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_405_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_400:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[57], attr, VSI_NN_TYPE_INT32, 1454432, 256);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_409_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_407:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[58], attr, VSI_NN_TYPE_INT8, 1535200, 24576);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_409_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_407:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[59], attr, VSI_NN_TYPE_INT32, 1534944, 256);

    /* @trans_InceptionV4/InceptionV4/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_402_conv_505:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[60], attr, VSI_NN_TYPE_INT8, 97194720, 1327104);

    /* @trans_InceptionV4/InceptionV4/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_402_conv_505:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[61], attr, VSI_NN_TYPE_INT32, 97193184, 1536);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Conv2D_397_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Relu_389:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[62], attr, VSI_NN_TYPE_INT8, 1479648, 55296);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Conv2D_397_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Relu_389:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[63], attr, VSI_NN_TYPE_INT32, 1479264, 384);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_406_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_401:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[64], attr, VSI_NN_TYPE_INT8, 1560160, 55296);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_406_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_401:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[65], attr, VSI_NN_TYPE_INT32, 1559776, 384);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_399_InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_391:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[66], attr, VSI_NN_TYPE_INT8, 1699168, 36864);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_399_InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_391:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[67], attr, VSI_NN_TYPE_INT32, 1698784, 384);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_398_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_390:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[68], attr, VSI_NN_TYPE_INT8, 1615840, 82944);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_398_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_390:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[69], attr, VSI_NN_TYPE_INT32, 1615456, 384);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Conv2D_373_InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Relu_365:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[70], attr, VSI_NN_TYPE_INT8, 1736416, 36864);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Conv2D_373_InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Relu_365:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[71], attr, VSI_NN_TYPE_INT32, 1736032, 384);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Conv2D_382_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Relu_377:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[72], attr, VSI_NN_TYPE_INT8, 1773536, 24576);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Conv2D_382_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Relu_377:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[73], attr, VSI_NN_TYPE_INT32, 1773280, 256);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Conv2D_386_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Relu_384:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[74], attr, VSI_NN_TYPE_INT8, 1854048, 24576);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Conv2D_386_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Relu_384:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[75], attr, VSI_NN_TYPE_INT32, 1853792, 256);

    /* @trans_InceptionV4/InceptionV4/Mixed_5e/Branch_3/AvgPool_0a_3x3/AvgPool_379_conv_504:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[76], attr, VSI_NN_TYPE_INT8, 98523360, 1327104);

    /* @trans_InceptionV4/InceptionV4/Mixed_5e/Branch_3/AvgPool_0a_3x3/AvgPool_379_conv_504:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[77], attr, VSI_NN_TYPE_INT32, 98521824, 1536);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Conv2D_374_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Relu_366:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[78], attr, VSI_NN_TYPE_INT8, 1798496, 55296);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Conv2D_374_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Relu_366:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[79], attr, VSI_NN_TYPE_INT32, 1798112, 384);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Conv2D_383_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Relu_378:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[80], attr, VSI_NN_TYPE_INT8, 1879008, 55296);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Conv2D_383_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Relu_378:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[81], attr, VSI_NN_TYPE_INT32, 1878624, 384);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Conv2D_376_InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Relu_368:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[82], attr, VSI_NN_TYPE_INT8, 2018016, 36864);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Conv2D_376_InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Relu_368:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[83], attr, VSI_NN_TYPE_INT32, 2017632, 384);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Conv2D_375_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Relu_367:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 96;
    attr.size[3] = 96;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[84], attr, VSI_NN_TYPE_INT8, 1934688, 82944);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Conv2D_375_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Relu_367:bias */
    attr.size[0] = 96;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[85], attr, VSI_NN_TYPE_INT32, 1934304, 384);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Conv2D_356_InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Relu_351:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[86], attr, VSI_NN_TYPE_INT8, 2056416, 1327104);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Conv2D_356_InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Relu_351:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[87], attr, VSI_NN_TYPE_INT32, 2054880, 1536);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_363_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_361:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 384;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[88], attr, VSI_NN_TYPE_INT8, 3384288, 73728);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_363_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_361:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[89], attr, VSI_NN_TYPE_INT32, 3383520, 768);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_360_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_358:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[90], attr, VSI_NN_TYPE_INT8, 3458912, 387072);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_360_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_358:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[91], attr, VSI_NN_TYPE_INT32, 3458016, 896);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Conv2D_357_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Relu_352:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[92], attr, VSI_NN_TYPE_INT8, 3847008, 516096);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Conv2D_357_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Relu_352:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[93], attr, VSI_NN_TYPE_INT32, 3845984, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_327_InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_319:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[94], attr, VSI_NN_TYPE_INT8, 4364640, 393216);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_327_InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_319:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[95], attr, VSI_NN_TYPE_INT32, 4363104, 1536);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_342_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_338:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[96], attr, VSI_NN_TYPE_INT8, 4758624, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_342_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_338:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[97], attr, VSI_NN_TYPE_INT32, 4757856, 768);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_349_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_347:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[98], attr, VSI_NN_TYPE_INT8, 7466720, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_349_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_347:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[99], attr, VSI_NN_TYPE_INT32, 7465952, 768);

    /* @trans_InceptionV4/InceptionV4/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_333_conv_503:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1024;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[100], attr, VSI_NN_TYPE_INT8, 99854560, 9437184);

    /* @trans_InceptionV4/InceptionV4/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_333_conv_503:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[101], attr, VSI_NN_TYPE_INT32, 99850464, 4096);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_336_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_331:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[102], attr, VSI_NN_TYPE_INT8, 4956128, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_336_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_331:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[103], attr, VSI_NN_TYPE_INT32, 4955232, 896);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_346_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_344:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[104], attr, VSI_NN_TYPE_INT8, 7664096, 258048);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_346_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_344:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[105], attr, VSI_NN_TYPE_INT32, 7663328, 768);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_330_InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_322:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[106], attr, VSI_NN_TYPE_INT8, 13193952, 131072);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_330_InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_322:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[107], attr, VSI_NN_TYPE_INT32, 13193440, 512);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_328_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_320:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[108], attr, VSI_NN_TYPE_INT8, 7064544, 401408);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_328_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_320:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[109], attr, VSI_NN_TYPE_INT32, 7063520, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_343_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_339:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[110], attr, VSI_NN_TYPE_INT8, 7923040, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_343_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_339:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[111], attr, VSI_NN_TYPE_INT32, 7922144, 896);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_337_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_332:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[112], attr, VSI_NN_TYPE_INT8, 10031328, 351232);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_337_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_332:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[113], attr, VSI_NN_TYPE_INT32, 10030432, 896);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_329_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_321:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[114], attr, VSI_NN_TYPE_INT8, 10383584, 2809856);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_329_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_321:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[115], attr, VSI_NN_TYPE_INT32, 10382560, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_295_InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_287:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[116], attr, VSI_NN_TYPE_INT8, 13326560, 393216);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_295_InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_287:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[117], attr, VSI_NN_TYPE_INT32, 13325024, 1536);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_310_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_306:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[118], attr, VSI_NN_TYPE_INT8, 13720544, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_310_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_306:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[119], attr, VSI_NN_TYPE_INT32, 13719776, 768);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_317_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_315:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[120], attr, VSI_NN_TYPE_INT8, 16428640, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_317_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_315:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[121], attr, VSI_NN_TYPE_INT32, 16427872, 768);

    /* @trans_InceptionV4/InceptionV4/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_301_conv_502:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1024;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[122], attr, VSI_NN_TYPE_INT8, 109295840, 9437184);

    /* @trans_InceptionV4/InceptionV4/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_301_conv_502:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[123], attr, VSI_NN_TYPE_INT32, 109291744, 4096);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_304_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_299:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[124], attr, VSI_NN_TYPE_INT8, 13918048, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_304_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_299:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[125], attr, VSI_NN_TYPE_INT32, 13917152, 896);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_314_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_312:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[126], attr, VSI_NN_TYPE_INT8, 16626016, 258048);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_314_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_312:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[127], attr, VSI_NN_TYPE_INT32, 16625248, 768);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_298_InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_290:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[128], attr, VSI_NN_TYPE_INT8, 22155872, 131072);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_298_InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_290:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[129], attr, VSI_NN_TYPE_INT32, 22155360, 512);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_296_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_288:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[130], attr, VSI_NN_TYPE_INT8, 16026464, 401408);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_296_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_288:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[131], attr, VSI_NN_TYPE_INT32, 16025440, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_311_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_307:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[132], attr, VSI_NN_TYPE_INT8, 16884960, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_311_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_307:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[133], attr, VSI_NN_TYPE_INT32, 16884064, 896);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_305_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_300:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[134], attr, VSI_NN_TYPE_INT8, 18993248, 351232);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_305_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_300:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[135], attr, VSI_NN_TYPE_INT32, 18992352, 896);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_297_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_289:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[136], attr, VSI_NN_TYPE_INT8, 19345504, 2809856);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_297_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_289:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[137], attr, VSI_NN_TYPE_INT32, 19344480, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_263_InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_255:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[138], attr, VSI_NN_TYPE_INT8, 22288480, 393216);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_263_InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_255:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[139], attr, VSI_NN_TYPE_INT32, 22286944, 1536);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_278_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_274:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[140], attr, VSI_NN_TYPE_INT8, 22682464, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_278_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_274:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[141], attr, VSI_NN_TYPE_INT32, 22681696, 768);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_285_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_283:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[142], attr, VSI_NN_TYPE_INT8, 25390560, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_285_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_283:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[143], attr, VSI_NN_TYPE_INT32, 25389792, 768);

    /* @trans_InceptionV4/InceptionV4/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_269_conv_501:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1024;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[144], attr, VSI_NN_TYPE_INT8, 118737120, 9437184);

    /* @trans_InceptionV4/InceptionV4/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_269_conv_501:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[145], attr, VSI_NN_TYPE_INT32, 118733024, 4096);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_272_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_267:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[146], attr, VSI_NN_TYPE_INT8, 22879968, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_272_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_267:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[147], attr, VSI_NN_TYPE_INT32, 22879072, 896);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_282_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_280:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[148], attr, VSI_NN_TYPE_INT8, 25587936, 258048);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_282_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_280:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[149], attr, VSI_NN_TYPE_INT32, 25587168, 768);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_266_InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_258:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[150], attr, VSI_NN_TYPE_INT8, 31117792, 131072);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_266_InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_258:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[151], attr, VSI_NN_TYPE_INT32, 31117280, 512);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_264_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_256:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[152], attr, VSI_NN_TYPE_INT8, 24988384, 401408);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_264_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_256:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[153], attr, VSI_NN_TYPE_INT32, 24987360, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_279_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_275:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[154], attr, VSI_NN_TYPE_INT8, 25846880, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_279_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_275:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[155], attr, VSI_NN_TYPE_INT32, 25845984, 896);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_273_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_268:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[156], attr, VSI_NN_TYPE_INT8, 27955168, 351232);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_273_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_268:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[157], attr, VSI_NN_TYPE_INT32, 27954272, 896);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_265_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_257:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[158], attr, VSI_NN_TYPE_INT8, 28307424, 2809856);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_265_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_257:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[159], attr, VSI_NN_TYPE_INT32, 28306400, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_231_InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_223:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[160], attr, VSI_NN_TYPE_INT8, 31250400, 393216);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_231_InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_223:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[161], attr, VSI_NN_TYPE_INT32, 31248864, 1536);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_246_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_242:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[162], attr, VSI_NN_TYPE_INT8, 31644384, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_246_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_242:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[163], attr, VSI_NN_TYPE_INT32, 31643616, 768);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_253_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_251:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[164], attr, VSI_NN_TYPE_INT8, 34352480, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_253_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_251:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[165], attr, VSI_NN_TYPE_INT32, 34351712, 768);

    /* @trans_InceptionV4/InceptionV4/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_237_conv_500:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1024;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[166], attr, VSI_NN_TYPE_INT8, 128178400, 9437184);

    /* @trans_InceptionV4/InceptionV4/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_237_conv_500:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[167], attr, VSI_NN_TYPE_INT32, 128174304, 4096);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_240_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_235:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[168], attr, VSI_NN_TYPE_INT8, 31841888, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_240_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_235:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[169], attr, VSI_NN_TYPE_INT32, 31840992, 896);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_250_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_248:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[170], attr, VSI_NN_TYPE_INT8, 34549856, 258048);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_250_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_248:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[171], attr, VSI_NN_TYPE_INT32, 34549088, 768);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_234_InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_226:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[172], attr, VSI_NN_TYPE_INT8, 40079712, 131072);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_234_InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_226:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[173], attr, VSI_NN_TYPE_INT32, 40079200, 512);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_232_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_224:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[174], attr, VSI_NN_TYPE_INT8, 33950304, 401408);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_232_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_224:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[175], attr, VSI_NN_TYPE_INT32, 33949280, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_247_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_243:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[176], attr, VSI_NN_TYPE_INT8, 34808800, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_247_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_243:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[177], attr, VSI_NN_TYPE_INT32, 34807904, 896);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_241_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_236:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[178], attr, VSI_NN_TYPE_INT8, 36917088, 351232);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_241_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_236:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[179], attr, VSI_NN_TYPE_INT32, 36916192, 896);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_233_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_225:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[180], attr, VSI_NN_TYPE_INT8, 37269344, 2809856);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_233_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_225:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[181], attr, VSI_NN_TYPE_INT32, 37268320, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Conv2D_199_InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Relu_191:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[182], attr, VSI_NN_TYPE_INT8, 40212320, 393216);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Conv2D_199_InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Relu_191:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[183], attr, VSI_NN_TYPE_INT32, 40210784, 1536);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Conv2D_214_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Relu_210:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[184], attr, VSI_NN_TYPE_INT8, 40606304, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Conv2D_214_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Relu_210:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[185], attr, VSI_NN_TYPE_INT32, 40605536, 768);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Conv2D_221_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Relu_219:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[186], attr, VSI_NN_TYPE_INT8, 43314400, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Conv2D_221_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Relu_219:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[187], attr, VSI_NN_TYPE_INT32, 43313632, 768);

    /* @trans_InceptionV4/InceptionV4/Mixed_6f/Branch_3/AvgPool_0a_3x3/AvgPool_205_conv_499:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1024;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[188], attr, VSI_NN_TYPE_INT8, 137619680, 9437184);

    /* @trans_InceptionV4/InceptionV4/Mixed_6f/Branch_3/AvgPool_0a_3x3/AvgPool_205_conv_499:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[189], attr, VSI_NN_TYPE_INT32, 137615584, 4096);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Conv2D_208_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Relu_203:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[190], attr, VSI_NN_TYPE_INT8, 40803808, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Conv2D_208_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Relu_203:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[191], attr, VSI_NN_TYPE_INT32, 40802912, 896);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Conv2D_218_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Relu_216:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[192], attr, VSI_NN_TYPE_INT8, 43511776, 258048);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Conv2D_218_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Relu_216:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[193], attr, VSI_NN_TYPE_INT32, 43511008, 768);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Conv2D_202_InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Relu_194:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[194], attr, VSI_NN_TYPE_INT8, 49041632, 131072);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Conv2D_202_InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Relu_194:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[195], attr, VSI_NN_TYPE_INT32, 49041120, 512);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Conv2D_200_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Relu_192:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[196], attr, VSI_NN_TYPE_INT8, 42912224, 401408);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Conv2D_200_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Relu_192:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[197], attr, VSI_NN_TYPE_INT32, 42911200, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Conv2D_215_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Relu_211:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[198], attr, VSI_NN_TYPE_INT8, 43770720, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Conv2D_215_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Relu_211:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[199], attr, VSI_NN_TYPE_INT32, 43769824, 896);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Conv2D_209_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Relu_204:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[200], attr, VSI_NN_TYPE_INT8, 45879008, 351232);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Conv2D_209_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Relu_204:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[201], attr, VSI_NN_TYPE_INT32, 45878112, 896);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Conv2D_201_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Relu_193:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[202], attr, VSI_NN_TYPE_INT8, 46231264, 2809856);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Conv2D_201_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Relu_193:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[203], attr, VSI_NN_TYPE_INT32, 46230240, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Conv2D_167_InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Relu_159:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[204], attr, VSI_NN_TYPE_INT8, 49174240, 393216);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Conv2D_167_InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Relu_159:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[205], attr, VSI_NN_TYPE_INT32, 49172704, 1536);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Conv2D_182_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Relu_178:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[206], attr, VSI_NN_TYPE_INT8, 49568224, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Conv2D_182_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Relu_178:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[207], attr, VSI_NN_TYPE_INT32, 49567456, 768);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Conv2D_189_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Relu_187:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[208], attr, VSI_NN_TYPE_INT8, 52276320, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Conv2D_189_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Relu_187:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[209], attr, VSI_NN_TYPE_INT32, 52275552, 768);

    /* @trans_InceptionV4/InceptionV4/Mixed_6g/Branch_3/AvgPool_0a_3x3/AvgPool_173_conv_498:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1024;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[210], attr, VSI_NN_TYPE_INT8, 147060960, 9437184);

    /* @trans_InceptionV4/InceptionV4/Mixed_6g/Branch_3/AvgPool_0a_3x3/AvgPool_173_conv_498:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[211], attr, VSI_NN_TYPE_INT32, 147056864, 4096);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Conv2D_176_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Relu_171:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[212], attr, VSI_NN_TYPE_INT8, 49765728, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Conv2D_176_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Relu_171:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[213], attr, VSI_NN_TYPE_INT32, 49764832, 896);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Conv2D_186_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Relu_184:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[214], attr, VSI_NN_TYPE_INT8, 52473696, 258048);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Conv2D_186_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Relu_184:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[215], attr, VSI_NN_TYPE_INT32, 52472928, 768);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Conv2D_170_InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Relu_162:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[216], attr, VSI_NN_TYPE_INT8, 58003552, 131072);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Conv2D_170_InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Relu_162:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[217], attr, VSI_NN_TYPE_INT32, 58003040, 512);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Conv2D_168_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Relu_160:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[218], attr, VSI_NN_TYPE_INT8, 51874144, 401408);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Conv2D_168_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Relu_160:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[219], attr, VSI_NN_TYPE_INT32, 51873120, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Conv2D_183_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Relu_179:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[220], attr, VSI_NN_TYPE_INT8, 52732640, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Conv2D_183_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Relu_179:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[221], attr, VSI_NN_TYPE_INT32, 52731744, 896);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Conv2D_177_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Relu_172:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[222], attr, VSI_NN_TYPE_INT8, 54840928, 351232);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Conv2D_177_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Relu_172:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[223], attr, VSI_NN_TYPE_INT32, 54840032, 896);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Conv2D_169_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Relu_161:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[224], attr, VSI_NN_TYPE_INT8, 55193184, 2809856);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Conv2D_169_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Relu_161:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[225], attr, VSI_NN_TYPE_INT32, 55192160, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Conv2D_135_InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Relu_127:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[226], attr, VSI_NN_TYPE_INT8, 58136160, 393216);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Conv2D_135_InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Relu_127:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[227], attr, VSI_NN_TYPE_INT32, 58134624, 1536);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Conv2D_150_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Relu_146:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[228], attr, VSI_NN_TYPE_INT8, 58530144, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Conv2D_150_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Relu_146:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[229], attr, VSI_NN_TYPE_INT32, 58529376, 768);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Conv2D_157_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Relu_155:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[230], attr, VSI_NN_TYPE_INT8, 61238240, 196608);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Conv2D_157_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Relu_155:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[231], attr, VSI_NN_TYPE_INT32, 61237472, 768);

    /* @trans_InceptionV4/InceptionV4/Mixed_6h/Branch_3/AvgPool_0a_3x3/AvgPool_141_conv_497:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1024;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[232], attr, VSI_NN_TYPE_INT8, 156502240, 9437184);

    /* @trans_InceptionV4/InceptionV4/Mixed_6h/Branch_3/AvgPool_0a_3x3/AvgPool_141_conv_497:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[233], attr, VSI_NN_TYPE_INT32, 156498144, 4096);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Conv2D_144_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Relu_139:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[234], attr, VSI_NN_TYPE_INT8, 58727648, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Conv2D_144_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Relu_139:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[235], attr, VSI_NN_TYPE_INT32, 58726752, 896);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Conv2D_154_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Relu_152:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[236], attr, VSI_NN_TYPE_INT8, 61435616, 258048);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Conv2D_154_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Relu_152:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[237], attr, VSI_NN_TYPE_INT32, 61434848, 768);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Conv2D_138_InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Relu_130:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[238], attr, VSI_NN_TYPE_INT8, 66965472, 131072);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Conv2D_138_InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Relu_130:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[239], attr, VSI_NN_TYPE_INT32, 66964960, 512);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Conv2D_136_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Relu_128:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[240], attr, VSI_NN_TYPE_INT8, 60836064, 401408);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Conv2D_136_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Relu_128:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[241], attr, VSI_NN_TYPE_INT32, 60835040, 1024);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Conv2D_151_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Relu_147:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 192;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[242], attr, VSI_NN_TYPE_INT8, 61694560, 2107392);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Conv2D_151_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Relu_147:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[243], attr, VSI_NN_TYPE_INT32, 61693664, 896);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Conv2D_145_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Relu_140:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 224;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[244], attr, VSI_NN_TYPE_INT8, 63802848, 351232);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Conv2D_145_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Relu_140:bias */
    attr.size[0] = 224;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[245], attr, VSI_NN_TYPE_INT32, 63801952, 896);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Conv2D_137_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Relu_129:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 224;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[246], attr, VSI_NN_TYPE_INT8, 64155104, 2809856);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Conv2D_137_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Relu_129:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[247], attr, VSI_NN_TYPE_INT32, 64154080, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_118_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_114:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[248], attr, VSI_NN_TYPE_INT8, 67097312, 196608);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_118_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_114:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[249], attr, VSI_NN_TYPE_INT32, 67096544, 768);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_125_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_123:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[250], attr, VSI_NN_TYPE_INT8, 67627488, 262144);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_125_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_123:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[251], attr, VSI_NN_TYPE_INT32, 67626464, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_112_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_107:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 192;
    attr.size[3] = 192;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[252], attr, VSI_NN_TYPE_INT8, 67294688, 331776);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_112_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_107:bias */
    attr.size[0] = 192;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[253], attr, VSI_NN_TYPE_INT32, 67293920, 768);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_122_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_120:weight */
    attr.size[0] = 7;
    attr.size[1] = 7;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[254], attr, VSI_NN_TYPE_INT8, 67890656, 3211264);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_122_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_120:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[255], attr, VSI_NN_TYPE_INT32, 67889632, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_119_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_115:weight */
    attr.size[0] = 1;
    attr.size[1] = 7;
    attr.size[2] = 256;
    attr.size[3] = 320;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[256], attr, VSI_NN_TYPE_INT8, 71103200, 573440);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_119_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_115:bias */
    attr.size[0] = 320;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[257], attr, VSI_NN_TYPE_INT32, 71101920, 1280);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_113_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_108:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 320;
    attr.size[3] = 320;
    attr.dim_num = 4;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[258], attr, VSI_NN_TYPE_INT8, 71677920, 921600);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_113_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_108:bias */
    attr.size[0] = 320;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[259], attr, VSI_NN_TYPE_INT32, 71676640, 1280);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_83_InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_73:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[260], attr, VSI_NN_TYPE_INT8, 72600544, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_83_InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_73:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[261], attr, VSI_NN_TYPE_INT32, 72599520, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_98_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_94:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[262], attr, VSI_NN_TYPE_INT8, 72995296, 589824);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_98_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_94:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[263], attr, VSI_NN_TYPE_INT32, 72993760, 1536);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_105_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_103:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[264], attr, VSI_NN_TYPE_INT8, 74768352, 589824);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_105_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_103:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[265], attr, VSI_NN_TYPE_INT32, 74766816, 1536);

    /* @trans_InceptionV4/InceptionV4/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_93_conv_496:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1536;
    attr.size[3] = 1536;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[266], attr, VSI_NN_TYPE_INT8, 165945568, 21233664);

    /* @trans_InceptionV4/InceptionV4/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_93_conv_496:bias */
    attr.size[0] = 1536;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[267], attr, VSI_NN_TYPE_INT32, 165939424, 6144);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_89_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_78:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[268], attr, VSI_NN_TYPE_INT8, 73586144, 884736);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_89_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_78:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[269], attr, VSI_NN_TYPE_INT32, 73585120, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Conv2D_90_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Relu_79:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[270], attr, VSI_NN_TYPE_INT8, 74471904, 294912);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Conv2D_90_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Relu_79:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[271], attr, VSI_NN_TYPE_INT32, 74470880, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Conv2D_102_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Relu_100:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 448;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[272], attr, VSI_NN_TYPE_INT8, 75359968, 516096);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Conv2D_102_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Relu_100:bias */
    attr.size[0] = 448;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[273], attr, VSI_NN_TYPE_INT32, 75358176, 1792);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_88_InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_76:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[274], attr, VSI_NN_TYPE_INT8, 79518432, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_88_InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_76:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[275], attr, VSI_NN_TYPE_INT32, 79517408, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_99_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_95:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 448;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[276], attr, VSI_NN_TYPE_INT8, 75878112, 2064384);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_99_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_95:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[277], attr, VSI_NN_TYPE_INT32, 75876064, 2048);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Conv2D_91_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Relu_80:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[278], attr, VSI_NN_TYPE_INT8, 77943520, 1179648);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Conv2D_91_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Relu_80:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[279], attr, VSI_NN_TYPE_INT32, 77942496, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Conv2D_92_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Relu_81:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[280], attr, VSI_NN_TYPE_INT8, 79124192, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Conv2D_92_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Relu_81:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[281], attr, VSI_NN_TYPE_INT32, 79123168, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_49_InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_39:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[282], attr, VSI_NN_TYPE_INT8, 79912672, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_49_InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_39:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[283], attr, VSI_NN_TYPE_INT32, 79911648, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_64_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_60:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[284], attr, VSI_NN_TYPE_INT8, 80307424, 589824);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_64_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_60:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[285], attr, VSI_NN_TYPE_INT32, 80305888, 1536);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_71_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_69:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[286], attr, VSI_NN_TYPE_INT8, 82080480, 589824);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_71_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_69:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[287], attr, VSI_NN_TYPE_INT32, 82078944, 1536);

    /* @trans_InceptionV4/InceptionV4/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_59_conv_495:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1536;
    attr.size[3] = 1536;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[288], attr, VSI_NN_TYPE_INT8, 187185376, 21233664);

    /* @trans_InceptionV4/InceptionV4/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_59_conv_495:bias */
    attr.size[0] = 1536;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[289], attr, VSI_NN_TYPE_INT32, 187179232, 6144);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_55_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_44:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[290], attr, VSI_NN_TYPE_INT8, 80898272, 884736);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_55_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_44:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[291], attr, VSI_NN_TYPE_INT32, 80897248, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_56_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_45:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[292], attr, VSI_NN_TYPE_INT8, 81784032, 294912);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_56_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_45:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[293], attr, VSI_NN_TYPE_INT32, 81783008, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Conv2D_68_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Relu_66:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 448;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[294], attr, VSI_NN_TYPE_INT8, 82672096, 516096);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Conv2D_68_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Relu_66:bias */
    attr.size[0] = 448;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[295], attr, VSI_NN_TYPE_INT32, 82670304, 1792);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_54_InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_42:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[296], attr, VSI_NN_TYPE_INT8, 86830560, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_54_InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_42:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[297], attr, VSI_NN_TYPE_INT32, 86829536, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_65_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_61:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 448;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[298], attr, VSI_NN_TYPE_INT8, 83190240, 2064384);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_65_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_61:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[299], attr, VSI_NN_TYPE_INT32, 83188192, 2048);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Conv2D_57_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Relu_46:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[300], attr, VSI_NN_TYPE_INT8, 85255648, 1179648);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Conv2D_57_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Relu_46:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[301], attr, VSI_NN_TYPE_INT32, 85254624, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Conv2D_58_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Relu_47:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[302], attr, VSI_NN_TYPE_INT8, 86436320, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Conv2D_58_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Relu_47:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[303], attr, VSI_NN_TYPE_INT32, 86435296, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Conv2D_15_InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Relu_5:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[304], attr, VSI_NN_TYPE_INT8, 87224800, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Conv2D_15_InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Relu_5:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[305], attr, VSI_NN_TYPE_INT32, 87223776, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Conv2D_30_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Relu_26:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[306], attr, VSI_NN_TYPE_INT8, 87619552, 589824);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Conv2D_30_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Relu_26:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[307], attr, VSI_NN_TYPE_INT32, 87618016, 1536);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Conv2D_37_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Relu_35:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 384;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[308], attr, VSI_NN_TYPE_INT8, 89392608, 589824);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Conv2D_37_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Relu_35:bias */
    attr.size[0] = 384;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[309], attr, VSI_NN_TYPE_INT32, 89391072, 1536);

    /* @trans_InceptionV4/InceptionV4/Mixed_7d/Branch_3/AvgPool_0a_3x3/AvgPool_25_conv_494:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1536;
    attr.size[3] = 1536;
    attr.dim_num = 4;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[310], attr, VSI_NN_TYPE_INT8, 208425184, 21233664);

    /* @trans_InceptionV4/InceptionV4/Mixed_7d/Branch_3/AvgPool_0a_3x3/AvgPool_25_conv_494:bias */
    attr.size[0] = 1536;
    attr.dim_num = 1;
    attr.dtype.fl = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[311], attr, VSI_NN_TYPE_INT32, 208419040, 6144);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Conv2D_21_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Relu_10:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[312], attr, VSI_NN_TYPE_INT8, 88210400, 884736);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Conv2D_21_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Relu_10:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[313], attr, VSI_NN_TYPE_INT32, 88209376, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Conv2D_22_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Relu_11:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[314], attr, VSI_NN_TYPE_INT8, 89096160, 294912);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Conv2D_22_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Relu_11:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[315], attr, VSI_NN_TYPE_INT32, 89095136, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Conv2D_34_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Relu_32:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 384;
    attr.size[3] = 448;
    attr.dim_num = 4;
    attr.dtype.fl = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[316], attr, VSI_NN_TYPE_INT8, 89984224, 516096);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Conv2D_34_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Relu_32:bias */
    attr.size[0] = 448;
    attr.dim_num = 1;
    attr.dtype.fl = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[317], attr, VSI_NN_TYPE_INT32, 89982432, 1792);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Conv2D_20_InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Relu_8:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1536;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[318], attr, VSI_NN_TYPE_INT8, 94142688, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Conv2D_20_InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Relu_8:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[319], attr, VSI_NN_TYPE_INT32, 94141664, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Conv2D_31_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Relu_27:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 448;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[320], attr, VSI_NN_TYPE_INT8, 90502368, 2064384);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Conv2D_31_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Relu_27:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[321], attr, VSI_NN_TYPE_INT32, 90500320, 2048);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Conv2D_23_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Relu_12:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[322], attr, VSI_NN_TYPE_INT8, 92567776, 1179648);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Conv2D_23_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Relu_12:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[323], attr, VSI_NN_TYPE_INT32, 92566752, 1024);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Conv2D_24_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Relu_13:weight */
    attr.size[0] = 1;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.fl = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[324], attr, VSI_NN_TYPE_INT8, 93748448, 393216);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Conv2D_24_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Relu_13:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.fl = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[325], attr, VSI_NN_TYPE_INT32, 93747424, 1024);

    /* @trans_InceptionV4/Logits/Logits/BiasAdd_2:weight */
    attr.size[0] = 1536;
    attr.size[1] = 1001;
    attr.dim_num = 2;
    attr.dtype.fl = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[326], attr, VSI_NN_TYPE_INT8, 229662852, 1537536);

    /* @trans_InceptionV4/Logits/Logits/BiasAdd_2:bias */
    attr.size[0] = 1001;
    attr.dim_num = 1;
    attr.dtype.fl = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_CONST_TENSOR(const_tensor[327], attr, VSI_NN_TYPE_INT32, 229658848, 4004);



    /* @InceptionV4/InceptionV4/Conv2d_1a_3x3/Conv2D_493_InceptionV4/InceptionV4/Conv2d_1a_3x3/Relu_491:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Conv2d_2a_3x3/Conv2D_490_InceptionV4/InceptionV4/Conv2d_2a_3x3/Relu_488:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Conv2d_2b_3x3/Conv2D_487_InceptionV4/InceptionV4/Conv2d_2b_3x3/Relu_485:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_3a/Branch_0/MaxPool_0a_3x3/MaxPool_481:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Conv2D_484_InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Relu_482:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_3a/concat_480:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Conv2D_472_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Relu_468:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Conv2D_479_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Relu_477:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Conv2D_466_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Relu_462:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Conv2D_476_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Relu_474:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Conv2D_473_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Relu_469:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Conv2D_467_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Relu_463:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_4a/concat_461:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5a/Branch_1/MaxPool_1a_3x3/MaxPool_458:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Conv2D_460_InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Relu_457:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5a/concat_456:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_442_InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_434:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_451_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_446:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_455_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_453:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_448_conv_507:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Conv2D_443_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Relu_435:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_452_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_447:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_445_InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_437:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_444_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_436:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5b/concat_433:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_419_InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_411:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Conv2D_428_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Relu_423:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_432_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_430:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_425_conv_506:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Conv2D_420_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Relu_412:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_429_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_424:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_422_InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_414:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_421_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_413:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[32]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5c/concat_410:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[33]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_396_InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_388:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[34]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_405_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_400:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[35]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_409_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_407:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[36]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_402_conv_505:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[37]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Conv2D_397_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Relu_389:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[38]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_406_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_401:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[39]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_399_InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_391:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[40]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_398_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_390:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[41]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5d/concat_387:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[42]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Conv2D_373_InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Relu_365:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[43]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Conv2D_382_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Relu_377:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[44]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Conv2D_386_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Relu_384:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[45]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_5e/Branch_3/AvgPool_0a_3x3/AvgPool_379_conv_504:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[46]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Conv2D_374_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Relu_366:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[47]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Conv2D_383_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Relu_378:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[48]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Conv2D_376_InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Relu_368:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[49]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Conv2D_375_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Relu_367:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[50]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_5e/concat_364:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[51]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_2/MaxPool_1a_3x3/MaxPool_353:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[52]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Conv2D_356_InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Relu_351:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[53]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_363_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_361:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[54]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_360_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_358:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[55]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Conv2D_357_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Relu_352:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[56]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6a/concat_350:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[57]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_327_InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_319:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[58]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_342_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_338:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[59]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_349_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_347:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[60]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_333_conv_503:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[61]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_336_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_331:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[62]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_346_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_344:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[63]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_330_InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_322:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[64]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_328_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_320:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[65]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_343_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_339:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[66]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_337_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_332:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[67]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_329_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_321:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[68]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6b/concat_318:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[69]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_295_InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_287:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[70]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_310_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_306:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[71]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_317_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_315:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[72]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_301_conv_502:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[73]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_304_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_299:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[74]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_314_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_312:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[75]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_298_InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_290:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[76]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_296_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_288:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[77]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_311_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_307:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[78]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_305_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_300:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[79]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_297_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_289:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[80]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6c/concat_286:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[81]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_263_InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_255:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[82]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_278_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_274:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[83]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_285_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_283:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[84]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_269_conv_501:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[85]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_272_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_267:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[86]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_282_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_280:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[87]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_266_InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_258:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[88]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_264_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_256:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[89]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_279_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_275:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[90]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_273_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_268:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[91]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_265_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_257:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[92]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6d/concat_254:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[93]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_231_InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_223:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[94]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_246_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_242:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[95]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_253_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_251:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[96]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_237_conv_500:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[97]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_240_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_235:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[98]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_250_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_248:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[99]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_234_InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_226:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[100]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_232_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_224:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[101]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_247_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_243:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[102]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_241_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_236:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[103]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_233_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_225:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[104]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6e/concat_222:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[105]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Conv2D_199_InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Relu_191:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[106]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Conv2D_214_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Relu_210:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[107]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Conv2D_221_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Relu_219:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[108]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_6f/Branch_3/AvgPool_0a_3x3/AvgPool_205_conv_499:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[109]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Conv2D_208_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Relu_203:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[110]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Conv2D_218_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Relu_216:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[111]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Conv2D_202_InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Relu_194:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[112]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Conv2D_200_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Relu_192:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[113]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Conv2D_215_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Relu_211:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[114]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Conv2D_209_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Relu_204:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[115]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Conv2D_201_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Relu_193:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[116]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6f/concat_190:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[117]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Conv2D_167_InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Relu_159:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[118]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Conv2D_182_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Relu_178:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[119]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Conv2D_189_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Relu_187:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[120]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_6g/Branch_3/AvgPool_0a_3x3/AvgPool_173_conv_498:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[121]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Conv2D_176_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Relu_171:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[122]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Conv2D_186_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Relu_184:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[123]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Conv2D_170_InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Relu_162:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[124]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Conv2D_168_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Relu_160:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[125]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Conv2D_183_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Relu_179:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[126]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Conv2D_177_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Relu_172:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[127]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Conv2D_169_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Relu_161:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[128]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6g/concat_158:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[129]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Conv2D_135_InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Relu_127:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[130]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Conv2D_150_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Relu_146:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[131]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Conv2D_157_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Relu_155:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[132]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_6h/Branch_3/AvgPool_0a_3x3/AvgPool_141_conv_497:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[133]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Conv2D_144_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Relu_139:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[134]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Conv2D_154_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Relu_152:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[135]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Conv2D_138_InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Relu_130:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[136]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Conv2D_136_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Relu_128:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[137]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Conv2D_151_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Relu_147:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[138]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Conv2D_145_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Relu_140:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[139]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Conv2D_137_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Relu_129:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[140]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_6h/concat_126:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[141]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_2/MaxPool_1a_3x3/MaxPool_109:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[142]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_118_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_114:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[143]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_125_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_123:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[144]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_112_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_107:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[145]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_122_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_120:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[146]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_119_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_115:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[147]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_113_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_108:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[148]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7a/concat_106:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[149]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_83_InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_73:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[150]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_98_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_94:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[151]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_105_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_103:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[152]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_93_conv_496:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[153]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_89_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_78:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[154]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Conv2D_90_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Relu_79:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[155]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Conv2D_102_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Relu_100:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[156]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_88_InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_76:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[157]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_1/concat_74:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[158]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_99_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_95:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[159]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Conv2D_91_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Relu_80:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[160]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Conv2D_92_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Relu_81:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[161]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/Branch_2/concat_75:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[162]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7b/concat_72:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[163]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_49_InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_39:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[164]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_64_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_60:out0 */
    attr.dtype.fl = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[165]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_71_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_69:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[166]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_59_conv_495:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[167]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_55_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_44:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[168]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_56_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_45:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[169]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Conv2D_68_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Relu_66:out0 */
    attr.dtype.fl = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[170]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_54_InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_42:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[171]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_1/concat_40:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[172]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_65_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_61:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[173]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Conv2D_57_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Relu_46:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[174]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Conv2D_58_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Relu_47:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[175]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/Branch_2/concat_41:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[176]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7c/concat_38:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[177]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Conv2D_15_InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Relu_5:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[178]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Conv2D_30_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Relu_26:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[179]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Conv2D_37_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Relu_35:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[180]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @trans_InceptionV4/InceptionV4/Mixed_7d/Branch_3/AvgPool_0a_3x3/AvgPool_25_conv_494:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[181]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Conv2D_21_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Relu_10:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[182]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Conv2D_22_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Relu_11:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[183]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Conv2D_34_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Relu_32:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[184]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Conv2D_20_InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Relu_8:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[185]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_1/concat_6:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[186]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Conv2D_31_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Relu_27:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[187]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Conv2D_23_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Relu_12:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[188]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Conv2D_24_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Relu_13:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[189]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/Branch_2/concat_7:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[190]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/InceptionV4/Mixed_7d/concat_4:out0 */
    attr.dtype.fl = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[191]->output.tensors[0], attr, VSI_NN_TYPE_INT8);

    /* @InceptionV4/Logits/AvgPool_1a/AvgPool_3:out0 */
    attr.dtype.fl = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_DFP;
    NEW_VIRTUAL_TENSOR(node[192]->output.tensors[0], attr, VSI_NN_TYPE_INT8);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[0]->input.tensors[0] = norm_tensor[0];
    node[193]->output.tensors[0] = norm_tensor[1];

    /* InceptionV4/InceptionV4/Conv2d_1a_3x3/Conv2D_493_InceptionV4/InceptionV4/Conv2d_1a_3x3/Relu_491 */
    node[0]->input.tensors[1] = const_tensor[0]; /* data_weight */
    node[0]->input.tensors[2] = const_tensor[1]; /* data_bias */

    /* InceptionV4/InceptionV4/Conv2d_2a_3x3/Conv2D_490_InceptionV4/InceptionV4/Conv2d_2a_3x3/Relu_488 */
    node[1]->input.tensors[0] = node[0]->output.tensors[0];
    node[1]->input.tensors[1] = const_tensor[2]; /* data_weight */
    node[1]->input.tensors[2] = const_tensor[3]; /* data_bias */

    /* InceptionV4/InceptionV4/Conv2d_2b_3x3/Conv2D_487_InceptionV4/InceptionV4/Conv2d_2b_3x3/Relu_485 */
    node[2]->input.tensors[0] = node[1]->output.tensors[0];
    node[2]->input.tensors[1] = const_tensor[4]; /* data_weight */
    node[2]->input.tensors[2] = const_tensor[5]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_3a/Branch_0/MaxPool_0a_3x3/MaxPool_481 */
    node[3]->input.tensors[0] = node[2]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Conv2D_484_InceptionV4/InceptionV4/Mixed_3a/Branch_1/Conv2d_0a_3x3/Relu_482 */
    node[4]->input.tensors[0] = node[2]->output.tensors[0];
    node[4]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[4]->input.tensors[2] = const_tensor[7]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_3a/concat_480 */
    node[5]->input.tensors[0] = node[3]->output.tensors[0];
    node[5]->input.tensors[1] = node[4]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Conv2D_472_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_0a_1x1/Relu_468 */
    node[6]->input.tensors[0] = node[5]->output.tensors[0];
    node[6]->input.tensors[1] = const_tensor[8]; /* data_weight */
    node[6]->input.tensors[2] = const_tensor[9]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Conv2D_479_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0a_1x1/Relu_477 */
    node[7]->input.tensors[0] = node[5]->output.tensors[0];
    node[7]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[7]->input.tensors[2] = const_tensor[11]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Conv2D_466_InceptionV4/InceptionV4/Mixed_4a/Branch_0/Conv2d_1a_3x3/Relu_462 */
    node[8]->input.tensors[0] = node[6]->output.tensors[0];
    node[8]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[8]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Conv2D_476_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0b_1x7/Relu_474 */
    node[9]->input.tensors[0] = node[7]->output.tensors[0];
    node[9]->input.tensors[1] = const_tensor[14]; /* data_weight */
    node[9]->input.tensors[2] = const_tensor[15]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Conv2D_473_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_0c_7x1/Relu_469 */
    node[10]->input.tensors[0] = node[9]->output.tensors[0];
    node[10]->input.tensors[1] = const_tensor[16]; /* data_weight */
    node[10]->input.tensors[2] = const_tensor[17]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Conv2D_467_InceptionV4/InceptionV4/Mixed_4a/Branch_1/Conv2d_1a_3x3/Relu_463 */
    node[11]->input.tensors[0] = node[10]->output.tensors[0];
    node[11]->input.tensors[1] = const_tensor[18]; /* data_weight */
    node[11]->input.tensors[2] = const_tensor[19]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_4a/concat_461 */
    node[12]->input.tensors[0] = node[8]->output.tensors[0];
    node[12]->input.tensors[1] = node[11]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_5a/Branch_1/MaxPool_1a_3x3/MaxPool_458 */
    node[13]->input.tensors[0] = node[12]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Conv2D_460_InceptionV4/InceptionV4/Mixed_5a/Branch_0/Conv2d_1a_3x3/Relu_457 */
    node[14]->input.tensors[0] = node[12]->output.tensors[0];
    node[14]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[14]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5a/concat_456 */
    node[15]->input.tensors[0] = node[14]->output.tensors[0];
    node[15]->input.tensors[1] = node[13]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Conv2D_442_InceptionV4/InceptionV4/Mixed_5b/Branch_0/Conv2d_0a_1x1/Relu_434 */
    node[16]->input.tensors[0] = node[15]->output.tensors[0];
    node[16]->input.tensors[1] = const_tensor[22]; /* data_weight */
    node[16]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Conv2D_451_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0a_1x1/Relu_446 */
    node[17]->input.tensors[0] = node[15]->output.tensors[0];
    node[17]->input.tensors[1] = const_tensor[24]; /* data_weight */
    node[17]->input.tensors[2] = const_tensor[25]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Conv2D_455_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0a_1x1/Relu_453 */
    node[18]->input.tensors[0] = node[15]->output.tensors[0];
    node[18]->input.tensors[1] = const_tensor[26]; /* data_weight */
    node[18]->input.tensors[2] = const_tensor[27]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool_448_conv_507 */
    node[19]->input.tensors[0] = node[15]->output.tensors[0];
    node[19]->input.tensors[1] = const_tensor[28]; /* data_weight */
    node[19]->input.tensors[2] = const_tensor[29]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Conv2D_443_InceptionV4/InceptionV4/Mixed_5b/Branch_1/Conv2d_0b_3x3/Relu_435 */
    node[20]->input.tensors[0] = node[17]->output.tensors[0];
    node[20]->input.tensors[1] = const_tensor[30]; /* data_weight */
    node[20]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Conv2D_452_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0b_3x3/Relu_447 */
    node[21]->input.tensors[0] = node[18]->output.tensors[0];
    node[21]->input.tensors[1] = const_tensor[32]; /* data_weight */
    node[21]->input.tensors[2] = const_tensor[33]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Conv2D_445_InceptionV4/InceptionV4/Mixed_5b/Branch_3/Conv2d_0b_1x1/Relu_437 */
    node[22]->input.tensors[0] = node[19]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[34]; /* data_weight */
    node[22]->input.tensors[2] = const_tensor[35]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Conv2D_444_InceptionV4/InceptionV4/Mixed_5b/Branch_2/Conv2d_0c_3x3/Relu_436 */
    node[23]->input.tensors[0] = node[21]->output.tensors[0];
    node[23]->input.tensors[1] = const_tensor[36]; /* data_weight */
    node[23]->input.tensors[2] = const_tensor[37]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5b/concat_433 */
    node[24]->input.tensors[0] = node[16]->output.tensors[0];
    node[24]->input.tensors[1] = node[20]->output.tensors[0];
    node[24]->input.tensors[2] = node[23]->output.tensors[0];
    node[24]->input.tensors[3] = node[22]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Conv2D_419_InceptionV4/InceptionV4/Mixed_5c/Branch_0/Conv2d_0a_1x1/Relu_411 */
    node[25]->input.tensors[0] = node[24]->output.tensors[0];
    node[25]->input.tensors[1] = const_tensor[38]; /* data_weight */
    node[25]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Conv2D_428_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0a_1x1/Relu_423 */
    node[26]->input.tensors[0] = node[24]->output.tensors[0];
    node[26]->input.tensors[1] = const_tensor[40]; /* data_weight */
    node[26]->input.tensors[2] = const_tensor[41]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Conv2D_432_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/Relu_430 */
    node[27]->input.tensors[0] = node[24]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[43]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_5c/Branch_3/AvgPool_0a_3x3/AvgPool_425_conv_506 */
    node[28]->input.tensors[0] = node[24]->output.tensors[0];
    node[28]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[28]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Conv2D_420_InceptionV4/InceptionV4/Mixed_5c/Branch_1/Conv2d_0b_3x3/Relu_412 */
    node[29]->input.tensors[0] = node[26]->output.tensors[0];
    node[29]->input.tensors[1] = const_tensor[46]; /* data_weight */
    node[29]->input.tensors[2] = const_tensor[47]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Conv2D_429_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0b_3x3/Relu_424 */
    node[30]->input.tensors[0] = node[27]->output.tensors[0];
    node[30]->input.tensors[1] = const_tensor[48]; /* data_weight */
    node[30]->input.tensors[2] = const_tensor[49]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Conv2D_422_InceptionV4/InceptionV4/Mixed_5c/Branch_3/Conv2d_0b_1x1/Relu_414 */
    node[31]->input.tensors[0] = node[28]->output.tensors[0];
    node[31]->input.tensors[1] = const_tensor[50]; /* data_weight */
    node[31]->input.tensors[2] = const_tensor[51]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Conv2D_421_InceptionV4/InceptionV4/Mixed_5c/Branch_2/Conv2d_0c_3x3/Relu_413 */
    node[32]->input.tensors[0] = node[30]->output.tensors[0];
    node[32]->input.tensors[1] = const_tensor[52]; /* data_weight */
    node[32]->input.tensors[2] = const_tensor[53]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5c/concat_410 */
    node[33]->input.tensors[0] = node[25]->output.tensors[0];
    node[33]->input.tensors[1] = node[29]->output.tensors[0];
    node[33]->input.tensors[2] = node[32]->output.tensors[0];
    node[33]->input.tensors[3] = node[31]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Conv2D_396_InceptionV4/InceptionV4/Mixed_5d/Branch_0/Conv2d_0a_1x1/Relu_388 */
    node[34]->input.tensors[0] = node[33]->output.tensors[0];
    node[34]->input.tensors[1] = const_tensor[54]; /* data_weight */
    node[34]->input.tensors[2] = const_tensor[55]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Conv2D_405_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0a_1x1/Relu_400 */
    node[35]->input.tensors[0] = node[33]->output.tensors[0];
    node[35]->input.tensors[1] = const_tensor[56]; /* data_weight */
    node[35]->input.tensors[2] = const_tensor[57]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Conv2D_409_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0a_1x1/Relu_407 */
    node[36]->input.tensors[0] = node[33]->output.tensors[0];
    node[36]->input.tensors[1] = const_tensor[58]; /* data_weight */
    node[36]->input.tensors[2] = const_tensor[59]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_5d/Branch_3/AvgPool_0a_3x3/AvgPool_402_conv_505 */
    node[37]->input.tensors[0] = node[33]->output.tensors[0];
    node[37]->input.tensors[1] = const_tensor[60]; /* data_weight */
    node[37]->input.tensors[2] = const_tensor[61]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Conv2D_397_InceptionV4/InceptionV4/Mixed_5d/Branch_1/Conv2d_0b_3x3/Relu_389 */
    node[38]->input.tensors[0] = node[35]->output.tensors[0];
    node[38]->input.tensors[1] = const_tensor[62]; /* data_weight */
    node[38]->input.tensors[2] = const_tensor[63]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Conv2D_406_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0b_3x3/Relu_401 */
    node[39]->input.tensors[0] = node[36]->output.tensors[0];
    node[39]->input.tensors[1] = const_tensor[64]; /* data_weight */
    node[39]->input.tensors[2] = const_tensor[65]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Conv2D_399_InceptionV4/InceptionV4/Mixed_5d/Branch_3/Conv2d_0b_1x1/Relu_391 */
    node[40]->input.tensors[0] = node[37]->output.tensors[0];
    node[40]->input.tensors[1] = const_tensor[66]; /* data_weight */
    node[40]->input.tensors[2] = const_tensor[67]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Conv2D_398_InceptionV4/InceptionV4/Mixed_5d/Branch_2/Conv2d_0c_3x3/Relu_390 */
    node[41]->input.tensors[0] = node[39]->output.tensors[0];
    node[41]->input.tensors[1] = const_tensor[68]; /* data_weight */
    node[41]->input.tensors[2] = const_tensor[69]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5d/concat_387 */
    node[42]->input.tensors[0] = node[34]->output.tensors[0];
    node[42]->input.tensors[1] = node[38]->output.tensors[0];
    node[42]->input.tensors[2] = node[41]->output.tensors[0];
    node[42]->input.tensors[3] = node[40]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Conv2D_373_InceptionV4/InceptionV4/Mixed_5e/Branch_0/Conv2d_0a_1x1/Relu_365 */
    node[43]->input.tensors[0] = node[42]->output.tensors[0];
    node[43]->input.tensors[1] = const_tensor[70]; /* data_weight */
    node[43]->input.tensors[2] = const_tensor[71]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Conv2D_382_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0a_1x1/Relu_377 */
    node[44]->input.tensors[0] = node[42]->output.tensors[0];
    node[44]->input.tensors[1] = const_tensor[72]; /* data_weight */
    node[44]->input.tensors[2] = const_tensor[73]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Conv2D_386_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0a_1x1/Relu_384 */
    node[45]->input.tensors[0] = node[42]->output.tensors[0];
    node[45]->input.tensors[1] = const_tensor[74]; /* data_weight */
    node[45]->input.tensors[2] = const_tensor[75]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_5e/Branch_3/AvgPool_0a_3x3/AvgPool_379_conv_504 */
    node[46]->input.tensors[0] = node[42]->output.tensors[0];
    node[46]->input.tensors[1] = const_tensor[76]; /* data_weight */
    node[46]->input.tensors[2] = const_tensor[77]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Conv2D_374_InceptionV4/InceptionV4/Mixed_5e/Branch_1/Conv2d_0b_3x3/Relu_366 */
    node[47]->input.tensors[0] = node[44]->output.tensors[0];
    node[47]->input.tensors[1] = const_tensor[78]; /* data_weight */
    node[47]->input.tensors[2] = const_tensor[79]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Conv2D_383_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0b_3x3/Relu_378 */
    node[48]->input.tensors[0] = node[45]->output.tensors[0];
    node[48]->input.tensors[1] = const_tensor[80]; /* data_weight */
    node[48]->input.tensors[2] = const_tensor[81]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Conv2D_376_InceptionV4/InceptionV4/Mixed_5e/Branch_3/Conv2d_0b_1x1/Relu_368 */
    node[49]->input.tensors[0] = node[46]->output.tensors[0];
    node[49]->input.tensors[1] = const_tensor[82]; /* data_weight */
    node[49]->input.tensors[2] = const_tensor[83]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Conv2D_375_InceptionV4/InceptionV4/Mixed_5e/Branch_2/Conv2d_0c_3x3/Relu_367 */
    node[50]->input.tensors[0] = node[48]->output.tensors[0];
    node[50]->input.tensors[1] = const_tensor[84]; /* data_weight */
    node[50]->input.tensors[2] = const_tensor[85]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_5e/concat_364 */
    node[51]->input.tensors[0] = node[43]->output.tensors[0];
    node[51]->input.tensors[1] = node[47]->output.tensors[0];
    node[51]->input.tensors[2] = node[50]->output.tensors[0];
    node[51]->input.tensors[3] = node[49]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6a/Branch_2/MaxPool_1a_3x3/MaxPool_353 */
    node[52]->input.tensors[0] = node[51]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Conv2D_356_InceptionV4/InceptionV4/Mixed_6a/Branch_0/Conv2d_1a_3x3/Relu_351 */
    node[53]->input.tensors[0] = node[51]->output.tensors[0];
    node[53]->input.tensors[1] = const_tensor[86]; /* data_weight */
    node[53]->input.tensors[2] = const_tensor[87]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Conv2D_363_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0a_1x1/Relu_361 */
    node[54]->input.tensors[0] = node[51]->output.tensors[0];
    node[54]->input.tensors[1] = const_tensor[88]; /* data_weight */
    node[54]->input.tensors[2] = const_tensor[89]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Conv2D_360_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_0b_3x3/Relu_358 */
    node[55]->input.tensors[0] = node[54]->output.tensors[0];
    node[55]->input.tensors[1] = const_tensor[90]; /* data_weight */
    node[55]->input.tensors[2] = const_tensor[91]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Conv2D_357_InceptionV4/InceptionV4/Mixed_6a/Branch_1/Conv2d_1a_3x3/Relu_352 */
    node[56]->input.tensors[0] = node[55]->output.tensors[0];
    node[56]->input.tensors[1] = const_tensor[92]; /* data_weight */
    node[56]->input.tensors[2] = const_tensor[93]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6a/concat_350 */
    node[57]->input.tensors[0] = node[53]->output.tensors[0];
    node[57]->input.tensors[1] = node[56]->output.tensors[0];
    node[57]->input.tensors[2] = node[52]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Conv2D_327_InceptionV4/InceptionV4/Mixed_6b/Branch_0/Conv2d_0a_1x1/Relu_319 */
    node[58]->input.tensors[0] = node[57]->output.tensors[0];
    node[58]->input.tensors[1] = const_tensor[94]; /* data_weight */
    node[58]->input.tensors[2] = const_tensor[95]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Conv2D_342_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0a_1x1/Relu_338 */
    node[59]->input.tensors[0] = node[57]->output.tensors[0];
    node[59]->input.tensors[1] = const_tensor[96]; /* data_weight */
    node[59]->input.tensors[2] = const_tensor[97]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Conv2D_349_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0a_1x1/Relu_347 */
    node[60]->input.tensors[0] = node[57]->output.tensors[0];
    node[60]->input.tensors[1] = const_tensor[98]; /* data_weight */
    node[60]->input.tensors[2] = const_tensor[99]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_6b/Branch_3/AvgPool_0a_3x3/AvgPool_333_conv_503 */
    node[61]->input.tensors[0] = node[57]->output.tensors[0];
    node[61]->input.tensors[1] = const_tensor[100]; /* data_weight */
    node[61]->input.tensors[2] = const_tensor[101]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Conv2D_336_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0b_1x7/Relu_331 */
    node[62]->input.tensors[0] = node[59]->output.tensors[0];
    node[62]->input.tensors[1] = const_tensor[102]; /* data_weight */
    node[62]->input.tensors[2] = const_tensor[103]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Conv2D_346_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0b_7x1/Relu_344 */
    node[63]->input.tensors[0] = node[60]->output.tensors[0];
    node[63]->input.tensors[1] = const_tensor[104]; /* data_weight */
    node[63]->input.tensors[2] = const_tensor[105]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Conv2D_330_InceptionV4/InceptionV4/Mixed_6b/Branch_3/Conv2d_0b_1x1/Relu_322 */
    node[64]->input.tensors[0] = node[61]->output.tensors[0];
    node[64]->input.tensors[1] = const_tensor[106]; /* data_weight */
    node[64]->input.tensors[2] = const_tensor[107]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Conv2D_328_InceptionV4/InceptionV4/Mixed_6b/Branch_1/Conv2d_0c_7x1/Relu_320 */
    node[65]->input.tensors[0] = node[62]->output.tensors[0];
    node[65]->input.tensors[1] = const_tensor[108]; /* data_weight */
    node[65]->input.tensors[2] = const_tensor[109]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Conv2D_343_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0c_1x7/Relu_339 */
    node[66]->input.tensors[0] = node[63]->output.tensors[0];
    node[66]->input.tensors[1] = const_tensor[110]; /* data_weight */
    node[66]->input.tensors[2] = const_tensor[111]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Conv2D_337_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0d_7x1/Relu_332 */
    node[67]->input.tensors[0] = node[66]->output.tensors[0];
    node[67]->input.tensors[1] = const_tensor[112]; /* data_weight */
    node[67]->input.tensors[2] = const_tensor[113]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Conv2D_329_InceptionV4/InceptionV4/Mixed_6b/Branch_2/Conv2d_0e_1x7/Relu_321 */
    node[68]->input.tensors[0] = node[67]->output.tensors[0];
    node[68]->input.tensors[1] = const_tensor[114]; /* data_weight */
    node[68]->input.tensors[2] = const_tensor[115]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6b/concat_318 */
    node[69]->input.tensors[0] = node[58]->output.tensors[0];
    node[69]->input.tensors[1] = node[65]->output.tensors[0];
    node[69]->input.tensors[2] = node[68]->output.tensors[0];
    node[69]->input.tensors[3] = node[64]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Conv2D_295_InceptionV4/InceptionV4/Mixed_6c/Branch_0/Conv2d_0a_1x1/Relu_287 */
    node[70]->input.tensors[0] = node[69]->output.tensors[0];
    node[70]->input.tensors[1] = const_tensor[116]; /* data_weight */
    node[70]->input.tensors[2] = const_tensor[117]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Conv2D_310_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0a_1x1/Relu_306 */
    node[71]->input.tensors[0] = node[69]->output.tensors[0];
    node[71]->input.tensors[1] = const_tensor[118]; /* data_weight */
    node[71]->input.tensors[2] = const_tensor[119]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Conv2D_317_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0a_1x1/Relu_315 */
    node[72]->input.tensors[0] = node[69]->output.tensors[0];
    node[72]->input.tensors[1] = const_tensor[120]; /* data_weight */
    node[72]->input.tensors[2] = const_tensor[121]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_6c/Branch_3/AvgPool_0a_3x3/AvgPool_301_conv_502 */
    node[73]->input.tensors[0] = node[69]->output.tensors[0];
    node[73]->input.tensors[1] = const_tensor[122]; /* data_weight */
    node[73]->input.tensors[2] = const_tensor[123]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Conv2D_304_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0b_1x7/Relu_299 */
    node[74]->input.tensors[0] = node[71]->output.tensors[0];
    node[74]->input.tensors[1] = const_tensor[124]; /* data_weight */
    node[74]->input.tensors[2] = const_tensor[125]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Conv2D_314_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0b_7x1/Relu_312 */
    node[75]->input.tensors[0] = node[72]->output.tensors[0];
    node[75]->input.tensors[1] = const_tensor[126]; /* data_weight */
    node[75]->input.tensors[2] = const_tensor[127]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Conv2D_298_InceptionV4/InceptionV4/Mixed_6c/Branch_3/Conv2d_0b_1x1/Relu_290 */
    node[76]->input.tensors[0] = node[73]->output.tensors[0];
    node[76]->input.tensors[1] = const_tensor[128]; /* data_weight */
    node[76]->input.tensors[2] = const_tensor[129]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Conv2D_296_InceptionV4/InceptionV4/Mixed_6c/Branch_1/Conv2d_0c_7x1/Relu_288 */
    node[77]->input.tensors[0] = node[74]->output.tensors[0];
    node[77]->input.tensors[1] = const_tensor[130]; /* data_weight */
    node[77]->input.tensors[2] = const_tensor[131]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Conv2D_311_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0c_1x7/Relu_307 */
    node[78]->input.tensors[0] = node[75]->output.tensors[0];
    node[78]->input.tensors[1] = const_tensor[132]; /* data_weight */
    node[78]->input.tensors[2] = const_tensor[133]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Conv2D_305_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0d_7x1/Relu_300 */
    node[79]->input.tensors[0] = node[78]->output.tensors[0];
    node[79]->input.tensors[1] = const_tensor[134]; /* data_weight */
    node[79]->input.tensors[2] = const_tensor[135]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Conv2D_297_InceptionV4/InceptionV4/Mixed_6c/Branch_2/Conv2d_0e_1x7/Relu_289 */
    node[80]->input.tensors[0] = node[79]->output.tensors[0];
    node[80]->input.tensors[1] = const_tensor[136]; /* data_weight */
    node[80]->input.tensors[2] = const_tensor[137]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6c/concat_286 */
    node[81]->input.tensors[0] = node[70]->output.tensors[0];
    node[81]->input.tensors[1] = node[77]->output.tensors[0];
    node[81]->input.tensors[2] = node[80]->output.tensors[0];
    node[81]->input.tensors[3] = node[76]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Conv2D_263_InceptionV4/InceptionV4/Mixed_6d/Branch_0/Conv2d_0a_1x1/Relu_255 */
    node[82]->input.tensors[0] = node[81]->output.tensors[0];
    node[82]->input.tensors[1] = const_tensor[138]; /* data_weight */
    node[82]->input.tensors[2] = const_tensor[139]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Conv2D_278_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0a_1x1/Relu_274 */
    node[83]->input.tensors[0] = node[81]->output.tensors[0];
    node[83]->input.tensors[1] = const_tensor[140]; /* data_weight */
    node[83]->input.tensors[2] = const_tensor[141]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Conv2D_285_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0a_1x1/Relu_283 */
    node[84]->input.tensors[0] = node[81]->output.tensors[0];
    node[84]->input.tensors[1] = const_tensor[142]; /* data_weight */
    node[84]->input.tensors[2] = const_tensor[143]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_6d/Branch_3/AvgPool_0a_3x3/AvgPool_269_conv_501 */
    node[85]->input.tensors[0] = node[81]->output.tensors[0];
    node[85]->input.tensors[1] = const_tensor[144]; /* data_weight */
    node[85]->input.tensors[2] = const_tensor[145]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Conv2D_272_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0b_1x7/Relu_267 */
    node[86]->input.tensors[0] = node[83]->output.tensors[0];
    node[86]->input.tensors[1] = const_tensor[146]; /* data_weight */
    node[86]->input.tensors[2] = const_tensor[147]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Conv2D_282_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0b_7x1/Relu_280 */
    node[87]->input.tensors[0] = node[84]->output.tensors[0];
    node[87]->input.tensors[1] = const_tensor[148]; /* data_weight */
    node[87]->input.tensors[2] = const_tensor[149]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Conv2D_266_InceptionV4/InceptionV4/Mixed_6d/Branch_3/Conv2d_0b_1x1/Relu_258 */
    node[88]->input.tensors[0] = node[85]->output.tensors[0];
    node[88]->input.tensors[1] = const_tensor[150]; /* data_weight */
    node[88]->input.tensors[2] = const_tensor[151]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Conv2D_264_InceptionV4/InceptionV4/Mixed_6d/Branch_1/Conv2d_0c_7x1/Relu_256 */
    node[89]->input.tensors[0] = node[86]->output.tensors[0];
    node[89]->input.tensors[1] = const_tensor[152]; /* data_weight */
    node[89]->input.tensors[2] = const_tensor[153]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Conv2D_279_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0c_1x7/Relu_275 */
    node[90]->input.tensors[0] = node[87]->output.tensors[0];
    node[90]->input.tensors[1] = const_tensor[154]; /* data_weight */
    node[90]->input.tensors[2] = const_tensor[155]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Conv2D_273_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0d_7x1/Relu_268 */
    node[91]->input.tensors[0] = node[90]->output.tensors[0];
    node[91]->input.tensors[1] = const_tensor[156]; /* data_weight */
    node[91]->input.tensors[2] = const_tensor[157]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Conv2D_265_InceptionV4/InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/Relu_257 */
    node[92]->input.tensors[0] = node[91]->output.tensors[0];
    node[92]->input.tensors[1] = const_tensor[158]; /* data_weight */
    node[92]->input.tensors[2] = const_tensor[159]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6d/concat_254 */
    node[93]->input.tensors[0] = node[82]->output.tensors[0];
    node[93]->input.tensors[1] = node[89]->output.tensors[0];
    node[93]->input.tensors[2] = node[92]->output.tensors[0];
    node[93]->input.tensors[3] = node[88]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Conv2D_231_InceptionV4/InceptionV4/Mixed_6e/Branch_0/Conv2d_0a_1x1/Relu_223 */
    node[94]->input.tensors[0] = node[93]->output.tensors[0];
    node[94]->input.tensors[1] = const_tensor[160]; /* data_weight */
    node[94]->input.tensors[2] = const_tensor[161]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Conv2D_246_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0a_1x1/Relu_242 */
    node[95]->input.tensors[0] = node[93]->output.tensors[0];
    node[95]->input.tensors[1] = const_tensor[162]; /* data_weight */
    node[95]->input.tensors[2] = const_tensor[163]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Conv2D_253_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0a_1x1/Relu_251 */
    node[96]->input.tensors[0] = node[93]->output.tensors[0];
    node[96]->input.tensors[1] = const_tensor[164]; /* data_weight */
    node[96]->input.tensors[2] = const_tensor[165]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_6e/Branch_3/AvgPool_0a_3x3/AvgPool_237_conv_500 */
    node[97]->input.tensors[0] = node[93]->output.tensors[0];
    node[97]->input.tensors[1] = const_tensor[166]; /* data_weight */
    node[97]->input.tensors[2] = const_tensor[167]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Conv2D_240_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0b_1x7/Relu_235 */
    node[98]->input.tensors[0] = node[95]->output.tensors[0];
    node[98]->input.tensors[1] = const_tensor[168]; /* data_weight */
    node[98]->input.tensors[2] = const_tensor[169]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Conv2D_250_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0b_7x1/Relu_248 */
    node[99]->input.tensors[0] = node[96]->output.tensors[0];
    node[99]->input.tensors[1] = const_tensor[170]; /* data_weight */
    node[99]->input.tensors[2] = const_tensor[171]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Conv2D_234_InceptionV4/InceptionV4/Mixed_6e/Branch_3/Conv2d_0b_1x1/Relu_226 */
    node[100]->input.tensors[0] = node[97]->output.tensors[0];
    node[100]->input.tensors[1] = const_tensor[172]; /* data_weight */
    node[100]->input.tensors[2] = const_tensor[173]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Conv2D_232_InceptionV4/InceptionV4/Mixed_6e/Branch_1/Conv2d_0c_7x1/Relu_224 */
    node[101]->input.tensors[0] = node[98]->output.tensors[0];
    node[101]->input.tensors[1] = const_tensor[174]; /* data_weight */
    node[101]->input.tensors[2] = const_tensor[175]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Conv2D_247_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0c_1x7/Relu_243 */
    node[102]->input.tensors[0] = node[99]->output.tensors[0];
    node[102]->input.tensors[1] = const_tensor[176]; /* data_weight */
    node[102]->input.tensors[2] = const_tensor[177]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Conv2D_241_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0d_7x1/Relu_236 */
    node[103]->input.tensors[0] = node[102]->output.tensors[0];
    node[103]->input.tensors[1] = const_tensor[178]; /* data_weight */
    node[103]->input.tensors[2] = const_tensor[179]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Conv2D_233_InceptionV4/InceptionV4/Mixed_6e/Branch_2/Conv2d_0e_1x7/Relu_225 */
    node[104]->input.tensors[0] = node[103]->output.tensors[0];
    node[104]->input.tensors[1] = const_tensor[180]; /* data_weight */
    node[104]->input.tensors[2] = const_tensor[181]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6e/concat_222 */
    node[105]->input.tensors[0] = node[94]->output.tensors[0];
    node[105]->input.tensors[1] = node[101]->output.tensors[0];
    node[105]->input.tensors[2] = node[104]->output.tensors[0];
    node[105]->input.tensors[3] = node[100]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Conv2D_199_InceptionV4/InceptionV4/Mixed_6f/Branch_0/Conv2d_0a_1x1/Relu_191 */
    node[106]->input.tensors[0] = node[105]->output.tensors[0];
    node[106]->input.tensors[1] = const_tensor[182]; /* data_weight */
    node[106]->input.tensors[2] = const_tensor[183]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Conv2D_214_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/Relu_210 */
    node[107]->input.tensors[0] = node[105]->output.tensors[0];
    node[107]->input.tensors[1] = const_tensor[184]; /* data_weight */
    node[107]->input.tensors[2] = const_tensor[185]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Conv2D_221_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0a_1x1/Relu_219 */
    node[108]->input.tensors[0] = node[105]->output.tensors[0];
    node[108]->input.tensors[1] = const_tensor[186]; /* data_weight */
    node[108]->input.tensors[2] = const_tensor[187]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_6f/Branch_3/AvgPool_0a_3x3/AvgPool_205_conv_499 */
    node[109]->input.tensors[0] = node[105]->output.tensors[0];
    node[109]->input.tensors[1] = const_tensor[188]; /* data_weight */
    node[109]->input.tensors[2] = const_tensor[189]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Conv2D_208_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0b_1x7/Relu_203 */
    node[110]->input.tensors[0] = node[107]->output.tensors[0];
    node[110]->input.tensors[1] = const_tensor[190]; /* data_weight */
    node[110]->input.tensors[2] = const_tensor[191]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Conv2D_218_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0b_7x1/Relu_216 */
    node[111]->input.tensors[0] = node[108]->output.tensors[0];
    node[111]->input.tensors[1] = const_tensor[192]; /* data_weight */
    node[111]->input.tensors[2] = const_tensor[193]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Conv2D_202_InceptionV4/InceptionV4/Mixed_6f/Branch_3/Conv2d_0b_1x1/Relu_194 */
    node[112]->input.tensors[0] = node[109]->output.tensors[0];
    node[112]->input.tensors[1] = const_tensor[194]; /* data_weight */
    node[112]->input.tensors[2] = const_tensor[195]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Conv2D_200_InceptionV4/InceptionV4/Mixed_6f/Branch_1/Conv2d_0c_7x1/Relu_192 */
    node[113]->input.tensors[0] = node[110]->output.tensors[0];
    node[113]->input.tensors[1] = const_tensor[196]; /* data_weight */
    node[113]->input.tensors[2] = const_tensor[197]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Conv2D_215_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0c_1x7/Relu_211 */
    node[114]->input.tensors[0] = node[111]->output.tensors[0];
    node[114]->input.tensors[1] = const_tensor[198]; /* data_weight */
    node[114]->input.tensors[2] = const_tensor[199]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Conv2D_209_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0d_7x1/Relu_204 */
    node[115]->input.tensors[0] = node[114]->output.tensors[0];
    node[115]->input.tensors[1] = const_tensor[200]; /* data_weight */
    node[115]->input.tensors[2] = const_tensor[201]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Conv2D_201_InceptionV4/InceptionV4/Mixed_6f/Branch_2/Conv2d_0e_1x7/Relu_193 */
    node[116]->input.tensors[0] = node[115]->output.tensors[0];
    node[116]->input.tensors[1] = const_tensor[202]; /* data_weight */
    node[116]->input.tensors[2] = const_tensor[203]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6f/concat_190 */
    node[117]->input.tensors[0] = node[106]->output.tensors[0];
    node[117]->input.tensors[1] = node[113]->output.tensors[0];
    node[117]->input.tensors[2] = node[116]->output.tensors[0];
    node[117]->input.tensors[3] = node[112]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Conv2D_167_InceptionV4/InceptionV4/Mixed_6g/Branch_0/Conv2d_0a_1x1/Relu_159 */
    node[118]->input.tensors[0] = node[117]->output.tensors[0];
    node[118]->input.tensors[1] = const_tensor[204]; /* data_weight */
    node[118]->input.tensors[2] = const_tensor[205]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Conv2D_182_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0a_1x1/Relu_178 */
    node[119]->input.tensors[0] = node[117]->output.tensors[0];
    node[119]->input.tensors[1] = const_tensor[206]; /* data_weight */
    node[119]->input.tensors[2] = const_tensor[207]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Conv2D_189_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0a_1x1/Relu_187 */
    node[120]->input.tensors[0] = node[117]->output.tensors[0];
    node[120]->input.tensors[1] = const_tensor[208]; /* data_weight */
    node[120]->input.tensors[2] = const_tensor[209]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_6g/Branch_3/AvgPool_0a_3x3/AvgPool_173_conv_498 */
    node[121]->input.tensors[0] = node[117]->output.tensors[0];
    node[121]->input.tensors[1] = const_tensor[210]; /* data_weight */
    node[121]->input.tensors[2] = const_tensor[211]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Conv2D_176_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0b_1x7/Relu_171 */
    node[122]->input.tensors[0] = node[119]->output.tensors[0];
    node[122]->input.tensors[1] = const_tensor[212]; /* data_weight */
    node[122]->input.tensors[2] = const_tensor[213]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Conv2D_186_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0b_7x1/Relu_184 */
    node[123]->input.tensors[0] = node[120]->output.tensors[0];
    node[123]->input.tensors[1] = const_tensor[214]; /* data_weight */
    node[123]->input.tensors[2] = const_tensor[215]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Conv2D_170_InceptionV4/InceptionV4/Mixed_6g/Branch_3/Conv2d_0b_1x1/Relu_162 */
    node[124]->input.tensors[0] = node[121]->output.tensors[0];
    node[124]->input.tensors[1] = const_tensor[216]; /* data_weight */
    node[124]->input.tensors[2] = const_tensor[217]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Conv2D_168_InceptionV4/InceptionV4/Mixed_6g/Branch_1/Conv2d_0c_7x1/Relu_160 */
    node[125]->input.tensors[0] = node[122]->output.tensors[0];
    node[125]->input.tensors[1] = const_tensor[218]; /* data_weight */
    node[125]->input.tensors[2] = const_tensor[219]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Conv2D_183_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0c_1x7/Relu_179 */
    node[126]->input.tensors[0] = node[123]->output.tensors[0];
    node[126]->input.tensors[1] = const_tensor[220]; /* data_weight */
    node[126]->input.tensors[2] = const_tensor[221]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Conv2D_177_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0d_7x1/Relu_172 */
    node[127]->input.tensors[0] = node[126]->output.tensors[0];
    node[127]->input.tensors[1] = const_tensor[222]; /* data_weight */
    node[127]->input.tensors[2] = const_tensor[223]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Conv2D_169_InceptionV4/InceptionV4/Mixed_6g/Branch_2/Conv2d_0e_1x7/Relu_161 */
    node[128]->input.tensors[0] = node[127]->output.tensors[0];
    node[128]->input.tensors[1] = const_tensor[224]; /* data_weight */
    node[128]->input.tensors[2] = const_tensor[225]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6g/concat_158 */
    node[129]->input.tensors[0] = node[118]->output.tensors[0];
    node[129]->input.tensors[1] = node[125]->output.tensors[0];
    node[129]->input.tensors[2] = node[128]->output.tensors[0];
    node[129]->input.tensors[3] = node[124]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Conv2D_135_InceptionV4/InceptionV4/Mixed_6h/Branch_0/Conv2d_0a_1x1/Relu_127 */
    node[130]->input.tensors[0] = node[129]->output.tensors[0];
    node[130]->input.tensors[1] = const_tensor[226]; /* data_weight */
    node[130]->input.tensors[2] = const_tensor[227]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Conv2D_150_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0a_1x1/Relu_146 */
    node[131]->input.tensors[0] = node[129]->output.tensors[0];
    node[131]->input.tensors[1] = const_tensor[228]; /* data_weight */
    node[131]->input.tensors[2] = const_tensor[229]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Conv2D_157_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0a_1x1/Relu_155 */
    node[132]->input.tensors[0] = node[129]->output.tensors[0];
    node[132]->input.tensors[1] = const_tensor[230]; /* data_weight */
    node[132]->input.tensors[2] = const_tensor[231]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_6h/Branch_3/AvgPool_0a_3x3/AvgPool_141_conv_497 */
    node[133]->input.tensors[0] = node[129]->output.tensors[0];
    node[133]->input.tensors[1] = const_tensor[232]; /* data_weight */
    node[133]->input.tensors[2] = const_tensor[233]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Conv2D_144_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0b_1x7/Relu_139 */
    node[134]->input.tensors[0] = node[131]->output.tensors[0];
    node[134]->input.tensors[1] = const_tensor[234]; /* data_weight */
    node[134]->input.tensors[2] = const_tensor[235]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Conv2D_154_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0b_7x1/Relu_152 */
    node[135]->input.tensors[0] = node[132]->output.tensors[0];
    node[135]->input.tensors[1] = const_tensor[236]; /* data_weight */
    node[135]->input.tensors[2] = const_tensor[237]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Conv2D_138_InceptionV4/InceptionV4/Mixed_6h/Branch_3/Conv2d_0b_1x1/Relu_130 */
    node[136]->input.tensors[0] = node[133]->output.tensors[0];
    node[136]->input.tensors[1] = const_tensor[238]; /* data_weight */
    node[136]->input.tensors[2] = const_tensor[239]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Conv2D_136_InceptionV4/InceptionV4/Mixed_6h/Branch_1/Conv2d_0c_7x1/Relu_128 */
    node[137]->input.tensors[0] = node[134]->output.tensors[0];
    node[137]->input.tensors[1] = const_tensor[240]; /* data_weight */
    node[137]->input.tensors[2] = const_tensor[241]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Conv2D_151_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0c_1x7/Relu_147 */
    node[138]->input.tensors[0] = node[135]->output.tensors[0];
    node[138]->input.tensors[1] = const_tensor[242]; /* data_weight */
    node[138]->input.tensors[2] = const_tensor[243]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Conv2D_145_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0d_7x1/Relu_140 */
    node[139]->input.tensors[0] = node[138]->output.tensors[0];
    node[139]->input.tensors[1] = const_tensor[244]; /* data_weight */
    node[139]->input.tensors[2] = const_tensor[245]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Conv2D_137_InceptionV4/InceptionV4/Mixed_6h/Branch_2/Conv2d_0e_1x7/Relu_129 */
    node[140]->input.tensors[0] = node[139]->output.tensors[0];
    node[140]->input.tensors[1] = const_tensor[246]; /* data_weight */
    node[140]->input.tensors[2] = const_tensor[247]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_6h/concat_126 */
    node[141]->input.tensors[0] = node[130]->output.tensors[0];
    node[141]->input.tensors[1] = node[137]->output.tensors[0];
    node[141]->input.tensors[2] = node[140]->output.tensors[0];
    node[141]->input.tensors[3] = node[136]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7a/Branch_2/MaxPool_1a_3x3/MaxPool_109 */
    node[142]->input.tensors[0] = node[141]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Conv2D_118_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_0a_1x1/Relu_114 */
    node[143]->input.tensors[0] = node[141]->output.tensors[0];
    node[143]->input.tensors[1] = const_tensor[248]; /* data_weight */
    node[143]->input.tensors[2] = const_tensor[249]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Conv2D_125_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0a_1x1/Relu_123 */
    node[144]->input.tensors[0] = node[141]->output.tensors[0];
    node[144]->input.tensors[1] = const_tensor[250]; /* data_weight */
    node[144]->input.tensors[2] = const_tensor[251]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Conv2D_112_InceptionV4/InceptionV4/Mixed_7a/Branch_0/Conv2d_1a_3x3/Relu_107 */
    node[145]->input.tensors[0] = node[143]->output.tensors[0];
    node[145]->input.tensors[1] = const_tensor[252]; /* data_weight */
    node[145]->input.tensors[2] = const_tensor[253]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Conv2D_122_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0b_1x7/Relu_120 */
    node[146]->input.tensors[0] = node[144]->output.tensors[0];
    node[146]->input.tensors[1] = const_tensor[254]; /* data_weight */
    node[146]->input.tensors[2] = const_tensor[255]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Conv2D_119_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_0c_7x1/Relu_115 */
    node[147]->input.tensors[0] = node[146]->output.tensors[0];
    node[147]->input.tensors[1] = const_tensor[256]; /* data_weight */
    node[147]->input.tensors[2] = const_tensor[257]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Conv2D_113_InceptionV4/InceptionV4/Mixed_7a/Branch_1/Conv2d_1a_3x3/Relu_108 */
    node[148]->input.tensors[0] = node[147]->output.tensors[0];
    node[148]->input.tensors[1] = const_tensor[258]; /* data_weight */
    node[148]->input.tensors[2] = const_tensor[259]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7a/concat_106 */
    node[149]->input.tensors[0] = node[145]->output.tensors[0];
    node[149]->input.tensors[1] = node[148]->output.tensors[0];
    node[149]->input.tensors[2] = node[142]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Conv2D_83_InceptionV4/InceptionV4/Mixed_7b/Branch_0/Conv2d_0a_1x1/Relu_73 */
    node[150]->input.tensors[0] = node[149]->output.tensors[0];
    node[150]->input.tensors[1] = const_tensor[260]; /* data_weight */
    node[150]->input.tensors[2] = const_tensor[261]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Conv2D_98_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0a_1x1/Relu_94 */
    node[151]->input.tensors[0] = node[149]->output.tensors[0];
    node[151]->input.tensors[1] = const_tensor[262]; /* data_weight */
    node[151]->input.tensors[2] = const_tensor[263]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Conv2D_105_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0a_1x1/Relu_103 */
    node[152]->input.tensors[0] = node[149]->output.tensors[0];
    node[152]->input.tensors[1] = const_tensor[264]; /* data_weight */
    node[152]->input.tensors[2] = const_tensor[265]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_7b/Branch_3/AvgPool_0a_3x3/AvgPool_93_conv_496 */
    node[153]->input.tensors[0] = node[149]->output.tensors[0];
    node[153]->input.tensors[1] = const_tensor[266]; /* data_weight */
    node[153]->input.tensors[2] = const_tensor[267]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Conv2D_89_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0b_1x3/Relu_78 */
    node[154]->input.tensors[0] = node[151]->output.tensors[0];
    node[154]->input.tensors[1] = const_tensor[268]; /* data_weight */
    node[154]->input.tensors[2] = const_tensor[269]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Conv2D_90_InceptionV4/InceptionV4/Mixed_7b/Branch_1/Conv2d_0c_3x1/Relu_79 */
    node[155]->input.tensors[0] = node[151]->output.tensors[0];
    node[155]->input.tensors[1] = const_tensor[270]; /* data_weight */
    node[155]->input.tensors[2] = const_tensor[271]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Conv2D_102_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0b_3x1/Relu_100 */
    node[156]->input.tensors[0] = node[152]->output.tensors[0];
    node[156]->input.tensors[1] = const_tensor[272]; /* data_weight */
    node[156]->input.tensors[2] = const_tensor[273]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Conv2D_88_InceptionV4/InceptionV4/Mixed_7b/Branch_3/Conv2d_0b_1x1/Relu_76 */
    node[157]->input.tensors[0] = node[153]->output.tensors[0];
    node[157]->input.tensors[1] = const_tensor[274]; /* data_weight */
    node[157]->input.tensors[2] = const_tensor[275]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_1/concat_74 */
    node[158]->input.tensors[0] = node[154]->output.tensors[0];
    node[158]->input.tensors[1] = node[155]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Conv2D_99_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0c_1x3/Relu_95 */
    node[159]->input.tensors[0] = node[156]->output.tensors[0];
    node[159]->input.tensors[1] = const_tensor[276]; /* data_weight */
    node[159]->input.tensors[2] = const_tensor[277]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Conv2D_91_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0d_1x3/Relu_80 */
    node[160]->input.tensors[0] = node[159]->output.tensors[0];
    node[160]->input.tensors[1] = const_tensor[278]; /* data_weight */
    node[160]->input.tensors[2] = const_tensor[279]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Conv2D_92_InceptionV4/InceptionV4/Mixed_7b/Branch_2/Conv2d_0e_3x1/Relu_81 */
    node[161]->input.tensors[0] = node[159]->output.tensors[0];
    node[161]->input.tensors[1] = const_tensor[280]; /* data_weight */
    node[161]->input.tensors[2] = const_tensor[281]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7b/Branch_2/concat_75 */
    node[162]->input.tensors[0] = node[160]->output.tensors[0];
    node[162]->input.tensors[1] = node[161]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7b/concat_72 */
    node[163]->input.tensors[0] = node[150]->output.tensors[0];
    node[163]->input.tensors[1] = node[158]->output.tensors[0];
    node[163]->input.tensors[2] = node[162]->output.tensors[0];
    node[163]->input.tensors[3] = node[157]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Conv2D_49_InceptionV4/InceptionV4/Mixed_7c/Branch_0/Conv2d_0a_1x1/Relu_39 */
    node[164]->input.tensors[0] = node[163]->output.tensors[0];
    node[164]->input.tensors[1] = const_tensor[282]; /* data_weight */
    node[164]->input.tensors[2] = const_tensor[283]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Conv2D_64_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0a_1x1/Relu_60 */
    node[165]->input.tensors[0] = node[163]->output.tensors[0];
    node[165]->input.tensors[1] = const_tensor[284]; /* data_weight */
    node[165]->input.tensors[2] = const_tensor[285]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Conv2D_71_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0a_1x1/Relu_69 */
    node[166]->input.tensors[0] = node[163]->output.tensors[0];
    node[166]->input.tensors[1] = const_tensor[286]; /* data_weight */
    node[166]->input.tensors[2] = const_tensor[287]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_7c/Branch_3/AvgPool_0a_3x3/AvgPool_59_conv_495 */
    node[167]->input.tensors[0] = node[163]->output.tensors[0];
    node[167]->input.tensors[1] = const_tensor[288]; /* data_weight */
    node[167]->input.tensors[2] = const_tensor[289]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Conv2D_55_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0b_1x3/Relu_44 */
    node[168]->input.tensors[0] = node[165]->output.tensors[0];
    node[168]->input.tensors[1] = const_tensor[290]; /* data_weight */
    node[168]->input.tensors[2] = const_tensor[291]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Conv2D_56_InceptionV4/InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/Relu_45 */
    node[169]->input.tensors[0] = node[165]->output.tensors[0];
    node[169]->input.tensors[1] = const_tensor[292]; /* data_weight */
    node[169]->input.tensors[2] = const_tensor[293]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Conv2D_68_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0b_3x1/Relu_66 */
    node[170]->input.tensors[0] = node[166]->output.tensors[0];
    node[170]->input.tensors[1] = const_tensor[294]; /* data_weight */
    node[170]->input.tensors[2] = const_tensor[295]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Conv2D_54_InceptionV4/InceptionV4/Mixed_7c/Branch_3/Conv2d_0b_1x1/Relu_42 */
    node[171]->input.tensors[0] = node[167]->output.tensors[0];
    node[171]->input.tensors[1] = const_tensor[296]; /* data_weight */
    node[171]->input.tensors[2] = const_tensor[297]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_1/concat_40 */
    node[172]->input.tensors[0] = node[168]->output.tensors[0];
    node[172]->input.tensors[1] = node[169]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Conv2D_65_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0c_1x3/Relu_61 */
    node[173]->input.tensors[0] = node[170]->output.tensors[0];
    node[173]->input.tensors[1] = const_tensor[298]; /* data_weight */
    node[173]->input.tensors[2] = const_tensor[299]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Conv2D_57_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0d_1x3/Relu_46 */
    node[174]->input.tensors[0] = node[173]->output.tensors[0];
    node[174]->input.tensors[1] = const_tensor[300]; /* data_weight */
    node[174]->input.tensors[2] = const_tensor[301]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Conv2D_58_InceptionV4/InceptionV4/Mixed_7c/Branch_2/Conv2d_0e_3x1/Relu_47 */
    node[175]->input.tensors[0] = node[173]->output.tensors[0];
    node[175]->input.tensors[1] = const_tensor[302]; /* data_weight */
    node[175]->input.tensors[2] = const_tensor[303]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7c/Branch_2/concat_41 */
    node[176]->input.tensors[0] = node[174]->output.tensors[0];
    node[176]->input.tensors[1] = node[175]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7c/concat_38 */
    node[177]->input.tensors[0] = node[164]->output.tensors[0];
    node[177]->input.tensors[1] = node[172]->output.tensors[0];
    node[177]->input.tensors[2] = node[176]->output.tensors[0];
    node[177]->input.tensors[3] = node[171]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Conv2D_15_InceptionV4/InceptionV4/Mixed_7d/Branch_0/Conv2d_0a_1x1/Relu_5 */
    node[178]->input.tensors[0] = node[177]->output.tensors[0];
    node[178]->input.tensors[1] = const_tensor[304]; /* data_weight */
    node[178]->input.tensors[2] = const_tensor[305]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Conv2D_30_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0a_1x1/Relu_26 */
    node[179]->input.tensors[0] = node[177]->output.tensors[0];
    node[179]->input.tensors[1] = const_tensor[306]; /* data_weight */
    node[179]->input.tensors[2] = const_tensor[307]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Conv2D_37_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0a_1x1/Relu_35 */
    node[180]->input.tensors[0] = node[177]->output.tensors[0];
    node[180]->input.tensors[1] = const_tensor[308]; /* data_weight */
    node[180]->input.tensors[2] = const_tensor[309]; /* data_bias */

    /* trans_InceptionV4/InceptionV4/Mixed_7d/Branch_3/AvgPool_0a_3x3/AvgPool_25_conv_494 */
    node[181]->input.tensors[0] = node[177]->output.tensors[0];
    node[181]->input.tensors[1] = const_tensor[310]; /* data_weight */
    node[181]->input.tensors[2] = const_tensor[311]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Conv2D_21_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0b_1x3/Relu_10 */
    node[182]->input.tensors[0] = node[179]->output.tensors[0];
    node[182]->input.tensors[1] = const_tensor[312]; /* data_weight */
    node[182]->input.tensors[2] = const_tensor[313]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Conv2D_22_InceptionV4/InceptionV4/Mixed_7d/Branch_1/Conv2d_0c_3x1/Relu_11 */
    node[183]->input.tensors[0] = node[179]->output.tensors[0];
    node[183]->input.tensors[1] = const_tensor[314]; /* data_weight */
    node[183]->input.tensors[2] = const_tensor[315]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Conv2D_34_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0b_3x1/Relu_32 */
    node[184]->input.tensors[0] = node[180]->output.tensors[0];
    node[184]->input.tensors[1] = const_tensor[316]; /* data_weight */
    node[184]->input.tensors[2] = const_tensor[317]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Conv2D_20_InceptionV4/InceptionV4/Mixed_7d/Branch_3/Conv2d_0b_1x1/Relu_8 */
    node[185]->input.tensors[0] = node[181]->output.tensors[0];
    node[185]->input.tensors[1] = const_tensor[318]; /* data_weight */
    node[185]->input.tensors[2] = const_tensor[319]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_1/concat_6 */
    node[186]->input.tensors[0] = node[182]->output.tensors[0];
    node[186]->input.tensors[1] = node[183]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Conv2D_31_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0c_1x3/Relu_27 */
    node[187]->input.tensors[0] = node[184]->output.tensors[0];
    node[187]->input.tensors[1] = const_tensor[320]; /* data_weight */
    node[187]->input.tensors[2] = const_tensor[321]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Conv2D_23_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0d_1x3/Relu_12 */
    node[188]->input.tensors[0] = node[187]->output.tensors[0];
    node[188]->input.tensors[1] = const_tensor[322]; /* data_weight */
    node[188]->input.tensors[2] = const_tensor[323]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Conv2D_24_InceptionV4/InceptionV4/Mixed_7d/Branch_2/Conv2d_0e_3x1/Relu_13 */
    node[189]->input.tensors[0] = node[187]->output.tensors[0];
    node[189]->input.tensors[1] = const_tensor[324]; /* data_weight */
    node[189]->input.tensors[2] = const_tensor[325]; /* data_bias */

    /* InceptionV4/InceptionV4/Mixed_7d/Branch_2/concat_7 */
    node[190]->input.tensors[0] = node[188]->output.tensors[0];
    node[190]->input.tensors[1] = node[189]->output.tensors[0];

    /* InceptionV4/InceptionV4/Mixed_7d/concat_4 */
    node[191]->input.tensors[0] = node[178]->output.tensors[0];
    node[191]->input.tensors[1] = node[186]->output.tensors[0];
    node[191]->input.tensors[2] = node[190]->output.tensors[0];
    node[191]->input.tensors[3] = node[185]->output.tensors[0];

    /* InceptionV4/Logits/AvgPool_1a/AvgPool_3 */
    node[192]->input.tensors[0] = node[191]->output.tensors[0];

    /* trans_InceptionV4/Logits/Logits/BiasAdd_2 */
    node[193]->input.tensors[0] = node[192]->output.tensors[0];
    node[193]->input.tensors[1] = const_tensor[326]; /* data_weight */
    node[193]->input.tensors[2] = const_tensor[327]; /* data_bias */



    graph->input.tensors[0] = norm_tensor[0];
    graph->output.tensors[0] = norm_tensor[1];


    status = vsi_nn_SetupGraph( graph, FALSE );
    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vnn_ReleaseInceptionv4( graph, release_ctx );

    return NULL;
} /* vsi_nn_CreateInceptionv4() */

void vnn_ReleaseInceptionv4
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vsi_nn_ReleaseInceptionv4() */

